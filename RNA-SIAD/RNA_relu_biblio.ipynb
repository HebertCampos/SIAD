{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip intall tensorflow\n",
    "# pip install numpy\n",
    "# pip install matplotlib\n",
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>condominio</th>\n",
       "      <th>preco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>500</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>200</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>300</td>\n",
       "      <td>330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  condominio    preco\n",
       "0    33         300   235000\n",
       "1    33         500   320000\n",
       "2    35         200   270000\n",
       "3    36         300   330000\n",
       "4    36         200  2000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv('df_mangabeiras.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fec7468b8e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABM70lEQVR4nO3deZxddX34/9fnnLvOzJ0lyUz2kAQSQoKsAYnQGCkqigb1h5WIX2urJVYtoNW6sloXqrWFVtukaNVWQUuLxAUUxBhQIoSwSBYSskD2WTLbnbuecz6/P869N3fubHdm7j7v5+MRJnPm3nvOmQzv+dzP5/15v5XWGiGEEKVnlPsChBBiqpIALIQQZSIBWAghykQCsBBClIkEYCGEKBMJwEIIUSYVF4CVUt9RSrUrpV7M8/F/ppTaqZTaoZT6YbGvTwghCkVVWh6wUmo1EAa+r7U+e4zHLgF+DFyute5WSrVprdtLcZ1CCDFZFTcC1lpvAU5mH1NKna6Uelgp9YxS6nGl1LLUl/4K+KbWujv1XAm+QoiqUXEBeAQbgb/RWl8IfBL4Vur4UmCpUup3SqmtSqkry3aFQggxTp5yX8BYlFINwOuA/1FKpQ/7Ux89wBJgDTAPeFwpdbbWuqfElymEEONW8QEYd5Teo7U+b5ivHQa2aq2TwAGl1Eu4AfnpEl6fEEJMSMVPQWit+3CD67sBlOvc1Jd/ArwhdXwG7pTE/nJcpxBCjFfFBWCl1L3Ak8CZSqnDSqkPAtcBH1RKPQ/sAK5OPfyXQJdSaifwG+BTWuuucly3EEKMV8WloQkhxFRRcSNgIYSYKipqEe7KK6/UDz/8cLkvQwghCk0Nd7CiRsCdnZ3lvgQhhCiZigrAQggxlUgAFkKIMpEALIQQZSIBWAghykQCsBBClIkEYCGEKBMJwEIIUSYSgIUQokwkAAshRJlU1FZkISrB5t3tbNiyn0PdEea31LF+9WLWLGsr92WJGiQjYCGybN7dzi2bdtDeH6M56KW9P8Ytm3awebe0GxSFJwFYiCwbtuzHayrqfB6Ucj96TcWGLVLnXxSeBGAhshzqjhD0moOOBb0mh7sjZboiUcskAAuRZX5LHdGkPehYNGkzr6WuTFckapkEYCGyrF+9mKStiSQstHY/Jm3N+tWLy31pogZJABYiy5plbdyxdgVtoQC90SRtoQB3rF0hWRCiKCQNTYgca5a1ScAVJSEjYCGEKBMJwEIIUSZFnYJQSh0E+gEbsLTWK4t5PiGEqCalmAN+g9Zaum0KIUQOmYIQQogyKXYA1sCvlFLPKKWuH+4BSqnrlVLblFLbOjo6inw5QghROYodgC/VWl8AvAX4qFJqde4DtNYbtdYrtdYrW1tbi3w5QghROYo6B6y1Ppr62K6UegC4GNhSzHMKMRlSilKUUtFGwEqpeqVUKP134E3Ai8U6nxCTJaUoRakVcwpiJvCEUup54Cng51rrh4t4PiEmRUpRilIr2hSE1no/cG6xXl+IQjvUHaE56B10TEpRimKSNDQhUqQUpSg1CcBCpEgpSlFqEoCFSJFSlKLUpBylEFmkFKUoJRkBCyFEmUgAFkKIMQzELXqjyYK/rgRgIYQYRW8kyYm+GFrrgr+2zAELIcQIusLxoox80yQACyFEDq01Hf1xwnGrqOeRACyEEFlsR3OiL0YsZ1NOMUgAFkKIlKTtcLw3RtJ2SnI+CcBCCAHEkjYn+mLYTuEX20YiAVgIMeVFEhbtfXGcImQ6jEYCsBBiSuuLJensj5fl3BKAhRBT1smBBD2RRNnOLwFYCDHlaK3pCMcJx4qbZjYWCcBCiCnFcTQn+mNEE8VPMxuLBGAhskhTztpm2Q7H+2IkrNKkmY1FakEIkSJNOWtb3LI52lM5wRckAAuRIU05a1c0YXOsJ4blVE7wBQnAQmQc6o4Q9JqDjklTzurXH0tyvC826RzfYswZSwAWIkWactae7oEEHf3xSZeSfHJfF2+9+3GeeeVkga7MJQFYiBRpylk70tXMuieZ46u15r+2vsIXfvIi3ZEkt/90Z0HrAksWhBApa5a1cQfuXPDh7gjzJAuiKjmOpr0/TiQxuRzfaMLmzod3s2VvJwDnzGvinvevRClViMsEJAALMYg05axuhUozO9oT5ZYHd7C/cwCAq14zm1vfvpy2xkAhLjNDArAQoiYkLIcTfZMvJfnMK93c8bOd9McsTEPxsTecwdpzZ+PzFH7GVgKwEKLqFaKUpNaa+585zIYt+3E0NAe93Lp2OefOay7cheaQACyEqGrhuDXpTId40uYfH9nDo7vcTTdL2hq44+oVzCzwlEMuCcBCiKrVG0nSNTC5UpLtfe6Oxz0nwgBccVYbn3jjUgI5OeHFIAFYCFGVOsNx+ibZsfiFwz3ctmknPdEkhoLrVy/m3RfOK2imw2gkAAshqorWbprZwCQ7Fm96/ij/8tjL2I4mFPDwhavO4qKF0wp0lfmRACyEqBq2ozneFyM+iY7FSdvhXx57mZ+9cAyARTPquePqFcxtDhbqMvMmAViILFKOsnIVomPxyYEEt27awY6jfQD8yZIZfObKZQR9xZ/vHY4EYCFS0uUovaYaVI7yDpAgXGaFSDPbfbyPWx7cQWfY3Z78F69byHWXLMAo0XzvcCQAC5GSXY4SoM7nIZKw2LBlvwTgMhqIW7RPMs3slzuO841H9pC0NXU+k8++ZRmXnjGjgFc5MRKAhUg51B2hOegddEzKUZbXZNPMLNvh37fs5/+2HwFgXkuQL169gtOm1xfqEidFArAQKfNb6mjvj2VGwCDlKMtpsmlmvZEkt/9sJ88d6gHgtYum8fm3nkVDoHLCXuVciRBltn71Ym7ZtINIwiLoNYkm7Uw5SlmcK51CpJntaw9z84M7ON4XA+C61y7gA69biGlMbL436DMJBbxjP3CcJAALkTJSOUpAFudKpBBpZr/Z3c4//PIl4pZDwGPwd1cuY82ZrRN+vZY6Hy31vgk/fzQSgIXIMlw5ynUbt8riXAlMtpqZ7Wi+87sD3PvUIQBmNQb44tUrOL2tYUKv5zEMWkP+oqaoSQAWYgyyOFd8k00zC8cs/v4Xu3jqgNsy6PwFzdxy1XKa6iY2bRD0mbSFAhOessiXBGAhxiCLc8U12Wpmr3QNcPODOzjcHQXgXRfM5a9ff/qEg2cxpxxyFT0AK6VMYBtwRGv9tmKfT4jJyl1wW7V4GvdvPzLs4pyYnJ5IgpMDE+/b9ruXO/nKQ7uJJGy8puLjVyzlyrNnTei1SjHlMOScJTjHjcAuoLEE5xJiUobbDXf/9iNcc8Fcntx/UnrFFVBHf5z+2MTSzByt+cHWV/nP3x8EYEaDj9vXruCs2RMLM6WacshV1ACslJoHXAV8CfhEMc8lRCGMtBvuyf0nuff6S8p8dbVhsk0zIwmLrz70Ek+87DbLXDGnkdvXrmDaBKcNSjnlkKvYI+B/Bv4OCI30AKXU9cD1AAsWLCjy5QgxOllwK67JNs080hPl5p+8yMEu99/jqtfM5m8uP2NC/dpMQ9EWCpStEA9A4bvMpSil3ga0a62fGe1xWuuNWuuVWuuVra0Tz9UTohDmt9QRzclBlQW3wkhYDkd7Jh58tx08yUd+sJ2DXRFMQ3HTFUv42zctnVDwDfpM5jYHyxp8oYgBGLgUWKuUOgjcB1yulPrvIp5PiElbv3oxSVsTSVho7X6UBbfJiyZsjvZEsZzxB1+tNT96+hCf+b8/0h+zaKnz8o/vPoe1586Z0LW01PmY3RTEYxYz/OVHTabCUN4nUWoN8MmxsiBWrlypt23bVvTrEWI06SwIWXArjP5Yks5wYkJpZrGkzT/+ag+/3u02y1w6s4E71q6gbQLNMss85TDs6p7kAQuRY7jdcGJiJpNmdqIvxs0P7uDl9lPNMv/2jUvxT6BZZtBn0trgr4hRb7aSBGCt9WZgcynOJYQoP601neHEhNPMnj/cw+1ZzTLXv/50rrlg7oSaZZYzy2EsMgIWQhTUZNLMtNZsev4o//qbfdiOpjHg4ea3LefC01rG/VqVkOUwFgnAQoiCmUyaWcJyuPvXe/nFi8cBWJxqljlnAs0yK3XKIZcEYCGqVKXVKI5bNid64xPKdOgKx7l10052HnObZa5eMoNPT7BZZnOdb8KbMkpNArAQVajSGohGE241M2cCmQ67jrnNMrsGEijgLy5dyHWvXTDu+d5qmHLIJQFYiCpUSQ1EJ5Nm9tCLx/nnR91mmfU+k8+99SxWnT593K8T8Jq0hSp/yiGXBGAhqlClbJnuHkjQHRl/mpllO/zbb/fzwLNus8z5LUG+ePXZLJg+/h2H1TTlkEsCsBBVqNw1irXWdITjhGPjz3Rwm2Xu4LlDvQBcsngan3vrWTT4xxeOqnHKIVd1jdeFEEB5t0w7qb5tEwm+L7eH+fAPnskE3+teu4AvXn32uINvwFsZtRwmS0bAQlShkRqIFnv+17IdjvVOrG9boZplVvOUQy4JwEJUqVJvmZ5ompntaL79xAHue3pyzTJNQ9Ea8g+adql2tXMnQoiiiSQs2vvi404z648l+dLPd/HUwW4ALljQzM1vW05TcHzNMqs1y2EsEoCFEKPqiyXp7I+P+3kHuwa4+Sc7ONLjNsu85sK5rF89/maZzXU+Wuq8E6oDUekkAIspY7w7xyptp1k5nBxI0DOBNLPfvdzJl3+xm2jSbZb5t286kzctnzmu16jFKYdctTWeF2IE6Z1j7f2xQTvHNqfqzE728bVGa017X2zcwdfRmu8/eZCbH9xBNGnT2uDn7mvPH3fwTWc51HLwBQnAYorI3jmmlPvRayo2bNlfkMfXEtvRHOuNEY6PL80skrC4ddMOvvv7VwA4e04j//a+Czhz1ogtIYfVXOdjdlOg5uZ7h1Pbv16ESBnvzrFK2WlWaknb4fgE0syOdEe5+cFTzTLffu5sPvaGM/COI4hOhSmHXFPnTsWUNt6dY+XeaVYOsaRbUMd2xpfp8PTBk3zxZ7sIxy08huJvLj+Dt4+zX1utZjmMRQKwqBmjLZqtX72YWzbtIJKwCHpNokl71J1j4318Idz96B7ueeIAAwmbep/Jhy5bxA1XLC3a+bJ9/eHd/OfvDxJN2gS9Jn924Tz+3+sWjvocrTU/3naY/3h8P46Gljovt719Ba+Z1zSuczcFvUyr99VklsNYStKUM1/SlFNMVHZ5xuyAecfaFZkgPN5mm6Vsznn3o3u467GXMRQYChzt/rnx8jOKHoT/4aFd/PuW/RgKlAKdOvefX3LaiEE4t1nmmTND3HH1ClpD/rzPO8WmHIb97SIBWNSEdRu3DpkyiCQs2kIB7r3+kjJeWX7Oue2XRJM2HuPUW3DLcQh6TV647c1FO29XOM7qf/gNccvGzDq37Tj4PSY//ZvLhjzneF+MW7KaZb5x+Uw+ccWScTXL9HtNZk6tKQfpiixqV7Uvmg0kbDw5schQ7vFi0FrT0R8nHLeIJm1y46BS7px3rucO9XD7T3fSm2qW+eHXn87/N85mmVN5yiGXBGBRE6p90aze506bZG8Sc7R7vNBsR3OiL0YsFWCDXpO4ZQ8ao2ntHj/1ueYnzx3lm795GUczoWaZU2zKIS9TZvwvals5yzMWwocuW4Sj3WkHRzupj+7xQkraDkd7opngC/BnF87D0e60g6Od1Ef3OLjNMr/+qz38y2Nu8F08o55vXXfBuIKv32syZwpsrBgv+W6ImlCu8oyFkl5oK2YWxEhpZumFth8/c3hIFkRnOM6tm3aw61g/AK9f2srfXXnmoNHxWGTKYWSyCCfEFDAQt2jvj4+rb9vOo33cuulUs8y/vGwh7704/2aZpqGY0eCnfpzF1muULMIJMRX1RpJ0DYyvmllus8zPX3UWlyzOv1mmP7WxYjw74aYiCcBC1LCucJzeaDLvx1u2w7c27+Mnzx0FUs0y33E2C6blv5gpUw75kwAsRA3SWtPeH2dgHAV1eiIJbv/pTp4/7PZrW7V4Op9967K8+7UZys1ykCmH/Ml3SogaY6eaZsaHyeMdyd4T/dz84A7aU4XXr3vtAv7i0oUYeY5iZcphYiQAC1FDEpbDib7xVTP79a52vv6rVLNMr8FnrlzG6qX5N8uUKYeJkwAsRI0YbzWz3GaZs5vcZpmLW/NrlilTDpMn3zkhakA4btExjjSz/liSv//5Lp5ONcu8MNUsszHPZpky5VAYEoCFqCAT6UM33jSzA50D3PLgqWaZ775wHtevXpx3s8zGoJc/Hurhkz8+MCX65RWzN6BsxBCiQuRTUjNXZzhO3zjSzJ7Y28lXHppYs8z0lMPTB06O+zqr1UT+TUYw7G83ef8gRIUYTx86x9Ec743lHXwdrfnu7w9yy6aJNcv0e03mtgSp93umVL+8Yt+rTEGIKaPS28znW1LTsh1O9MfzTjOLJCy+8tBufvdyFwCvmdvIrW9fwbR6X17Pbwx6mZ6V5VDtpT/Ho9j3KiNgMSVUQ5v5+S11Q2rw5pbUTFgOx3rzz/E90h3loz98NhN81547h6+/+9y8gq+hFG2NAWY0+AelmOVznbWi2PcqAVhMCdXwtnmskpqxpM3RnmjeOb5PHTjJX/9gO690RfAYik+8cSk3XbEkr8wFn8dgbktw2F1w1V76czyKfa8yBSGmhGp42zxaSc3xpJlprbnv6UPc8/gBNG6zzNvXruDsufk1y8ydchjPdRZbqaeRin2vkgUhpoRq7hnXE0lwciCR12NjSZuv/fIlfvNSBwBnzgpxx9r8mmVW+saKAmYklINkQYipq1rfNneG43kH3+N9MW6497lM8H3zipnc9Z7z8gq+2VkOlaoappHGq3K/20IUULV1zBhvNbPJNMuslloO1TCNNF4SgMWUsWZZW8UG3GzjqWamteaBZ4/yrc2nmmXe8rblXJBHv7Zqa5JZ7Y1Xh1O077xSKgBsAfyp89yvtb61WOcTU0cl5PPe/eieovRvG081s4Tl8M+P7uXhHccBWNxazxevXsHspuCYzw2kajl4qqiWw/rVi7ll0w4iCWvQHHClTyONpmiLcMp9P1OvtQ4rpbzAE8CNWuutIz1HFuHEWCphIebuR/dw12MvYygwlNs+3tFw4+VnTCoIj6eaWW6zzDVLW/lUns0ym+t8eW/CqDTpX77VMI2Uo7Q94bQb2cOpT72pP5WTciGqUvZCDECdz0MkYbFhy37WLGsryej4nicOYCjwGO7o0VBuO/l7njgw4QA8nqaZO472cuumnZxMNcv84GWLWHfx/DHncE1D0RYKEPTl39G40lTLNFK+ivr+QyllKqWeA9qBR7TWfxjmMdcrpbYppbZ1dHQU83JEDTjUHRkyyksvxJRqt9tAwia3cJih3OMT0RtNcqIvllfw/cUfj/GJHz/PyYEE9X6TL73zbN772rE7FQd9JnObg1UdfGtRUQOw1trWWp8HzAMuVkqdPcxjNmqtV2qtV7a25l+FX0xNo20NLVWaUr3PJHeWwNHu8fHqCsfpCo9dStKyHe56dC9f/5XbqXjBtDq+9d4L8upU3FLnY3ZTsKrme6eKkvyLaK17gM3AlaU4n6hdo+XzjjY6LqQPXbYIR7vTDo52Uh/d4/nSWtPeF8urY3F3JMEn73+BB593OxWvWjydb773fOaP0anYYxjMbgrSUqXzvVNBMbMgWoGk1rpHKRUErgDuLNb5xNQwWj7v/C2lSVNKz/NONAvCdjQn+mLE8kgz23Oin1uymmW+/5LTeP/rThuzWWbQZ9IWCuRdZF2URzGzIM4BvgeYuCPtH2ut7xjtOZIFISajEjIkxpK0HY735pdm9utdJ/jar/aQSDfLfMsyVi8Ze5puWr2P5joZ9VaYkmdBvACcX6zXFyJXpe92yzfNzHY09zy+nx9tOwy4zTL//h1ns2hG/ajP8xgGbY1+AnmkoonKUB1bYITIU6WmKUUSFu19cZwx3nH2Rd1mmdteSTXLPK2Fm686a8xmmXU+D60hv0w5VBkJwKKgirVDbLwqYbdcWl8sSWf/2JkOBzoHuPnBFznaEwPya5aplGJanY+muvy6GVeySvo3KxUpRykKplg7xMarkuaCTw4k6ImMXc3s8b2dfOWhXcSSDj6PwSfftJQrzhq9X5vXNGgN1caUQyX9mxWJlKMUxZW9Q8xQRuqje7yUKqFsoVvNLDZm8HW05ru/O8itm3YQSzq0hfzcfe15Ywbfer+Huc3Bmgi+UBn/ZuWQ9xSEUsoHpIcxL2mt8++FLaaEgYSNJ+dX+mR2iE3U3vZ+InGLpKPxpUaJDX5PycoWOo7mRH+M6Bj3PRC3+PIvdvPkfrdf2znzmrj17ctpGSWDQSnFtHofTWPMCVebWiw1mY+8ArBSag1uStlB3KH0fKXUn2uttxTtykTVqfe5bx2zpywnukNsojbvbqc/ZuFojWkoLEdztCfG9AYvC6c3FP38lu1wvC9Gwho9zezQyQg3P7iDV0+6Aebqc+fw0TecPuputVqacshVi6Um85HvCPgfgTdprV8CUEotBe4FLizWhYnq86HLFnHXYy9jOc6gOeDx7BCbrA1b9tNS56UjnMBKOpnqT53hBF95Z3HLFsYtmxO9cSxn9OC7dX8XX/rFLgbiNh5DccOfLuFt58zmqf0nue/pQxzrizK7Mci1F83n4sXTAHfKobXBj1GjWQ61WGoyH/kGYG86+AJorfekSkwKkTHZHWKTtXl3O9tf7SZpOTicWvVQgGUXd7E5mnBzfEdLM9Nac+9Th/j2E26zzGn1Pm57+3LOntvEU/tPctdje/EYisaAh66BOHc9tpcb1RLecvbsmshyGE2l53AXS15ZEEqp7+CWkvyv1KHrAI/W+i8KeTGSBSEmKrsSWjw18lW4b9uVcv9+/oKWojTg7I8l6QwnRq1mFk3afD2rWeayWSFuz2qW+YkfPU/XQHxQLYuYZTO7MciPPryq4NcsSm5SO+H+GvgocEPqhbYA3yrMdQkxeelV9JmhAK+cPLVwk7QdvKbBrCZ/URZ0ugcSdI+R6XC8N8bND77Ivo4BAK5cMYubrliCL2vF8lhflMbAqf8dDUMR8ns42hst+DWLypFvAPYAd2mtvwFunV/cVkNCVIT0KrryKfweY9Ai2JzmQKYYeaForekMJ+iPjZ4MtP3Vbu746U76YhaGgo+sOYN3nj9nSP3e2Y1BdwTsM/EYBqahiCSsml+EmuryDcC/xq1mlu5wEQR+BbyuGBclqkN659KeE30kbY3PY7CkLVSWubvsVfRZjYHMyNFrKExDFXRBx3HcjsWRhNuxeLjFs4sWtfB/zx7h3zbvyzTLvPXtyzl/wfDNMq+9aD53P7aXpO3gM41BZTZF7cp3Dvi5VGH1UY9NlswBV4/0nGvCsukaSL0F1zAj5MNrmiXfwZS7k6ozHKc7kiQU8BT0l0Jumln24lnAaxBLOiRthznNQba/2gPA6a31fPHqs5nVNPIIvM7nYeeRXv7jiQNTahFqCpnUHPCAUuoCrfV2AKXUhYBMTk1h6TnXrrCFgcIwFI7W9EUtZjV5Mj3aSiV3FX3RjAa+WuAANlzH4vuePoTHUJnFM4+hONGX4HifW/vhDWe28qk3nzli7m52LYdZTQEuXz76DjhRW/INwDcB/6OUOpr6fDbwnqJckagK6TnXhO1gpuYzlYKE7ZRtB1MxK6GNVEoye/EsmrQ52nvqMX/1J4u49qKRm2VK+UiRVwDWWj+tlFoGnIk7lN4tW5GntvScq880sGyNUqA1+Eyj5nYwheMWHSN0LE4vnsUtJ9O1QilYNL2edRcvGPE1pXykgPy3ItcBnwBO01r/lVJqiVLqTK31z4p7eaJSpXcuhQIeugYSOI4GDY313gktHm3e3c5XH9rFgS535Lx4Rj2fvnJZyaYxRiqF2BtJ0jUQH3GX2jUXzuXLD+0mkqr74DEULXVerv+Tke+/WjpWVGJ5yEq8psnIdxHuR8AzwPu11menerw9KYtwU1v6f4a9J/pI5JEFMdL/PJt3t/PJ+5+nJ5LM1JFwNLTUefnaNecW/X+wkUohfvKNSzl7XtOwC22Wo/ngpYt48Pmj/PFILwB+j8HSthDXvXZBZgtxtmqacqjE8pCVeE3jMOxbnXwD8Dat9Uql1LNa6/NTx57XWp9byCuUAFy7RvufZ8OW/Tx7qBvtkKl14Ghd1N1r2dZt3DqoEIzWmv5YkpY6P994z7nD7lLrjSY5GUmQTG1xfv+q03j/qpGbZVZbk8zc7wm4XT3aQoGi/3tU0zWNw6SyIBKpUa8GUEqdDoxd4l+IlOx6r+DOgUYSVmZEbDs6s5gH7jyqZTslWczLLoWotc7kNB/vcxN9cnep9cWStPfH0bglEz/zlmX8yZIZI75+S52v6lrDV2J5yEq8psnKtyD7rcDDuGUof4C7MePvinZVouYc6o4MGkHCqf955rfUYRqK7DdjWrtv2UuxmDe/pY5o0sZJBV+tNbGkw6zGIOAutMWSDlprOvrjHO9zg6/PNPjX954/YvA1DcXspmDVBV849T3JVu7F1Uq8pskaMwArpQygBXgX8AHcMpQrtdabi3ploqaM9j/P+tWLafB7sLXGdpzUH00o4CnJTrD1qxeTsBz6Y0kc7RBN2liO5tqL5gPuLrWE5fBqd5TuqJv84/MYfObKM0fsVBz0mcxtDhIsYS3kQlq/ejFJWxNJWGitK2JnXiVe02SNGYC11g7wMa11l9b651rrn2mtO0twbaKGjPY/z5plbXz9mnM5o7UepRRKKZa0NZRkAQ7gokXT+OgbzmBanZ/+mMX0ej83Xr4ks5A2I+Qj6Wjiqd1vbQ1+bnvb8hGvrbnOx+ym4KjF1bNt3t3Ouo1buezOx1i3cSubd7cX5sYmYc2yNu5Yu4K2UIDeaJK2UKDsi12VeE2Tle8i3M24O99+BAykj2utTxbyYmQRrralsyAqaattbzRJV3jk5Ywtezr46sO782qWmS74M55Rb5Wv7Iv8TSoL4gAw5IFa64KO/SUAi1LqCsfpjQ6/n8jRmu/+/iD/vfVVANpCfu64egVLZ4aGfXzAa9IW8uc96k2r8pV9kb9JZUEsBz4CXIYbiB8H/r0w1yVEaaUX08Jxa9ivh+MWX/7FLrbud9/gjdUss7nOx7QJLrTV4sq+yF++Afh7QB9wd+rzdaljf1aMixKiWGxHc6IvRiw5fMfiV09GuPknL3Ko201Bu/q8OXx0zfDNMk1D0RryDxq9jtdUbUYpXPn+5JyZs+niN0qp54txQUIUS9J2ON47uJpZtq37u/jSz3cxkLDxmoqb/nQJb3nN7GEfO9Eph1xTtRmlcOUbgJ9VSl2itd4KoJR6LfC74l2WEIU1Wsfi3GaZ0+t93L52BcvnNA77WpOZcsg1VZtRCle+i3C7cCuhvZo6tADYBTiA1lqfU4iLkUW4qauYRVYiCYv2vviwHYujSZuvPfwSm/e4zTLPmu02y5zRMLTjViGmHMSUNalFuCsLeCFCDJKditUc9NLeH+OWTTu4AyYdhPtiSbpG6Fh8rDfKzQ/uYP8ozTLTCjXlIES2fOsBv1LsCxFT12h1IiYTgE8OJOgZoWNxbrPMj77hDN5x3tBmmeBOObTUeUcsrC7ERMl7KTEudz+6h3ueOMBAwqbeZ/KhyxZxwxVLJ/WahUzF2ry7nX//7T5eORlhZiiQqdubprXmf7cf4d9/6zbLbAp6ufXtyzlvfvOQ15IpB1Fs8pMl8nb3o3u467GXMRR4DHf+9K7HXgaYVBAuVCrW5t3t3PzgixgKGvwmXQNx7npsLzfibitOWA7feGQPv9p5AoAzWhu44x0rmNU4tFmmTDmIUpCfLpG3e544kAq+BoYyUh/d45ORrhPR0R9jf0eYXcf6ONwdZdUwRc1H8++/3YdS4PeYKNytvR5Dcd/Th+joj3Pjfc9lgu8bzmzl7nXnDRt8m4JeZjcFJPiKopOfMJG3gYRNbj1xQ7nHJ2PNsjauuWAu3ZEkMcvGZyqm1Xu5f/uRvAvTxC2bg10D+HMW0AJeg1dPDvDh/36Gl070o3CbZX7hqrOGdKYwDcWspgDTG/wy3ytKQqYgRN7qfe5Ggewg7Gj3+GQ9uf8k81qCQ2oi5LMQF024HYtnpRpkZtcd7gwn6Ikk0UCD38MXrjqLixcNHVn7U1MOXhn1ihKSACzy9qHLFnHXYy9jOQ6GcoOvo93j+Rgt1ze9ENcXTdIZjpOwHXymQe8IWQxp/bEknak0s2svms9dj+0lmrTxexTHeuOZ0flp0+t49wXzuO+pQ/zTo3sGNdZsCnqZVu+TUa8oOfl1L/J2wxVLufHyMwh6TSzHzVS48fIz8lqAS+f6tvfHBuX6pqcY5rfU0RmOc7Q3imW77YkStkN/3B5xGqInkhjULv7ixdO48fIlNAa8vHIymgm+l54xnb9ctZAfPPUqXQNxGgOezALdnuP9MuUgykYCsBiXG65Yygu3vZlvv38lK+Y08eNnDudVRDw711cp96PXVGzYsh9wF+K6I25pSGW4JfcU7lxw+jHZOvrjnBwYOjpuqvPS3h/PNMv881WncfvaFTzw3FE8hrswp3DPH/QafO9JSXEX5SNTEGLcJrJzbaxc3zXL2ggFPETiFklH4zMNWkN+GvyeQfnAjqNp748TSQwtJfnIzhP84yN7SFgOQa/J5966jEvPcPu1ZTfWNA2FaSi8pkfKPoqykgAsxm0iO9fyyfVd0hYatjh5+jG2ozneFyOeU0rSdjQbt+znf545DMDc5iBffMcKFk4/1a9tdmOQk5E4DX5vpjV89msLUQ5FC8BKqfnA94FZuEV7Nmqt7yrGuYpZyGUqG+n7mu/OteznN/hM+lLdJ3LLLn78vu1seuE4tuNOGzT4TRZOrx/0mITlcKJvaCnJ3miSv//ZTp55tQeAixa28IWrziIUGHx977tkAXf9ei9xy664so/y8zt15VUNbUIvrNRsYLbWertSKgQ8A7xDa71zpOdMpBqa9NQqvM272/nqQ7vY2xHGaxjMbHR3hKW/rxu27B+zjc5w/y7tfTFsDXHLyWxjfnJfJ08e6B5yDXU+k3PnNbN+9WIuOX06J/pimQCdtr8jzM0P7uBYbwxwuxd/8LJFmRFuWmPQy/R6H799qaPiyj5W4s+v/EIoion3hCvI2ZV6EPhXrfUjIz1mIgFYemoVVna2guNolFJoDXOaA5mmk+ki4qMFjdx/l75okiM9UTyG4oy2BqJJm96om0I2knktQeY0BXnXBXOH5O7+dk8Hd6aaZfo9Bp9685lcnhMkDKWYkZpHrlSV9vNbib8QasSwAbgkWRBKqYXA+cAfhvna9UqpbUqpbR0dHeN+7UPdkUGJ9yA9tSYjPb9rOxpDKQylUMrNOkh/X/NpD57779IZjmMosLXOZEGM1JMtLeT3cKw3yl2/3stTqf5sjtZ8+4kD3P7TncSSDm0hP3dfe96Q4OvzGMxtCVZ08IXK+/kdK1tFFFbRfzqVUg3A/wI3aa37cr+utd4IbAR3BDze15eeWpOX/Zazoz/OrEY/PtPAsjVKgVKQsJ1B39c1y9pGHRHl/rskbAcF+LJ2muVOKeSyHZ0Zhd339CGWz20c1CzzvPlN3PK25TTnNMtMTzlUQ25vpf38SpPQ0ipqAFZKeXGD7w+01v9XjHNIT62JG26uVyk40hNjWp2X7mgS23KwtZuXe7g7ytXnzsk8N3uecFajj1/v7siUqfzTZa0c6Ylm/l1MQ2HZmtbQqU4TpqEy+bq5Qn53hNwdSZC0HY71Rvngd7fREY4D8M7z5/LXr188qGBONUw55Kq0n99K+4VQ64q5CKdwOyef1FrflM9zJtqSKB0MKmlxpdKNNNfbHPTQNZDASQXdNL+pmNbgw2uaXHPBXO7ffiQzT3i4O0JP1MI0wGOozBbltefM4nhfgsPdEep9Jl0DCRqD3kGLcgMJm9yBsNeA1lCA9v4YCoWjNek4bRqKT7xxKW85e9ag5/g8Bm2hwLDdLCpdJf38yhxw0ZR2EU4pdRnwOPBH3DQ0gM9prX8x0nOkJ1zppBd/Xj0ZwVQKpdxAh9YkHY2j3Z8YjRtU57UECQW8RBIWHf1x6v0mfVGLhO1kRrFGqhQkgOW4myFeuO3NmXPmBpqeSILuSIL+mEXcsvGaBh5DEbMclALH1jiQCdCGgtNnNLDh/RcOupdQwMuMhuqYcqgGlfQLoYZMqifcuGmtnxjppKL80nN9uXO9cUvjMRVB0yBhO5hKYTmOG6gNhc80iCRsogkbI7WjLB2As0eyw5WpzJ03vuzOx5jR4Gd6g5+k7RCOpacchg4KAh6D2U1++uPJrHNU35RDNRhrfl8UTvW9XxMFMb+ljmjSZkaDHweN47h/NICG1lB6Ic7Bctzgmi6QowEHN0tCjfA7Np8ylfNb6hhIWJng297vbrTwmYN/czcGPMxrCWI5MKsxCLhTDnOaKz/LQYjRSACeotJdKDymYk5TAGWArd3pBsvRHOyKMJCwsbIGo7bWpEOu7UAsaRPN2RYcTR2zHT1mmcr3vXYBPZEkBzsHONobcwO9A0nn1PyzqaAt5CNuOViOW3IyFPAytzlYlfO9QmSTn+ApKjuX19GwcFodzQEPVnoUPAzL1rTUeU8FvhEmmAzljn7Pmdc84vm7wnH6Y9aQ13EArd3AO73ei2EownGb6fV+bvrTJVx17mxaQ1I+UtQGef82haXn+tIr393R5KiP10DnQDzzW9tnGKl5Y3daIuAxWDIzBIzczUJrt5rZQNzivqcP0eD3ML3ex4HOgUymgwIWTKvDcjTzW+r5xnvOxWsazGysziwHIUYiAXgKS692b3+1GwVD0sGGYzvuKLW1wUsk4ZBIFcfxGu4URdpwyfu2o/nJ9sP819ZXOdYX5eRAgmmp+r3ZwVcBlqMzUw4NAQ+tDf5MLYdKq1EgtRPERJWsFkQ+JA2tdLLzPV89GcFxTuXa5uP01vpMsv7+jnCmhdDi1gbAHQF7DUVLvZ9D3RHmNgc5e04jv3jxOB5DEfAaHOgawMqaQm4MeIgmLUCxYnYT1148n6vOmU0o4GXz7nY+ef/zhOMWtqMxDUWD38PXrzm3rMFO8mZFnkqbhiYq1+bd7dxw37MMJCwCHtNNNRvnL+KkrTO7t0IBj9uFAoddx3rxGAY+U+H3miQdTWPAremw/dVumoMeQn4/PdHkoOA7p8mPaRjU+z3cePkSLl0yY9CUw1cf2kVPJImpFKZSaAd6Ikm++tCusga6idRGFiJNJtSmmPSILZKwMxkPyVRqWb4MxaBiPM1BLw0+E8NwN3SgIGo5eEyF32NiOZqAx8RxNN0DSfZ1hmnvj2dey2O40x/T6/3cePkSLl/exryWwVkOB7oiGIrMOQxDYSj3eDlVWjEdUV1kBDzFpEdsfo+7AcMwFB7TwLFOBWE3KBqZ+d1cLUHPoGT9dRu3knT0oPoBu4710TOQIOQ/VdhFKbAcMjlmCvfvC6bXc8+fr8RQiukNviHF1CuZ1E4QkyEj4CkmPWLL3oCRXfXBY7ibHEbK8mr0G9T5BwfI7FHg8d4oO472YjmaqKXpGnBHurGk7QbfFFO5f5QCtM5srBgp+C6eUZ+qMaHRaBztbpdePKN+2MeXSjqfOpKw0Nr9KMWgRL5kBDzFpEdsjamSg53hOHFLEwp4aAp66eiPu7WAOVULwlDgNQ20hvqAl3qfybqNWzOr/iG/h2jSpi+apCOnwHrXQJJY0hm0LdlnunUnvKZBS52XmOUwtzk4am7vp69cxqfuf57+mIVlO3gM97mfvnJZEb5L+VuzrI07QGoniAmRLIgpZrRVeyDzteO9MaJJt1KZx1B4DIWtNVprWup8g6qa9UaTKKAznBg0l5wO4Glew51iaEyPchUkLYdZTcG8uj9IkRhRxSQLQpwasX3sh88QTpyaE9jw25e5d/3ruOZwD/c8cWDQiNXRmqTjbrRIWA6NQS+WrTnQO+AW7DEU04OeTLBVuNMLNmQi8NKZDcQTNod63Pzf1gYffq+JrRnx7Xq6XnF6oc1rQCTp4Gg41B3l+cM9mb5xhQ7EktsrSkFGwFPQug2/H7YR5rKZ9USSmoRlc6IvjsYNph7TrQAxvcHLyYEksxr9HO2NYeC2K7Idt2i7z+MW71FqcKF1U7nFfbymge04dA24Fc/OnBni01cuGzawpfN+eyJJDAWJEZKUG/wm0+r9Bc27ldxeUQTl6wknKstwwRdg94kBvKaiP2Zhpn5cNG4NCI3m5ECSxTPqOdEfx8BNBQNAKQzAstzKadnBV3Eq+AZ9JqZh4DEMDKU40hMd8Ro3bNlPOG65eb/GyD+m4bhd8J5lG7bsJ2HZHO+N8dKJfo73xkhYtvRFEwUnAVgMEvSaJGwHj2ngTeXaatxebiG/yaevXEbSTmciONhaY9vuLjorZ5Dq8yg+sOo0dOp1Ywmb430xLFtjGjCQsLhl0w42724fch2HuiPYjh4xGyP3mguZd7vnRB9dAwn3OpXbSqlrIMHeE0NaGgoxKRKAxSDRpI0vlfHgMQ28pkG9z2RWU4AlMxtZs6yNpW0NqZKUGo+hMHN+ioJekzlNAZbPauL/vW4h85rrsFJTD6dGzoqAxxxx9Dq/pQ7TcNsk5XPNhcy7zXT4yNr0ASNPgwgxUbIINwWtWtQy6hxwKJDqC+dokrYmAezrGOBYb4y7HnmJ9atP585f7iZp2fTHLZJZ+b0GqZrAvW7Pt93H+nj90hl8c/M+4pbbGdmTqircGvIPGb2mF7/2nOjDsh20BsfOvdLB9nUMsK9jgOW3PMyHVy/mQGeYTS8cz9SMuPi0ZlAGh7oj4DicjFrELYd6n8mHLlvEDVcsHfR6Po9BNGHjaHcErlOp0lKJTRSaLMJNUbkLcasWtXDv+tdlAuDeE330RpODgiu4c7ofWHUaAN//wyuMsFkuo9Fv4k91RW7vj2d6zbWF/LQ1BogkLNpCAe69/pIhi1+d4TjH++IFud8Gv0nQa9ARdktueg1AuQ1Eb7z8jEFBeN3GrRzsCmd63vlMg8agh4XTG/JKlxNiGLIIJ1wfv287T73SA7hdht953mzuXf86wE1Tu/f6S/j6u88btjqaBn749Ks8tONEJvgaI8zTek1FOGHTH3MrmKXLXWqgayA+ZNdYdmEbpVSmwWfaWNPB2V9P97hLC8dtugaSmce53T8MDAX3PHFg0OusX70Yr+lOu5w5M8SspgBe05TdbaLgJABPMR+/bzsPPHcMOxUNbUfzwHPH+Ph92zOPSY9ER6oPHLc0x/tigJsb3NrgH/Zx6RrDMcsZskPOciBhOYNSu7K3NPdFkxztHZwlMeZ7tTEidOZ+0tMKjNw8NLvYUFsoIClooihkDniK2fTCcWDw6FBr9/g/Xet+nh6JjqXeZzK7KTAknUyltsAlbY2hTgW+zDm1G0x7o8lBQS27sE1n2E11yyPsZt3I6F/OXIs+dS0jNQ+VzsCiFGQEPMXYWcNarU+NBG1Hs/LvH2Hdxq3sbe8fUmIx1zvOnUMo4CFuOSRtZ9APkk4FWM0wXTZSn3uNoSPP7MI2bvdlPea0wzAvPeTewJ0Dnl7vzTzOVGA57q66sZqHClEsEoCnGDM1YTvc2mtvJMnBrjD9MYuOcGzEUfDspgA3XLGEm65YyqzGAKZh4PMY1HnGCJepkafXNECpISPP7Lf+hlIYSnHa9DpaG3yDHjej3stZs0KE/IN/fBXuot+qRS2Z+zQNxapFLbxmbjMBr4d5TX7qfCYO7kJf7gKcEKUkUxA1KreOwuIZ9Xz6ymVcfFrzsCloZirftS9q4fcoTvQlhjwGoCngdqzwmgbvOH8u1168IDNnnLsZImvGAXC3NLvTAHrEkWduo1DTUMxsDNAY9A7ZDrxu49YhtXgjCQuUwb4vv3Wc3zEhSk8CcA3KraMAsLc9zA33bsfvNanzGkSy8ssUbo6rox0iiZHzyhZOr+PDq0/nDWe10drgz2xQSBf4+cB3nx70mtlTuCG/gVIGAwl7xPzbbPmUeTzUHaE5OLh+sHSjENVEAnANyq6jkA6SSmvCCZuErVkyM8T+jjCWrUk4jrsopnVmWiJ3dsJIFU9vrvPxltfMpqluaNH0NcvaaAx46I9Z7vOzZiMUcPbclnHn0I61EJZetLNsTWc4nqnMtnCadKMQ1UHmgGvQcHUUVCoDwHLcEW66I0Y6IyFmOSRsPTT44s4XJx3YebSXZ191py/ufnQPSz73cxZ+xv1z5hceYsXsUOb56UWwdDDuiSSGrfkwGetXL6Y3muRIT5Sk7e6yS9dtKPS5hCgGCcA1aLg6Clqf6vUG0Bj04lGjZ24pIKuFG4ZS3LJpBx+/bzvfeHTvoF1yccvhyQPd+IfZrtta7yNhOyMW3pmoNcvcqRCPodC4i3vzWoI0Br1SuUxUBZmCqEHrVy/OzAHrVB6Yo6HB524LjiQs+qIJornly3Jkf9VjKGY1BTANlcklHk66xkIklWLmMRUDCZuZTcGitGvvj1uc0dYwqJ2R1rqm5oGlOHztkhFwDVqzrI2vX3MuZ7TWo5Rb0WtJWwN3r7uAr11zLm2hQKYmwkh8WT8ZAY87sgwF3DZE9khb5FIsR2fygC1bE0914yzGAtn8ljqiycH5xLXUlTidDdLeH6M56KW9P1bwdxKifGQEXKNGWsDSWrNibhMXfenREZ8b9BrMbgrQGU7QGvIPabluGmrUIOzm8J7ahOGk5kKKERjXr17MLZt2EElYg7pX1Erdhuz6GAB1Pk9R3kmI8pAAPIU4juZEf4z+6Oij3+Y6L5bj5unev/3IkOC29pxZPPDcsRGfnz0i1bhvs4Zr116It9ZrlrUN6mOXTnEDBnVurta37ZJqV9skAE8Rlu1wvC9GR1+cv/2f50d8nKFg4fSGTMA6Z17zsLm4i2bs4V8e2zukXGUut2C7oi0UGBQEs0tPZr+1vgPGFSg3727n/u1HaA35WZD6JfH9ra+geIXGoHdSr10JsutjpNXSFMtUJ/WAp4C4ZXOiN85Lx/u4+cEdmUpmuQzgOx+4aFxBKr0b7XhvjHjSzrQlSjfzNJRiw/suHPKaI+1iS9cGHu/5s19nb3s/aFgyMzSp164E0iC0Zkhb+qkomrA50Rfj17tO8A+/fCmzIKYAj+HO1zq4Pd+CXiOzDTjfqYH0W+R0HznlaOzUVuPs1xzpedkm8tZ6uNexHU3uwKJa37bnsyNQVC8JwDWsP5bkRF+cex7fz31PHwLcmg/K0CgNSik0irnNgcw0wXinBtJvkX2mgWVrPKaBoXUmba0tFBj22gr11nq41zENBXrwgKOa37ZLaczaJWloNaonkuBAxwCfe+CPmeDb4PfQXGdipHa2JW23s/Hx3lhmgezOh3fT3hfj1ZMRDnQOYDt61Lbv6RKSoYAHB+2WeHQ0jUHPqNkI2aUntdYjLtKt27iVy+58jHUbtw6bejXc6zT4PYQCnlFfW4hKIAG4BnWG4zz7ajcf+eF2njpwEoB3XTAXjwG9EQtlGKmeaG5nClu7c4oAe9rDONptZmk5mqM9MSzbGfHte7qE5KIZDTQFPAS9Jk11XhZObxh1nnKsrhP55r8O9zpfv+bcTL6zdLQQlUwW4WqI42ja++M8svM4X3loN5GEjddUfOKNS7nqNXO46u4txCwnsx0Z3NoQQa/JC7e9mXUbt/LsoW60Q6aIj6PdoujnLxh/MZ3JKNQinRAVQhbhapllOxztjfKfTxzkP39/EHCbYoYCHh7ZeYIz20L4PAYxy50iyLRbB3ypwuuHuiPMDPk52hsDh9RjNJae3Nv3ieT7Sv6rmApkCqIGxC2bl9vDfP6BFwcF39YGf+Zt+G0/20lbKMD0eh8eU2FrjcdUTK/3sWRmI+AuaHlMgzlNwcxjDEOxpLVhwm/fJ7qVtta3GAsBRQzASqnvKKXalVIvFuscwk0z23awmw//9zM8vrcTgOn1PmY1+mmp8+E1Dep8HrymQmuNzzO43brPc6rdenpBy2MqFs2oZ8G0OtpCAT7zlrMmfH25rebT1zJWtbJ8FumEqHbFHAF/F7iyiK8/5fXHkvzshaN8+L+f4WBXBNNQ3HTFErweRWPAm5nHBfft+0DCHnXhqxjt2LNbzWdfy1hTCdIaXkwFRZsD1lpvUUotLNbrT3Unw3E2bNnPfzy+H0dDS52XW9++nNVL2/jD/pOpBaxTv1/Tb9/HyiktdM7pZPJ9Jf9V1LqyL8Ippa4HrgdYsGBBma+m8mmtOdQd4fZNO/l1ah516cwGvvSOs1kxt4k6n4f1qxfzqfuf50h3FMtxsx5CAQ83X7Wcy77yKId745nXm9fk54nPXlG06631amVCTEbZF+G01hu11iu11itbW1vLfTkVzXY0z77awwe/uy0TfN+4fCYb3nch5y9oGTTKTLcCUkpBqvPF3/742UHBF+Bwb5zLvjJyacrJkqkEIUZW9hGwyE/Sdnj4xePc/JMX6Ym63Y7Xv/50PnTZIqY3+Ac9dsOW/TQFvcxuCmaORRIW+zoGhn3t3KBcaDKVIMTwJABXgWiqAPe/PPYytqNpDHi49e3Leetr5hD0mUMeP1IOrRCishQtACul7gXWADOUUoeBW7XW3y7W+WpVVzjOLQ/u4Od/dAugL55Rz53XnMP585vxmMPPII3Url0IUVmKmQWxrlivPVXsOd7PTT96jp3H+gBYvWQGX37Xa8bMIMhuymm4U8BY9shbzuc1+Uf8mhCieGQKogJprfnN7nY+df8LdA0kUMBfXraQT7xxKfV+75jPT7drD8csbK3xmQb1PpPOcILhGlj8/TvPKfg9CCHGJgG4wtiO5ttP7Odrv3yJpK2p95ncunYF7zx/Lt4RphyG0x+3mNnopzOcIGE7RAfsTPDNnozQwJ0P75ZFMiHKQAJwBQnHk9z64A7+d/sRAOa1BPnn95zHhae1uOlk4xDye9jbHnY7GNt60Mg3dzJif+fw2RFCiOKSAFwhjnZH+cgPt/PcoR4ALlk8jX96z3mDUsnGI11mNGk5w047CCHKTwJwBXjqQBd/c++znOhz83H/36rT+Nxbzho2xSxfnQMJDDRWHo9dNF0qjAlRDhKAy+zeP7zCbT/dSdxyCHgMbl27nGsvWjDuKYdsm3e30x+z0EoxdMJhqMlUOxNCTFzNBuCJFAEvpaTl8MWf7+T7T74CwKzGAP/63vNZuXDapF97w5b91PkMeiJjj39H6loshCi+mgzA4+3sW2pd4Tgf+cF2/pDq13bhaS1887rzmdU4sfneXHvb++mNWHmMfeGvX396Qc4phBi/shfjKYaJFgEvhReP9LL2X3+XCb7rLp7PvR96bcGCL0B/zMpr4c1rwA1XLC3YeYUQ41OTI+BK7Sf20+eP8nf3v0A06TbLvPVtK3jfqtMKfp64lV/ew99cvqTg5xZC5K8mA/B4ioCXYq7YcTRf++Vu/u237gi8NeTnW9ddwEUFmO+dKAM4Z15z2c4vhKjRAJxvEfCR5oqvOdzDk/tPFiQo98eSfOyHz/LbPR0AvGZuE//x/pXMagpM+j5HEvQaRJPDj4LTeREzm/xs2LK/IubEhZiqajIAr1nWxh24c8GHuyPMGyGIZs8VA9T5PHT0x/jm5n3MawnmtYA32gh6X0eYD35vGwdTO83+vwvm8pV3nYPPU9yp9/PmNfHkge7hv6ggYBpMr/eXfUpGiKmuJgMw5FcEfLi54v6YheU4g4JyJFWPN/f1Rsu2sLTDTfc9Tzhu4TEUn7/qLP7i0kUFvceR7DjWP+LXTKWY1RSQFu9CVICaDcD5GG6uOG45+E2DvmgyU0vXAF7tinDZnY8NGuUON4IeiCe5+cEXOdITxdEwrd7HN997PqtOn1Gy+xpI2CgFepg8NMtxawRPq/dLXzYhyqwm09DytX71YpK2JpKw0Nr9aBoKv9fgaG/UraGrNXFbk3Q0piIzyt28u31Iy3XH0XSGExzqdoPvWbND/PRjl5Y0+ALU+8xhg29aOG4zt8kv879ClNmUDsDZDSOP90bp6I/jMxU9UQtHa5QBViqQeU1FZzgxKKd4fksd0aQNQDxp83JHmL6Yu/vsbefM5oGPXMrcMrzN/9BlY091PPVKT/EvRAgxqikdgMENwutXL6bO76U15Oe06fUowHZSXSQ0eA2FaSgStptZkM4pTo+gO/tj7OsIZ/Jv333hPP5l3fls3dfFuo1buezOx1i3cSubU52Mi+2GK5byzvNmM1w1ifQx28lnn5wQopiUHu29aomtXLlSb9u2reTnXbdx66C54P0dYRK2gy9VAN2yNSjwGIrFrQ1EEhZeQ9Fc5+OFwz1EUilfhoK5TQG0UjT4TLoGEjQGvYNS4UrZkn3z7nY+8N2nM5+r1H+0BtNQ7PvyW0tyHUKIYcdDU3MRLjd1bG97P7MaT+Xlzmjwc7gnwkDCxgAcwFQwqzFIJGHRG02C1hzuiWaCr6mgMeDB5zUJek1e7ghj2Zp6/6nt0CNlUxTLmmVtvPO82TzwnNvQU2f+A2vPmVWSaxBCjGzKBeC7H93DNzfvw3LcbAfbceiPWXjNODMaTgVh7bgjWtNQmFqDUgwkbJa01YHWHOyKkNvnMpo8lb6WsBwcDQe7IhgKWhv8tIZKn3v7T9deAGxn0wvHsR2NaSjWnjMrdVwIUU5TKgBv3t3ONzfvw9Ear2lga+gKJ6n3G5wcSFLn8xD0mpzoj2EYinktQUIBN084krBoCwX4+BuX8J4NW4dUGrM1OKk54OO9bhZEmqPhRH+cpO1w5qzGEt3tKf907QX807UlP60QYgxTahFuw5b97ihQKRQKQymUgnjSIeQ3aQsF6I0m0RrmNgcywRfchbddx3q57p4/jFjmMX28cyAx7Ne7I0nJvRVCZNTsCHi4LcKHuiP4PQaWrUk3nFDKnTrQwPZX3e272RkPfdEkHf2xzGPG4uYUD/81TWXUIxZCVIaaCcDZARfH4UQ4gaN1Zp73lk07CPk9WLZD10ACHDf4Jmw3sMYtB61PjWIjCZv2vjiOHtzUJ+AxiI1S7rEtFGBfh3QZFkKMrSamINI1Gdr7Y5gKjvTGSdruVEPCdjjeG+dId4SDXQPYjmZ6vQ+PqbAcjcbNYMgNtODO62Yf8xjQFBz9d9a9118y4je1Jr7ZQoiCqeoRcHrU+/TBk5kVfjsVVAESWWkKtoZY0qHeDy11PrymwbxUClpXePg521yWM/L8bralMxvYfSI87PFyqfQeeUJMRVU7KEuPeg90hjMjWSsr+A5H49ZraK7z8finL2fV4ml0R5J5ze2m2aM0m1i1qAVwuwzPaPAR8Bp4TUXAazCjwVe27sPZ7xCyq7aVameeEGJ4VbsTLr177XhvjEjCHlcQNQ3F7JCPI73xcT0vzWsoVp7WPKjm7qpFLdy7/nWZz9MjztHqEZdK7k4/OJVWd+/1l5TlmoSYYmprJ1y6lm/Myi87IZvtaA73xid0Xo8BhqFY//ozQA1+S58tHWzTb/vTDUHLEYQrtUeeEFNd1U5BzG+pozMcxylxURmtobXeO+Zb+kp6259dtS1NCrILUX5VOwJev3oxf/Vf2yY0hTAZtoaYrWnyufUd0oXb45bDX//gGRZOr6c/btEXTVLvN2kKutuby1ELIi3fHnlCiNKq2gAMpS+pqHDrQ3SGExjA4ZMR4rZGpb4WdTR728PMbQ4QSdhEEzZ+j5nZUVeut/359sgTQpRW1QbgDVv24/MYbtEcw53fTto2o+yRKIh0yG8PJzK76cCtmAbuAl9nOIHfY5CwHTr645kAXM63/fn0yBNClFbVzgEf6o4wM+THQeM4Gq01hhp2obFgNAwqsjNcAkl6d92MBj8AMcvOtDuSt/1CiGxVG4Dnt9ThMQ3mNAXxmApbawxDUZfVo63YjKx6EunQrzX4TIPGoJfp9T7qfR56o0naQoGSFmMXQlS+qp2CSC8seU3Fohn1mYWlk+FYya7BaygcwEBhOQ62duelZzX6iSQsfB6Tr77rHAm6QohhVe0IOLuhZnqEObfJTzhR5EngLJajmdMUQBmAUsxrDrCkrQFHIyNeIcSYqnYEDIMXlnL7nxXLoFlmpXA0nD+/RbIKhBDjVtUBOFt6p1kpmIZbyL0p4OHxT19esvMKIWpLzQTgQyXIr633mZluyaGAh0UzylfdTAhR/WomAM9tDnK4O1q01zcNmNUUkJ1kQoiCKeoinFLqSqXUS0qpl5VSnynWefpiSS5Y0FyU11ZAo9/kxsuXDFrwkwU2IcRkFW0ErJQygW8CbwQOA08rpTZprXcW8jzRhM33f3+Qe544UMiXxWMoZjcFBm3bvaGgZxBCTHXFnIK4GHhZa70fQCl1H3A1ULAAnLQd7vjZDu596hAAp02rY+VpLfxq53H64/YYz3b7u7U1ymhWCFEexQzAc4FDWZ8fBl5byBN84YEX+dE29xSrFk/ntrXLOb21gX80z8uUg0xYNu398cwWYgN3S7FSsGhGPZ++cpkEXyFEWRQzAA9XmGFI9QSl1PXA9QALFiwY1wmuf/1ifvHiMd5x3hw+vOZ0ZjcGM4V5siuAWbbDQMLGctx6EYsl8AohKkDRWhIppVYBt2mt35z6/LMAWuuvjPSc8bQkSjvcHcHnMWht8KOKXIxHCCEmqOQtiZ4GliilFgFHgGuB9xb6JHOaTo16hRCimhQtAGutLaXUx4BfAibwHa31jkKfR4KvEKJaFXUjhtb6F8AvinkOIYSoVlVbDU0IIaqdBGAhhCgTCcBCCFEmEoCFEKJMJAALIUSZSAAWQogykQAshBBlIgFYCCHKRAKwEEKUiQRgIYQoEwnAQghRJkUrRzkRSqkO4JVyX0cRzAA6y30RJSb3PDXIPeenU2t9Ze7BigrAtUoptU1rvbLc11FKcs9Tg9zz5MgUhBBClIkEYCGEKBMJwKWxsdwXUAZyz1OD3PMkyBywEEKUiYyAhRCiTCQACyFEmUgALgCl1HeUUu1KqRezjk1TSj2ilNqb+tiS9bXPKqVeVkq9pJR6c3mueuKUUvOVUr9RSu1SSu1QSt2YOl7L9xxQSj2llHo+dc+3p47X7D2nKaVMpdSzSqmfpT6v6XtWSh1USv1RKfWcUmpb6lhx7llrLX8m+QdYDVwAvJh17B+Az6T+/hngztTflwPPA35gEbAPMMt9D+O839nABam/h4A9qfuq5XtWQEPq717gD8AltXzPWff+CeCHwM9Sn9f0PQMHgRk5x4pyzzICLgCt9RbgZM7hq4Hvpf7+PeAdWcfv01rHtdYHgJeBi0txnYWitT6mtd6e+ns/sAuYS23fs9Zah1OfelN/NDV8zwBKqXnAVcA9WYdr+p5HUJR7lgBcPDO11sfADVhAW+r4XOBQ1uMOp45VJaXUQuB83BFhTd9z6q34c0A78IjWuubvGfhn4O8AJ+tYrd+zBn6llHpGKXV96lhR7tlTgIsV46OGOVaVuYBKqQbgf4GbtNZ9Sg13a+5DhzlWdfestbaB85RSzcADSqmzR3l41d+zUuptQLvW+hml1Jp8njLMsaq655RLtdZHlVJtwCNKqd2jPHZS9ywj4OI5oZSaDZD62J46fhiYn/W4ecDREl/bpCmlvLjB9wda6/9LHa7pe07TWvcAm4Erqe17vhRYq5Q6CNwHXK6U+m9q+57RWh9NfWwHHsCdUijKPUsALp5NwJ+n/v7nwINZx69VSvmVUouAJcBTZbi+CVPuUPfbwC6t9TeyvlTL99yaGvmilAoCVwC7qeF71lp/Vms9T2u9ELgWeExr/T5q+J6VUvVKqVD678CbgBcp1j2Xe8WxFv4A9wLHgCTub8QPAtOBXwN7Ux+nZT3+87irpS8Bbyn39U/gfi/DfZv1AvBc6s9ba/yezwGeTd3zi8AtqeM1e88597+GU1kQNXvPwGLcrIbngR3A54t5z7IVWQghykSmIIQQokwkAAshRJlIABZCiDKRACyEEGUiAVgIIcpEArAQQpSJBGAx5SilzHJfgxAgAVjUIKXUT1KFVHaki6kopcJKqTuUUn8AViml3peq7/ucUmpDOigrpf5NKbUtu+avEMUiAVjUor/UWl8IrARuUEpNB+px6zW/FugC3oNbdOU8wAauSz3381rrlbg7316vlDqn5FcvpgyphiZq0Q1KqXem/j4fd3++jVs8COBPgQuBp1MV3IKcKq7yZ6lRswe38Pxy3O3HQhScBGBRU1JlE68AVmmtI0qpzUAAiGm3nCS4JQS/p7X+bM5zFwGfBC7SWncrpb6beq4QRSFTEKLWNAHdqeC7DLdtUK5fA9ek6r2m+32dBjQCA0CvUmom8JZSXbSYmmQELGrNw8CHlVIv4Fan2pr7AK31TqXUF3C7Hhi4Vew+qrXeqpR6FrcK1n7gdyW8bjEFSTU0IYQoE5mCEEKIMpEALIQQZSIBWAghykQCsBBClIkEYCGEKBMJwEIIUSYSgIUQokz+f+/ZAlzhFSiEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x='area', y='preco', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fec7f569070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x='condominio', y='preco', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>condominio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>400</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>434</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>450</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>450</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>498</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  condominio\n",
       "0      33         300\n",
       "1      33         500\n",
       "2      35         200\n",
       "3      36         300\n",
       "4      36         200\n",
       "..    ...         ...\n",
       "465   400        2800\n",
       "466   434        2200\n",
       "467   450        3000\n",
       "468   450        2700\n",
       "469   498        2100\n",
       "\n",
       "[470 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = df.drop('preco', axis=1)\n",
    "y_df = df['preco']\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_df.to_numpy()\n",
    "y = y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim = 2, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 1742480998400.0000 - val_loss: 2029099155456.0000\n",
      "Epoch 2/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1742434598912.0000 - val_loss: 2029048430592.0000\n",
      "Epoch 3/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742388854784.0000 - val_loss: 2028998623232.0000\n",
      "Epoch 4/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742346387456.0000 - val_loss: 2028949602304.0000\n",
      "Epoch 5/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742302740480.0000 - val_loss: 2028901367808.0000\n",
      "Epoch 6/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742259486720.0000 - val_loss: 2028853264384.0000\n",
      "Epoch 7/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742217543680.0000 - val_loss: 2028807127040.0000\n",
      "Epoch 8/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742176649216.0000 - val_loss: 2028761907200.0000\n",
      "Epoch 9/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1742137196544.0000 - val_loss: 2028718129152.0000\n",
      "Epoch 10/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742098792448.0000 - val_loss: 2028676448256.0000\n",
      "Epoch 11/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742062878720.0000 - val_loss: 2028633849856.0000\n",
      "Epoch 12/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1742024736768.0000 - val_loss: 2028594790400.0000\n",
      "Epoch 13/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741990264832.0000 - val_loss: 2028554813440.0000\n",
      "Epoch 14/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741955399680.0000 - val_loss: 2028516802560.0000\n",
      "Epoch 15/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741921976320.0000 - val_loss: 2028478267392.0000\n",
      "Epoch 16/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741887635456.0000 - val_loss: 2028441829376.0000\n",
      "Epoch 17/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741855653888.0000 - val_loss: 2028406833152.0000\n",
      "Epoch 18/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741825507328.0000 - val_loss: 2028371836928.0000\n",
      "Epoch 19/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741793787904.0000 - val_loss: 2028338020352.0000\n",
      "Epoch 20/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1741764689920.0000 - val_loss: 2028305383424.0000\n",
      "Epoch 21/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1741735854080.0000 - val_loss: 2028273795072.0000\n",
      "Epoch 22/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741707804672.0000 - val_loss: 2028243386368.0000\n",
      "Epoch 23/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741680672768.0000 - val_loss: 2028212846592.0000\n",
      "Epoch 24/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741654327296.0000 - val_loss: 2028183093248.0000\n",
      "Epoch 25/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741627981824.0000 - val_loss: 2028154519552.0000\n",
      "Epoch 26/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741601898496.0000 - val_loss: 2028126076928.0000\n",
      "Epoch 27/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741577650176.0000 - val_loss: 2028098158592.0000\n",
      "Epoch 28/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1741552877568.0000 - val_loss: 2028071813120.0000\n",
      "Epoch 29/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1741530071040.0000 - val_loss: 2028045336576.0000\n",
      "Epoch 30/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1741507002368.0000 - val_loss: 2028020826112.0000\n",
      "Epoch 31/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1741484982272.0000 - val_loss: 2027996839936.0000\n",
      "Epoch 32/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741463224320.0000 - val_loss: 2027973771264.0000\n",
      "Epoch 33/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741442646016.0000 - val_loss: 2027948998656.0000\n",
      "Epoch 34/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741421805568.0000 - val_loss: 2027926585344.0000\n",
      "Epoch 35/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741402144768.0000 - val_loss: 2027905351680.0000\n",
      "Epoch 36/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741383270400.0000 - val_loss: 2027884904448.0000\n",
      "Epoch 37/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741365051392.0000 - val_loss: 2027864457216.0000\n",
      "Epoch 38/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741347356672.0000 - val_loss: 2027844272128.0000\n",
      "Epoch 39/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1741329399808.0000 - val_loss: 2027824742400.0000\n",
      "Epoch 40/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741312098304.0000 - val_loss: 2027805212672.0000\n",
      "Epoch 41/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741295321088.0000 - val_loss: 2027786207232.0000\n",
      "Epoch 42/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741278543872.0000 - val_loss: 2027768119296.0000\n",
      "Epoch 43/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741262684160.0000 - val_loss: 2027751211008.0000\n",
      "Epoch 44/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741247348736.0000 - val_loss: 2027734040576.0000\n",
      "Epoch 45/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741232930816.0000 - val_loss: 2027717132288.0000\n",
      "Epoch 46/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741218250752.0000 - val_loss: 2027701403648.0000\n",
      "Epoch 47/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741203963904.0000 - val_loss: 2027686199296.0000\n",
      "Epoch 48/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741190725632.0000 - val_loss: 2027670732800.0000\n",
      "Epoch 49/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1741177356288.0000 - val_loss: 2027656052736.0000\n",
      "Epoch 50/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741163986944.0000 - val_loss: 2027642028032.0000\n",
      "Epoch 51/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741151272960.0000 - val_loss: 2027628658688.0000\n",
      "Epoch 52/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741139738624.0000 - val_loss: 2027615289344.0000\n",
      "Epoch 53/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1741128204288.0000 - val_loss: 2027602444288.0000\n",
      "Epoch 54/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1741116669952.0000 - val_loss: 2027589599232.0000\n",
      "Epoch 55/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1741105397760.0000 - val_loss: 2027577016320.0000\n",
      "Epoch 56/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741094387712.0000 - val_loss: 2027564826624.0000\n",
      "Epoch 57/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741084164096.0000 - val_loss: 2027553030144.0000\n",
      "Epoch 58/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741073416192.0000 - val_loss: 2027541364736.0000\n",
      "Epoch 59/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741062930432.0000 - val_loss: 2027530092544.0000\n",
      "Epoch 60/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741053362176.0000 - val_loss: 2027519213568.0000\n",
      "Epoch 61/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741043662848.0000 - val_loss: 2027508727808.0000\n",
      "Epoch 62/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741034225664.0000 - val_loss: 2027498504192.0000\n",
      "Epoch 63/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741025050624.0000 - val_loss: 2027488280576.0000\n",
      "Epoch 64/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1741016006656.0000 - val_loss: 2027477794816.0000\n",
      "Epoch 65/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1741006831616.0000 - val_loss: 2027467833344.0000\n",
      "Epoch 66/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740997918720.0000 - val_loss: 2027457478656.0000\n",
      "Epoch 67/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740989136896.0000 - val_loss: 2027447123968.0000\n",
      "Epoch 68/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740979699712.0000 - val_loss: 2027437293568.0000\n",
      "Epoch 69/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740970786816.0000 - val_loss: 2027427594240.0000\n",
      "Epoch 70/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740961611776.0000 - val_loss: 2027416584192.0000\n",
      "Epoch 71/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740952174592.0000 - val_loss: 2027406098432.0000\n",
      "Epoch 72/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740943261696.0000 - val_loss: 2027395612672.0000\n",
      "Epoch 73/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740933693440.0000 - val_loss: 2027385913344.0000\n",
      "Epoch 74/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740924649472.0000 - val_loss: 2027375165440.0000\n",
      "Epoch 75/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740915081216.0000 - val_loss: 2027364548608.0000\n",
      "Epoch 76/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740905906176.0000 - val_loss: 2027353538560.0000\n",
      "Epoch 77/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740895682560.0000 - val_loss: 2027342135296.0000\n",
      "Epoch 78/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740885327872.0000 - val_loss: 2027330732032.0000\n",
      "Epoch 79/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740875366400.0000 - val_loss: 2027318804480.0000\n",
      "Epoch 80/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740864094208.0000 - val_loss: 2027306876928.0000\n",
      "Epoch 81/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740853346304.0000 - val_loss: 2027294294016.0000\n",
      "Epoch 82/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740842467328.0000 - val_loss: 2027281973248.0000\n",
      "Epoch 83/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740831326208.0000 - val_loss: 2027269128192.0000\n",
      "Epoch 84/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740819660800.0000 - val_loss: 2027255496704.0000\n",
      "Epoch 85/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740807340032.0000 - val_loss: 2027241472000.0000\n",
      "Epoch 86/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740795019264.0000 - val_loss: 2027227185152.0000\n",
      "Epoch 87/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740781256704.0000 - val_loss: 2027212242944.0000\n",
      "Epoch 88/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740767887360.0000 - val_loss: 2027195727872.0000\n",
      "Epoch 89/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740752945152.0000 - val_loss: 2027179081728.0000\n",
      "Epoch 90/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740737478656.0000 - val_loss: 2027161255936.0000\n",
      "Epoch 91/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740721750016.0000 - val_loss: 2027142643712.0000\n",
      "Epoch 92/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740704841728.0000 - val_loss: 2027122720768.0000\n",
      "Epoch 93/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1740686884864.0000 - val_loss: 2027101356032.0000\n",
      "Epoch 94/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740667879424.0000 - val_loss: 2027079598080.0000\n",
      "Epoch 95/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740647825408.0000 - val_loss: 2027057446912.0000\n",
      "Epoch 96/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740627247104.0000 - val_loss: 2027033985024.0000\n",
      "Epoch 97/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1740605882368.0000 - val_loss: 2027008950272.0000\n",
      "Epoch 98/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740583206912.0000 - val_loss: 2026982342656.0000\n",
      "Epoch 99/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740558958592.0000 - val_loss: 2026953768960.0000\n",
      "Epoch 100/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740533268480.0000 - val_loss: 2026923753472.0000\n",
      "Epoch 101/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1740506136576.0000 - val_loss: 2026893344768.0000\n",
      "Epoch 102/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740477825024.0000 - val_loss: 2026860969984.0000\n",
      "Epoch 103/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1740447416320.0000 - val_loss: 2026825187328.0000\n",
      "Epoch 104/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1740415696896.0000 - val_loss: 2026787176448.0000\n",
      "Epoch 105/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1740381487104.0000 - val_loss: 2026749296640.0000\n",
      "Epoch 106/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740346621952.0000 - val_loss: 2026708402176.0000\n",
      "Epoch 107/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740310052864.0000 - val_loss: 2026663837696.0000\n",
      "Epoch 108/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740268503040.0000 - val_loss: 2026618617856.0000\n",
      "Epoch 109/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740228657152.0000 - val_loss: 2026570383360.0000\n",
      "Epoch 110/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740185010176.0000 - val_loss: 2026519920640.0000\n",
      "Epoch 111/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740138610688.0000 - val_loss: 2026468933632.0000\n",
      "Epoch 112/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1740091293696.0000 - val_loss: 2026413096960.0000\n",
      "Epoch 113/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1740041224192.0000 - val_loss: 2026353590272.0000\n",
      "Epoch 114/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739987877888.0000 - val_loss: 2026291200000.0000\n",
      "Epoch 115/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739930468352.0000 - val_loss: 2026227892224.0000\n",
      "Epoch 116/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739872403456.0000 - val_loss: 2026157899776.0000\n",
      "Epoch 117/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739808702464.0000 - val_loss: 2026086072320.0000\n",
      "Epoch 118/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1739743690752.0000 - val_loss: 2026015686656.0000\n",
      "Epoch 119/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739679203328.0000 - val_loss: 2025941106688.0000\n",
      "Epoch 120/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739613143040.0000 - val_loss: 2025860497408.0000\n",
      "Epoch 121/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739540135936.0000 - val_loss: 2025779625984.0000\n",
      "Epoch 122/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1739467653120.0000 - val_loss: 2025694167040.0000\n",
      "Epoch 123/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1739390582784.0000 - val_loss: 2025606086656.0000\n",
      "Epoch 124/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1739312201728.0000 - val_loss: 2025517350912.0000\n",
      "Epoch 125/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1739229626368.0000 - val_loss: 2025424289792.0000\n",
      "Epoch 126/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739147182080.0000 - val_loss: 2025327427584.0000\n",
      "Epoch 127/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1739059101696.0000 - val_loss: 2025226108928.0000\n",
      "Epoch 128/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1738967482368.0000 - val_loss: 2025121775616.0000\n",
      "Epoch 129/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738872455168.0000 - val_loss: 2025016655872.0000\n",
      "Epoch 130/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738778214400.0000 - val_loss: 2024908128256.0000\n",
      "Epoch 131/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1738681352192.0000 - val_loss: 2024794357760.0000\n",
      "Epoch 132/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1738577281024.0000 - val_loss: 2024677572608.0000\n",
      "Epoch 133/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738471636992.0000 - val_loss: 2024555937792.0000\n",
      "Epoch 134/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738364289024.0000 - val_loss: 2024434565120.0000\n",
      "Epoch 135/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738256023552.0000 - val_loss: 2024309784576.0000\n",
      "Epoch 136/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1738146709504.0000 - val_loss: 2024181858304.0000\n",
      "Epoch 137/2000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1738029268992.0000 - val_loss: 2024051834880.0000\n",
      "Epoch 138/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1737911697408.0000 - val_loss: 2023916699648.0000\n",
      "Epoch 139/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1737795436544.0000 - val_loss: 2023780777984.0000\n",
      "Epoch 140/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1737670000640.0000 - val_loss: 2023649181696.0000\n",
      "Epoch 141/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1737549807616.0000 - val_loss: 2023502905344.0000\n",
      "Epoch 142/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1737418866688.0000 - val_loss: 2023358857216.0000\n",
      "Epoch 143/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1737290153984.0000 - val_loss: 2023206420480.0000\n",
      "Epoch 144/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1737147678720.0000 - val_loss: 2023049003008.0000\n",
      "Epoch 145/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1737009266688.0000 - val_loss: 2022899187712.0000\n",
      "Epoch 146/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736877539328.0000 - val_loss: 2022740852736.0000\n",
      "Epoch 147/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736739258368.0000 - val_loss: 2022583828480.0000\n",
      "Epoch 148/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736598749184.0000 - val_loss: 2022431784960.0000\n",
      "Epoch 149/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736461910016.0000 - val_loss: 2022273318912.0000\n",
      "Epoch 150/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736321138688.0000 - val_loss: 2022105677824.0000\n",
      "Epoch 151/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1736171323392.0000 - val_loss: 2021940789248.0000\n",
      "Epoch 152/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1736020459520.0000 - val_loss: 2021781405696.0000\n",
      "Epoch 153/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735879032832.0000 - val_loss: 2021609963520.0000\n",
      "Epoch 154/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735726071808.0000 - val_loss: 2021438390272.0000\n",
      "Epoch 155/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735572717568.0000 - val_loss: 2021264719872.0000\n",
      "Epoch 156/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735420149760.0000 - val_loss: 2021091049472.0000\n",
      "Epoch 157/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735261814784.0000 - val_loss: 2020917510144.0000\n",
      "Epoch 158/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1735108067328.0000 - val_loss: 2020736237568.0000\n",
      "Epoch 159/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1734947110912.0000 - val_loss: 2020551688192.0000\n",
      "Epoch 160/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1734782353408.0000 - val_loss: 2020368973824.0000\n",
      "Epoch 161/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1734614581248.0000 - val_loss: 2020181409792.0000\n",
      "Epoch 162/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1734448775168.0000 - val_loss: 2019986505728.0000\n",
      "Epoch 163/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1734279036928.0000 - val_loss: 2019793567744.0000\n",
      "Epoch 164/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1734104842240.0000 - val_loss: 2019605086208.0000\n",
      "Epoch 165/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1733931696128.0000 - val_loss: 2019403759616.0000\n",
      "Epoch 166/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1733749899264.0000 - val_loss: 2019211214848.0000\n",
      "Epoch 167/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1733579374592.0000 - val_loss: 2019008708608.0000\n",
      "Epoch 168/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1733397839872.0000 - val_loss: 2018808168448.0000\n",
      "Epoch 169/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1733215780864.0000 - val_loss: 2018597273600.0000\n",
      "Epoch 170/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1733029658624.0000 - val_loss: 2018382577664.0000\n",
      "Epoch 171/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1732840652800.0000 - val_loss: 2018171944960.0000\n",
      "Epoch 172/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1732648501248.0000 - val_loss: 2017962622976.0000\n",
      "Epoch 173/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1732463296512.0000 - val_loss: 2017739145216.0000\n",
      "Epoch 174/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1732264984576.0000 - val_loss: 2017520386048.0000\n",
      "Epoch 175/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1732069031936.0000 - val_loss: 2017310015488.0000\n",
      "Epoch 176/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1731879239680.0000 - val_loss: 2017087979520.0000\n",
      "Epoch 177/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1731679748096.0000 - val_loss: 2016859389952.0000\n",
      "Epoch 178/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1731481567232.0000 - val_loss: 2016633290752.0000\n",
      "Epoch 179/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1731279716352.0000 - val_loss: 2016410730496.0000\n",
      "Epoch 180/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1731080880128.0000 - val_loss: 2016188301312.0000\n",
      "Epoch 181/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1730881781760.0000 - val_loss: 2015961677824.0000\n",
      "Epoch 182/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1730678226944.0000 - val_loss: 2015740821504.0000\n",
      "Epoch 183/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1730483585024.0000 - val_loss: 2015511445504.0000\n",
      "Epoch 184/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1730283700224.0000 - val_loss: 2015279448064.0000\n",
      "Epoch 185/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1730075951104.0000 - val_loss: 2015056494592.0000\n",
      "Epoch 186/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1729869905920.0000 - val_loss: 2014820827136.0000\n",
      "Epoch 187/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1729661632512.0000 - val_loss: 2014585683968.0000\n",
      "Epoch 188/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1729451917312.0000 - val_loss: 2014350147584.0000\n",
      "Epoch 189/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1729244954624.0000 - val_loss: 2014104125440.0000\n",
      "Epoch 190/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1729028030464.0000 - val_loss: 2013869375488.0000\n",
      "Epoch 191/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1728820805632.0000 - val_loss: 2013625974784.0000\n",
      "Epoch 192/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1728603619328.0000 - val_loss: 2013397516288.0000\n",
      "Epoch 193/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1728394559488.0000 - val_loss: 2013163814912.0000\n",
      "Epoch 194/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1728185892864.0000 - val_loss: 2012921987072.0000\n",
      "Epoch 195/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1727976570880.0000 - val_loss: 2012676489216.0000\n",
      "Epoch 196/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1727753617408.0000 - val_loss: 2012427583488.0000\n",
      "Epoch 197/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1727533678592.0000 - val_loss: 2012183134208.0000\n",
      "Epoch 198/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1727315705856.0000 - val_loss: 2011942092800.0000\n",
      "Epoch 199/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1727091048448.0000 - val_loss: 2011685584896.0000\n",
      "Epoch 200/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1726869405696.0000 - val_loss: 2011430912000.0000\n",
      "Epoch 201/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1726641864704.0000 - val_loss: 2011185807360.0000\n",
      "Epoch 202/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1726421270528.0000 - val_loss: 2010943062016.0000\n",
      "Epoch 203/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1726204608512.0000 - val_loss: 2010677510144.0000\n",
      "Epoch 204/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1725973921792.0000 - val_loss: 2010413793280.0000\n",
      "Epoch 205/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1725737861120.0000 - val_loss: 2010164101120.0000\n",
      "Epoch 206/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1725507960832.0000 - val_loss: 2009907331072.0000\n",
      "Epoch 207/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1725280157696.0000 - val_loss: 2009635356672.0000\n",
      "Epoch 208/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1725048684544.0000 - val_loss: 2009364037632.0000\n",
      "Epoch 209/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1724806070272.0000 - val_loss: 2009106350080.0000\n",
      "Epoch 210/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1724572368896.0000 - val_loss: 2008847482880.0000\n",
      "Epoch 211/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1724338012160.0000 - val_loss: 2008577998848.0000\n",
      "Epoch 212/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1724098936832.0000 - val_loss: 2008307728384.0000\n",
      "Epoch 213/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1723855929344.0000 - val_loss: 2008037588992.0000\n",
      "Epoch 214/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1723618557952.0000 - val_loss: 2007760109568.0000\n",
      "Epoch 215/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1723373584384.0000 - val_loss: 2007491018752.0000\n",
      "Epoch 216/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1723128610816.0000 - val_loss: 2007204233216.0000\n",
      "Epoch 217/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1722873282560.0000 - val_loss: 2006927671296.0000\n",
      "Epoch 218/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1722623983616.0000 - val_loss: 2006640754688.0000\n",
      "Epoch 219/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1722371670016.0000 - val_loss: 2006358163456.0000\n",
      "Epoch 220/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1722119749632.0000 - val_loss: 2006079504384.0000\n",
      "Epoch 221/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1721864290304.0000 - val_loss: 2005800845312.0000\n",
      "Epoch 222/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1721622855680.0000 - val_loss: 2005503705088.0000\n",
      "Epoch 223/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1721354944512.0000 - val_loss: 2005223342080.0000\n",
      "Epoch 224/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1721107218432.0000 - val_loss: 2004936556544.0000\n",
      "Epoch 225/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1720849793024.0000 - val_loss: 2004652392448.0000\n",
      "Epoch 226/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1720608227328.0000 - val_loss: 2004365606912.0000\n",
      "Epoch 227/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1720350146560.0000 - val_loss: 2004093632512.0000\n",
      "Epoch 228/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1720104648704.0000 - val_loss: 2003812614144.0000\n",
      "Epoch 229/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1719861248000.0000 - val_loss: 2003519143936.0000\n",
      "Epoch 230/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1719594647552.0000 - val_loss: 2003231965184.0000\n",
      "Epoch 231/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1719329095680.0000 - val_loss: 2002944000000.0000\n",
      "Epoch 232/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1719076519936.0000 - val_loss: 2002634145792.0000\n",
      "Epoch 233/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1718800744448.0000 - val_loss: 2002345525248.0000\n",
      "Epoch 234/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1718545809408.0000 - val_loss: 2002042355712.0000\n",
      "Epoch 235/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1718280912896.0000 - val_loss: 2001746001920.0000\n",
      "Epoch 236/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1718018375680.0000 - val_loss: 2001440735232.0000\n",
      "Epoch 237/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1717747712000.0000 - val_loss: 2001153949696.0000\n",
      "Epoch 238/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1717493956608.0000 - val_loss: 2000863625216.0000\n",
      "Epoch 239/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1717233647616.0000 - val_loss: 2000575004672.0000\n",
      "Epoch 240/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1716969275392.0000 - val_loss: 2000282976256.0000\n",
      "Epoch 241/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1716706738176.0000 - val_loss: 1999974301696.0000\n",
      "Epoch 242/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1716437123072.0000 - val_loss: 1999665627136.0000\n",
      "Epoch 243/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1716165017600.0000 - val_loss: 1999360360448.0000\n",
      "Epoch 244/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1715890028544.0000 - val_loss: 1999057584128.0000\n",
      "Epoch 245/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1715618054144.0000 - val_loss: 1998758477824.0000\n",
      "Epoch 246/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1715348832256.0000 - val_loss: 1998451507200.0000\n",
      "Epoch 247/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1715074891776.0000 - val_loss: 1998136410112.0000\n",
      "Epoch 248/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1714803572736.0000 - val_loss: 1997827997696.0000\n",
      "Epoch 249/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1714524389376.0000 - val_loss: 1997521551360.0000\n",
      "Epoch 250/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1714251104256.0000 - val_loss: 1997203570688.0000\n",
      "Epoch 251/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1713962614784.0000 - val_loss: 1996885196800.0000\n",
      "Epoch 252/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1713682382848.0000 - val_loss: 1996555157504.0000\n",
      "Epoch 253/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1713386029056.0000 - val_loss: 1996229443584.0000\n",
      "Epoch 254/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1713092427776.0000 - val_loss: 1995912773632.0000\n",
      "Epoch 255/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1712811147264.0000 - val_loss: 1995579457536.0000\n",
      "Epoch 256/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1712518463488.0000 - val_loss: 1995264360448.0000\n",
      "Epoch 257/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1712241639424.0000 - val_loss: 1994930913280.0000\n",
      "Epoch 258/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1711940042752.0000 - val_loss: 1994607165440.0000\n",
      "Epoch 259/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1711655616512.0000 - val_loss: 1994286694400.0000\n",
      "Epoch 260/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1711365423104.0000 - val_loss: 1993955999744.0000\n",
      "Epoch 261/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1711073394688.0000 - val_loss: 1993633562624.0000\n",
      "Epoch 262/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1710794080256.0000 - val_loss: 1993313222656.0000\n",
      "Epoch 263/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1710511882240.0000 - val_loss: 1992985935872.0000\n",
      "Epoch 264/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1710217625600.0000 - val_loss: 1992665202688.0000\n",
      "Epoch 265/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1709923762176.0000 - val_loss: 1992327299072.0000\n",
      "Epoch 266/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1709622951936.0000 - val_loss: 1991993458688.0000\n",
      "Epoch 267/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1709335117824.0000 - val_loss: 1991661846528.0000\n",
      "Epoch 268/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1709035356160.0000 - val_loss: 1991331807232.0000\n",
      "Epoch 269/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1708738478080.0000 - val_loss: 1991010549760.0000\n",
      "Epoch 270/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1708452216832.0000 - val_loss: 1990657572864.0000\n",
      "Epoch 271/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1708147867648.0000 - val_loss: 1990332121088.0000\n",
      "Epoch 272/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1707847974912.0000 - val_loss: 1990010339328.0000\n",
      "Epoch 273/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1707562762240.0000 - val_loss: 1989664964608.0000\n",
      "Epoch 274/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1707261165568.0000 - val_loss: 1989321424896.0000\n",
      "Epoch 275/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1706954194944.0000 - val_loss: 1988992565248.0000\n",
      "Epoch 276/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1706658627584.0000 - val_loss: 1988649287680.0000\n",
      "Epoch 277/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1706347462656.0000 - val_loss: 1988313481216.0000\n",
      "Epoch 278/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1706049929216.0000 - val_loss: 1987966402560.0000\n",
      "Epoch 279/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1705749381120.0000 - val_loss: 1987606740992.0000\n",
      "Epoch 280/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1705435070464.0000 - val_loss: 1987265298432.0000\n",
      "Epoch 281/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1705135833088.0000 - val_loss: 1986929360896.0000\n",
      "Epoch 282/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1704830566400.0000 - val_loss: 1986587131904.0000\n",
      "Epoch 283/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1704520450048.0000 - val_loss: 1986237300736.0000\n",
      "Epoch 284/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1704209547264.0000 - val_loss: 1985895596032.0000\n",
      "Epoch 285/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1703909523456.0000 - val_loss: 1985553367040.0000\n",
      "Epoch 286/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1703598489600.0000 - val_loss: 1985211531264.0000\n",
      "Epoch 287/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1703297548288.0000 - val_loss: 1984866418688.0000\n",
      "Epoch 288/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1702986514432.0000 - val_loss: 1984527597568.0000\n",
      "Epoch 289/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1702689112064.0000 - val_loss: 1984171081728.0000\n",
      "Epoch 290/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1702368509952.0000 - val_loss: 1983817187328.0000\n",
      "Epoch 291/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1702053543936.0000 - val_loss: 1983449006080.0000\n",
      "Epoch 292/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1701721800704.0000 - val_loss: 1983098126336.0000\n",
      "Epoch 293/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1701418106880.0000 - val_loss: 1982740824064.0000\n",
      "Epoch 294/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1701096587264.0000 - val_loss: 1982377492480.0000\n",
      "Epoch 295/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1700773756928.0000 - val_loss: 1982006296576.0000\n",
      "Epoch 296/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1700449222656.0000 - val_loss: 1981638377472.0000\n",
      "Epoch 297/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1700113416192.0000 - val_loss: 1981293002752.0000\n",
      "Epoch 298/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1699806969856.0000 - val_loss: 1980929277952.0000\n",
      "Epoch 299/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1699481649152.0000 - val_loss: 1980558475264.0000\n",
      "Epoch 300/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1699172712448.0000 - val_loss: 1980178366464.0000\n",
      "Epoch 301/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1698825109504.0000 - val_loss: 1979826176000.0000\n",
      "Epoch 302/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1698508832768.0000 - val_loss: 1979473199104.0000\n",
      "Epoch 303/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1698201468928.0000 - val_loss: 1979111964672.0000\n",
      "Epoch 304/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1697873395712.0000 - val_loss: 1978760560640.0000\n",
      "Epoch 305/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1697549123584.0000 - val_loss: 1978404831232.0000\n",
      "Epoch 306/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1697240842240.0000 - val_loss: 1978029572096.0000\n",
      "Epoch 307/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1696900710400.0000 - val_loss: 1977675939840.0000\n",
      "Epoch 308/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1696587186176.0000 - val_loss: 1977298714624.0000\n",
      "Epoch 309/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1696261865472.0000 - val_loss: 1976921489408.0000\n",
      "Epoch 310/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1695920553984.0000 - val_loss: 1976568119296.0000\n",
      "Epoch 311/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1695606767616.0000 - val_loss: 1976196005888.0000\n",
      "Epoch 312/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1695264407552.0000 - val_loss: 1975823892480.0000\n",
      "Epoch 313/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1694941052928.0000 - val_loss: 1975436967936.0000\n",
      "Epoch 314/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1694603411456.0000 - val_loss: 1975060791296.0000\n",
      "Epoch 315/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1694267342848.0000 - val_loss: 1974687105024.0000\n",
      "Epoch 316/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1693931012096.0000 - val_loss: 1974313549824.0000\n",
      "Epoch 317/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1693599137792.0000 - val_loss: 1973930426368.0000\n",
      "Epoch 318/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1693255729152.0000 - val_loss: 1973547040768.0000\n",
      "Epoch 319/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1692915335168.0000 - val_loss: 1973158412288.0000\n",
      "Epoch 320/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1692564324352.0000 - val_loss: 1972776861696.0000\n",
      "Epoch 321/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1692236382208.0000 - val_loss: 1972371718144.0000\n",
      "Epoch 322/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1691875016704.0000 - val_loss: 1971995410432.0000\n",
      "Epoch 323/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1691532656640.0000 - val_loss: 1971614121984.0000\n",
      "Epoch 324/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1691208384512.0000 - val_loss: 1971214352384.0000\n",
      "Epoch 325/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1690847019008.0000 - val_loss: 1970839879680.0000\n",
      "Epoch 326/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1690505707520.0000 - val_loss: 1970463703040.0000\n",
      "Epoch 327/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1690172129280.0000 - val_loss: 1970082152448.0000\n",
      "Epoch 328/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1689827409920.0000 - val_loss: 1969694834688.0000\n",
      "Epoch 329/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1689484525568.0000 - val_loss: 1969292705792.0000\n",
      "Epoch 330/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1689133383680.0000 - val_loss: 1968894246912.0000\n",
      "Epoch 331/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1688781717504.0000 - val_loss: 1968507060224.0000\n",
      "Epoch 332/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1688437129216.0000 - val_loss: 1968115154944.0000\n",
      "Epoch 333/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1688088739840.0000 - val_loss: 1967725740032.0000\n",
      "Epoch 334/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1687744544768.0000 - val_loss: 1967337766912.0000\n",
      "Epoch 335/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1687397335040.0000 - val_loss: 1966930526208.0000\n",
      "Epoch 336/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1687032430592.0000 - val_loss: 1966539538432.0000\n",
      "Epoch 337/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1686683516928.0000 - val_loss: 1966141341696.0000\n",
      "Epoch 338/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1686326607872.0000 - val_loss: 1965756383232.0000\n",
      "Epoch 339/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1685990014976.0000 - val_loss: 1965343768576.0000\n",
      "Epoch 340/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1685623668736.0000 - val_loss: 1964955926528.0000\n",
      "Epoch 341/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1685283930112.0000 - val_loss: 1964560875520.0000\n",
      "Epoch 342/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1684931870720.0000 - val_loss: 1964174082048.0000\n",
      "Epoch 343/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1684576534528.0000 - val_loss: 1963767758848.0000\n",
      "Epoch 344/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1684217790464.0000 - val_loss: 1963363401728.0000\n",
      "Epoch 345/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1683870056448.0000 - val_loss: 1962944757760.0000\n",
      "Epoch 346/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1683488636928.0000 - val_loss: 1962553245696.0000\n",
      "Epoch 347/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1683137888256.0000 - val_loss: 1962139189248.0000\n",
      "Epoch 348/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1682773114880.0000 - val_loss: 1961742434304.0000\n",
      "Epoch 349/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1682420400128.0000 - val_loss: 1961337028608.0000\n",
      "Epoch 350/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1682065981440.0000 - val_loss: 1960937914368.0000\n",
      "Epoch 351/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1681706188800.0000 - val_loss: 1960547581952.0000\n",
      "Epoch 352/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1681354391552.0000 - val_loss: 1960128937984.0000\n",
      "Epoch 353/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1680987127808.0000 - val_loss: 1959732314112.0000\n",
      "Epoch 354/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1680626810880.0000 - val_loss: 1959319175168.0000\n",
      "Epoch 355/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1680257712128.0000 - val_loss: 1958915997696.0000\n",
      "Epoch 356/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1679903817728.0000 - val_loss: 1958501416960.0000\n",
      "Epoch 357/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1679533670400.0000 - val_loss: 1958072811520.0000\n",
      "Epoch 358/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1679161425920.0000 - val_loss: 1957646696448.0000\n",
      "Epoch 359/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1678778171392.0000 - val_loss: 1957246140416.0000\n",
      "Epoch 360/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1678419951616.0000 - val_loss: 1956838113280.0000\n",
      "Epoch 361/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1678062256128.0000 - val_loss: 1956424712192.0000\n",
      "Epoch 362/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1677691191296.0000 - val_loss: 1956011573248.0000\n",
      "Epoch 363/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1677332185088.0000 - val_loss: 1955585720320.0000\n",
      "Epoch 364/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1676951420928.0000 - val_loss: 1955176513536.0000\n",
      "Epoch 365/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1676582715392.0000 - val_loss: 1954771501056.0000\n",
      "Epoch 366/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1676212436992.0000 - val_loss: 1954351022080.0000\n",
      "Epoch 367/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1675849629696.0000 - val_loss: 1953918484480.0000\n",
      "Epoch 368/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1675464540160.0000 - val_loss: 1953498005504.0000\n",
      "Epoch 369/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1675095441408.0000 - val_loss: 1953075691520.0000\n",
      "Epoch 370/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1674717954048.0000 - val_loss: 1952671465472.0000\n",
      "Epoch 371/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1674357374976.0000 - val_loss: 1952246398976.0000\n",
      "Epoch 372/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1673975431168.0000 - val_loss: 1951831556096.0000\n",
      "Epoch 373/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1673609084928.0000 - val_loss: 1951404785664.0000\n",
      "Epoch 374/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1673225043968.0000 - val_loss: 1950984175616.0000\n",
      "Epoch 375/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1672833794048.0000 - val_loss: 1950567890944.0000\n",
      "Epoch 376/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1672470855680.0000 - val_loss: 1950111105024.0000\n",
      "Epoch 377/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1672074231808.0000 - val_loss: 1949651173376.0000\n",
      "Epoch 378/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1671672496128.0000 - val_loss: 1949211951104.0000\n",
      "Epoch 379/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1671281639424.0000 - val_loss: 1948796846080.0000\n",
      "Epoch 380/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1670918832128.0000 - val_loss: 1948372303872.0000\n",
      "Epoch 381/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1670538723328.0000 - val_loss: 1947944222720.0000\n",
      "Epoch 382/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1670158090240.0000 - val_loss: 1947513651200.0000\n",
      "Epoch 383/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1669770641408.0000 - val_loss: 1947091075072.0000\n",
      "Epoch 384/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1669392105472.0000 - val_loss: 1946662338560.0000\n",
      "Epoch 385/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1669001379840.0000 - val_loss: 1946216038400.0000\n",
      "Epoch 386/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1668613931008.0000 - val_loss: 1945751650304.0000\n",
      "Epoch 387/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1668201054208.0000 - val_loss: 1945316098048.0000\n",
      "Epoch 388/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1667814391808.0000 - val_loss: 1944889065472.0000\n",
      "Epoch 389/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1667430350848.0000 - val_loss: 1944447746048.0000\n",
      "Epoch 390/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1667047882752.0000 - val_loss: 1944008261632.0000\n",
      "Epoch 391/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1666647457792.0000 - val_loss: 1943575461888.0000\n",
      "Epoch 392/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1666259353600.0000 - val_loss: 1943135715328.0000\n",
      "Epoch 393/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1665872035840.0000 - val_loss: 1942687318016.0000\n",
      "Epoch 394/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1665481703424.0000 - val_loss: 1942236692480.0000\n",
      "Epoch 395/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1665075904512.0000 - val_loss: 1941783969792.0000\n",
      "Epoch 396/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1664675610624.0000 - val_loss: 1941335179264.0000\n",
      "Epoch 397/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1664277151744.0000 - val_loss: 1940888879104.0000\n",
      "Epoch 398/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1663879610368.0000 - val_loss: 1940450967552.0000\n",
      "Epoch 399/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1663487442944.0000 - val_loss: 1939994050560.0000\n",
      "Epoch 400/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1663087935488.0000 - val_loss: 1939535298560.0000\n",
      "Epoch 401/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1662688821248.0000 - val_loss: 1939082444800.0000\n",
      "Epoch 402/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1662281580544.0000 - val_loss: 1938638897152.0000\n",
      "Epoch 403/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1661886529536.0000 - val_loss: 1938186960896.0000\n",
      "Epoch 404/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1661469196288.0000 - val_loss: 1937729388544.0000\n",
      "Epoch 405/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1661074276352.0000 - val_loss: 1937266049024.0000\n",
      "Epoch 406/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1660648685568.0000 - val_loss: 1936801529856.0000\n",
      "Epoch 407/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1660245377024.0000 - val_loss: 1936318398464.0000\n",
      "Epoch 408/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1659815067648.0000 - val_loss: 1935858204672.0000\n",
      "Epoch 409/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1659420278784.0000 - val_loss: 1935402074112.0000\n",
      "Epoch 410/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1659012513792.0000 - val_loss: 1934950531072.0000\n",
      "Epoch 411/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1658594394112.0000 - val_loss: 1934488109056.0000\n",
      "Epoch 412/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1658188070912.0000 - val_loss: 1934000783360.0000\n",
      "Epoch 413/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1657747144704.0000 - val_loss: 1933531021312.0000\n",
      "Epoch 414/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1657338331136.0000 - val_loss: 1933041598464.0000\n",
      "Epoch 415/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1656916410368.0000 - val_loss: 1932590055424.0000\n",
      "Epoch 416/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1656505368576.0000 - val_loss: 1932129730560.0000\n",
      "Epoch 417/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1656091967488.0000 - val_loss: 1931649875968.0000\n",
      "Epoch 418/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1655663230976.0000 - val_loss: 1931166482432.0000\n",
      "Epoch 419/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1655234363392.0000 - val_loss: 1930685841408.0000\n",
      "Epoch 420/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1654812311552.0000 - val_loss: 1930212671488.0000\n",
      "Epoch 421/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1654397337600.0000 - val_loss: 1929737928704.0000\n",
      "Epoch 422/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1653971091456.0000 - val_loss: 1929281273856.0000\n",
      "Epoch 423/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1653559132160.0000 - val_loss: 1928807448576.0000\n",
      "Epoch 424/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1653142192128.0000 - val_loss: 1928319598592.0000\n",
      "Epoch 425/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1652718436352.0000 - val_loss: 1927853113344.0000\n",
      "Epoch 426/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1652294680576.0000 - val_loss: 1927382040576.0000\n",
      "Epoch 427/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1651883900928.0000 - val_loss: 1926902841344.0000\n",
      "Epoch 428/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1651457916928.0000 - val_loss: 1926445662208.0000\n",
      "Epoch 429/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1651049758720.0000 - val_loss: 1925993201664.0000\n",
      "Epoch 430/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1650644353024.0000 - val_loss: 1925516754944.0000\n",
      "Epoch 431/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1650237112320.0000 - val_loss: 1925049876480.0000\n",
      "Epoch 432/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1649817419776.0000 - val_loss: 1924600299520.0000\n",
      "Epoch 433/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1649408868352.0000 - val_loss: 1924136828928.0000\n",
      "Epoch 434/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1649006215168.0000 - val_loss: 1923661692928.0000\n",
      "Epoch 435/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1648585080832.0000 - val_loss: 1923196518400.0000\n",
      "Epoch 436/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1648155557888.0000 - val_loss: 1922731343872.0000\n",
      "Epoch 437/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1647748710400.0000 - val_loss: 1922241658880.0000\n",
      "Epoch 438/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1647301885952.0000 - val_loss: 1921745682432.0000\n",
      "Epoch 439/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1646879178752.0000 - val_loss: 1921264123904.0000\n",
      "Epoch 440/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1646460141568.0000 - val_loss: 1920802226176.0000\n",
      "Epoch 441/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1646038220800.0000 - val_loss: 1920333512704.0000\n",
      "Epoch 442/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1645613023232.0000 - val_loss: 1919871352832.0000\n",
      "Epoch 443/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1645210370048.0000 - val_loss: 1919383764992.0000\n",
      "Epoch 444/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1644786221056.0000 - val_loss: 1918906007552.0000\n",
      "Epoch 445/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1644361285632.0000 - val_loss: 1918443716608.0000\n",
      "Epoch 446/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1643954569216.0000 - val_loss: 1917963075584.0000\n",
      "Epoch 447/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1643524390912.0000 - val_loss: 1917486366720.0000\n",
      "Epoch 448/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1643098537984.0000 - val_loss: 1917008478208.0000\n",
      "Epoch 449/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1642666786816.0000 - val_loss: 1916526395392.0000\n",
      "Epoch 450/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1642235035648.0000 - val_loss: 1916043919360.0000\n",
      "Epoch 451/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1641812066304.0000 - val_loss: 1915557249024.0000\n",
      "Epoch 452/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1641365110784.0000 - val_loss: 1915083685888.0000\n",
      "Epoch 453/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1640951185408.0000 - val_loss: 1914579845120.0000\n",
      "Epoch 454/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1640506327040.0000 - val_loss: 1914098679808.0000\n",
      "Epoch 455/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1640073003008.0000 - val_loss: 1913592741888.0000\n",
      "Epoch 456/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1639630241792.0000 - val_loss: 1913088507904.0000\n",
      "Epoch 457/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1639187349504.0000 - val_loss: 1912586764288.0000\n",
      "Epoch 458/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1638738165760.0000 - val_loss: 1912122507264.0000\n",
      "Epoch 459/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1638334464000.0000 - val_loss: 1911629545472.0000\n",
      "Epoch 460/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1637891833856.0000 - val_loss: 1911144579072.0000\n",
      "Epoch 461/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1637445795840.0000 - val_loss: 1910653321216.0000\n",
      "Epoch 462/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1637017059328.0000 - val_loss: 1910156951552.0000\n",
      "Epoch 463/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1636589240320.0000 - val_loss: 1909656911872.0000\n",
      "Epoch 464/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1636151590912.0000 - val_loss: 1909166309376.0000\n",
      "Epoch 465/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1635711188992.0000 - val_loss: 1908691959808.0000\n",
      "Epoch 466/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1635288743936.0000 - val_loss: 1908203716608.0000\n",
      "Epoch 467/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1634847031296.0000 - val_loss: 1907715997696.0000\n",
      "Epoch 468/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1634414231552.0000 - val_loss: 1907207176192.0000\n",
      "Epoch 469/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1633966227456.0000 - val_loss: 1906702942208.0000\n",
      "Epoch 470/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1633513242624.0000 - val_loss: 1906207358976.0000\n",
      "Epoch 471/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1633080442880.0000 - val_loss: 1905716887552.0000\n",
      "Epoch 472/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1632646332416.0000 - val_loss: 1905225105408.0000\n",
      "Epoch 473/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1632220086272.0000 - val_loss: 1904728342528.0000\n",
      "Epoch 474/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1631767232512.0000 - val_loss: 1904238526464.0000\n",
      "Epoch 475/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1631318441984.0000 - val_loss: 1903742156800.0000\n",
      "Epoch 476/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1630878171136.0000 - val_loss: 1903220752384.0000\n",
      "Epoch 477/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1630423875584.0000 - val_loss: 1902695022592.0000\n",
      "Epoch 478/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1629961977856.0000 - val_loss: 1902195245056.0000\n",
      "Epoch 479/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1629515808768.0000 - val_loss: 1901681836032.0000\n",
      "Epoch 480/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1629057318912.0000 - val_loss: 1901174063104.0000\n",
      "Epoch 481/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1628598960128.0000 - val_loss: 1900666552320.0000\n",
      "Epoch 482/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1628159213568.0000 - val_loss: 1900161531904.0000\n",
      "Epoch 483/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1627722219520.0000 - val_loss: 1899659395072.0000\n",
      "Epoch 484/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1627270676480.0000 - val_loss: 1899164729344.0000\n",
      "Epoch 485/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1626828963840.0000 - val_loss: 1898651320320.0000\n",
      "Epoch 486/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1626373357568.0000 - val_loss: 1898143940608.0000\n",
      "Epoch 487/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1625921814528.0000 - val_loss: 1897627779072.0000\n",
      "Epoch 488/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1625458737152.0000 - val_loss: 1897124331520.0000\n",
      "Epoch 489/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1625016762368.0000 - val_loss: 1896624947200.0000\n",
      "Epoch 490/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1624570200064.0000 - val_loss: 1896108130304.0000\n",
      "Epoch 491/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1624110268416.0000 - val_loss: 1895594065920.0000\n",
      "Epoch 492/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1623659118592.0000 - val_loss: 1895080787968.0000\n",
      "Epoch 493/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1623197089792.0000 - val_loss: 1894572228608.0000\n",
      "Epoch 494/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1622743318528.0000 - val_loss: 1894040076288.0000\n",
      "Epoch 495/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1622275784704.0000 - val_loss: 1893524832256.0000\n",
      "Epoch 496/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1621814411264.0000 - val_loss: 1893009063936.0000\n",
      "Epoch 497/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1621361950720.0000 - val_loss: 1892482285568.0000\n",
      "Epoch 498/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1620882882560.0000 - val_loss: 1891977658368.0000\n",
      "Epoch 499/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1620449820672.0000 - val_loss: 1891434102784.0000\n",
      "Epoch 500/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1619964985344.0000 - val_loss: 1890922135552.0000\n",
      "Epoch 501/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1619500204032.0000 - val_loss: 1890409119744.0000\n",
      "Epoch 502/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1619060457472.0000 - val_loss: 1889881030656.0000\n",
      "Epoch 503/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1618592268288.0000 - val_loss: 1889366835200.0000\n",
      "Epoch 504/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1618123948032.0000 - val_loss: 1888841629696.0000\n",
      "Epoch 505/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1617653923840.0000 - val_loss: 1888318783488.0000\n",
      "Epoch 506/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1617185734656.0000 - val_loss: 1887789907968.0000\n",
      "Epoch 507/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1616713089024.0000 - val_loss: 1887257100288.0000\n",
      "Epoch 508/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1616254992384.0000 - val_loss: 1886725210112.0000\n",
      "Epoch 509/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1615777497088.0000 - val_loss: 1886220713984.0000\n",
      "Epoch 510/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1615332900864.0000 - val_loss: 1885687775232.0000\n",
      "Epoch 511/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1614859337728.0000 - val_loss: 1885159292928.0000\n",
      "Epoch 512/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1614402289664.0000 - val_loss: 1884613115904.0000\n",
      "Epoch 513/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1613907755008.0000 - val_loss: 1884083585024.0000\n",
      "Epoch 514/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1613427638272.0000 - val_loss: 1883541340160.0000\n",
      "Epoch 515/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1612952764416.0000 - val_loss: 1883012333568.0000\n",
      "Epoch 516/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1612488769536.0000 - val_loss: 1882465370112.0000\n",
      "Epoch 517/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1612007079936.0000 - val_loss: 1881939640320.0000\n",
      "Epoch 518/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1611521458176.0000 - val_loss: 1881405128704.0000\n",
      "Epoch 519/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1611055104000.0000 - val_loss: 1880860655616.0000\n",
      "Epoch 520/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1610577084416.0000 - val_loss: 1880316313600.0000\n",
      "Epoch 521/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1610088841216.0000 - val_loss: 1879787044864.0000\n",
      "Epoch 522/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1609610035200.0000 - val_loss: 1879239819264.0000\n",
      "Epoch 523/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1609136078848.0000 - val_loss: 1878694821888.0000\n",
      "Epoch 524/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1608671297536.0000 - val_loss: 1878141698048.0000\n",
      "Epoch 525/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1608166146048.0000 - val_loss: 1877632745472.0000\n",
      "Epoch 526/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1607709360128.0000 - val_loss: 1877097971712.0000\n",
      "Epoch 527/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1607223476224.0000 - val_loss: 1876554153984.0000\n",
      "Epoch 528/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1606724747264.0000 - val_loss: 1875972325376.0000\n",
      "Epoch 529/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1606230343680.0000 - val_loss: 1875407405056.0000\n",
      "Epoch 530/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1605733974016.0000 - val_loss: 1874846941184.0000\n",
      "Epoch 531/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1605235113984.0000 - val_loss: 1874293555200.0000\n",
      "Epoch 532/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1604761288704.0000 - val_loss: 1873738989568.0000\n",
      "Epoch 533/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1604256137216.0000 - val_loss: 1873192550400.0000\n",
      "Epoch 534/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1603768811520.0000 - val_loss: 1872647028736.0000\n",
      "Epoch 535/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1603283714048.0000 - val_loss: 1872092856320.0000\n",
      "Epoch 536/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1602784329728.0000 - val_loss: 1871545237504.0000\n",
      "Epoch 537/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1602298576896.0000 - val_loss: 1870976909312.0000\n",
      "Epoch 538/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1601800372224.0000 - val_loss: 1870420377600.0000\n",
      "Epoch 539/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1601313308672.0000 - val_loss: 1869874462720.0000\n",
      "Epoch 540/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1600833191936.0000 - val_loss: 1869329334272.0000\n",
      "Epoch 541/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1600349274112.0000 - val_loss: 1868789055488.0000\n",
      "Epoch 542/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1599873351680.0000 - val_loss: 1868248645632.0000\n",
      "Epoch 543/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1599386419200.0000 - val_loss: 1867701026816.0000\n",
      "Epoch 544/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1598906695680.0000 - val_loss: 1867156029440.0000\n",
      "Epoch 545/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1598414651392.0000 - val_loss: 1866614702080.0000\n",
      "Epoch 546/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1597931651072.0000 - val_loss: 1866036936704.0000\n",
      "Epoch 547/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1597411295232.0000 - val_loss: 1865435185152.0000\n",
      "Epoch 548/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1596879142912.0000 - val_loss: 1864868954112.0000\n",
      "Epoch 549/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1596388671488.0000 - val_loss: 1864311504896.0000\n",
      "Epoch 550/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1595906850816.0000 - val_loss: 1863750909952.0000\n",
      "Epoch 551/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1595415461888.0000 - val_loss: 1863214170112.0000\n",
      "Epoch 552/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1594927742976.0000 - val_loss: 1862669172736.0000\n",
      "Epoch 553/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1594435174400.0000 - val_loss: 1862109364224.0000\n",
      "Epoch 554/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1593937756160.0000 - val_loss: 1861554667520.0000\n",
      "Epoch 555/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1593438633984.0000 - val_loss: 1860996169728.0000\n",
      "Epoch 556/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1592942657536.0000 - val_loss: 1860441604096.0000\n",
      "Epoch 557/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1592457691136.0000 - val_loss: 1859891101696.0000\n",
      "Epoch 558/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1591980195840.0000 - val_loss: 1859317923840.0000\n",
      "Epoch 559/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1591468490752.0000 - val_loss: 1858745401344.0000\n",
      "Epoch 560/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1590955343872.0000 - val_loss: 1858175762432.0000\n",
      "Epoch 561/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1590457270272.0000 - val_loss: 1857625915392.0000\n",
      "Epoch 562/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1589980430336.0000 - val_loss: 1857072005120.0000\n",
      "Epoch 563/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1589480259584.0000 - val_loss: 1856525697024.0000\n",
      "Epoch 564/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1588991229952.0000 - val_loss: 1855971524608.0000\n",
      "Epoch 565/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1588489879552.0000 - val_loss: 1855399919616.0000\n",
      "Epoch 566/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1587974766592.0000 - val_loss: 1854799740928.0000\n",
      "Epoch 567/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1587457687552.0000 - val_loss: 1854230233088.0000\n",
      "Epoch 568/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1586965118976.0000 - val_loss: 1853636476928.0000\n",
      "Epoch 569/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1586432704512.0000 - val_loss: 1853084401664.0000\n",
      "Epoch 570/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1585944723456.0000 - val_loss: 1852533112832.0000\n",
      "Epoch 571/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1585448615936.0000 - val_loss: 1851983527936.0000\n",
      "Epoch 572/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1584957882368.0000 - val_loss: 1851411398656.0000\n",
      "Epoch 573/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1584442507264.0000 - val_loss: 1850853163008.0000\n",
      "Epoch 574/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1583946399744.0000 - val_loss: 1850277363712.0000\n",
      "Epoch 575/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1583441641472.0000 - val_loss: 1849693306880.0000\n",
      "Epoch 576/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1582927839232.0000 - val_loss: 1849112526848.0000\n",
      "Epoch 577/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1582408269824.0000 - val_loss: 1848543412224.0000\n",
      "Epoch 578/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1581912031232.0000 - val_loss: 1847961583616.0000\n",
      "Epoch 579/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1581401374720.0000 - val_loss: 1847393648640.0000\n",
      "Epoch 580/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1580904349696.0000 - val_loss: 1846827286528.0000\n",
      "Epoch 581/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1580392775680.0000 - val_loss: 1846270885888.0000\n",
      "Epoch 582/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1579905449984.0000 - val_loss: 1845696790528.0000\n",
      "Epoch 583/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1579385749504.0000 - val_loss: 1845130690560.0000\n",
      "Epoch 584/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1578879549440.0000 - val_loss: 1844561313792.0000\n",
      "Epoch 585/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1578371776512.0000 - val_loss: 1843975815168.0000\n",
      "Epoch 586/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1577859940352.0000 - val_loss: 1843395035136.0000\n",
      "Epoch 587/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1577359376384.0000 - val_loss: 1842816221184.0000\n",
      "Epoch 588/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1576829583360.0000 - val_loss: 1842244222976.0000\n",
      "Epoch 589/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1576331116544.0000 - val_loss: 1841664884736.0000\n",
      "Epoch 590/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1575820591104.0000 - val_loss: 1841085546496.0000\n",
      "Epoch 591/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1575308623872.0000 - val_loss: 1840516825088.0000\n",
      "Epoch 592/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1574800719872.0000 - val_loss: 1839937224704.0000\n",
      "Epoch 593/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1574282723328.0000 - val_loss: 1839337832448.0000\n",
      "Epoch 594/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1573754109952.0000 - val_loss: 1838766489600.0000\n",
      "Epoch 595/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1573237293056.0000 - val_loss: 1838190034944.0000\n",
      "Epoch 596/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1572728209408.0000 - val_loss: 1837611745280.0000\n",
      "Epoch 597/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1572205625344.0000 - val_loss: 1837019693056.0000\n",
      "Epoch 598/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1571681730560.0000 - val_loss: 1836393955328.0000\n",
      "Epoch 599/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1571128344576.0000 - val_loss: 1835793776640.0000\n",
      "Epoch 600/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1570610085888.0000 - val_loss: 1835207229440.0000\n",
      "Epoch 601/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1570087108608.0000 - val_loss: 1834603511808.0000\n",
      "Epoch 602/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1569545650176.0000 - val_loss: 1834016571392.0000\n",
      "Epoch 603/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1569039056896.0000 - val_loss: 1833433300992.0000\n",
      "Epoch 604/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1568513327104.0000 - val_loss: 1832857239552.0000\n",
      "Epoch 605/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1568001753088.0000 - val_loss: 1832248803328.0000\n",
      "Epoch 606/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1567465537536.0000 - val_loss: 1831652163584.0000\n",
      "Epoch 607/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1566941642752.0000 - val_loss: 1831063912448.0000\n",
      "Epoch 608/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1566423515136.0000 - val_loss: 1830466355200.0000\n",
      "Epoch 609/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1565884022784.0000 - val_loss: 1829872861184.0000\n",
      "Epoch 610/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1565349380096.0000 - val_loss: 1829264424960.0000\n",
      "Epoch 611/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1564821684224.0000 - val_loss: 1828619288576.0000\n",
      "Epoch 612/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1564246409216.0000 - val_loss: 1828031168512.0000\n",
      "Epoch 613/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1563726446592.0000 - val_loss: 1827426795520.0000\n",
      "Epoch 614/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1563183808512.0000 - val_loss: 1826834219008.0000\n",
      "Epoch 615/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1562654015488.0000 - val_loss: 1826227748864.0000\n",
      "Epoch 616/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1562113998848.0000 - val_loss: 1825613414400.0000\n",
      "Epoch 617/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1561575424000.0000 - val_loss: 1825003012096.0000\n",
      "Epoch 618/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1561032654848.0000 - val_loss: 1824365871104.0000\n",
      "Epoch 619/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1560473239552.0000 - val_loss: 1823756124160.0000\n",
      "Epoch 620/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1559944626176.0000 - val_loss: 1823143755776.0000\n",
      "Epoch 621/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1559413784576.0000 - val_loss: 1822527717376.0000\n",
      "Epoch 622/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1558858170368.0000 - val_loss: 1821940514816.0000\n",
      "Epoch 623/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1558326935552.0000 - val_loss: 1821348986880.0000\n",
      "Epoch 624/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1557807628288.0000 - val_loss: 1820737667072.0000\n",
      "Epoch 625/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1557264334848.0000 - val_loss: 1820129361920.0000\n",
      "Epoch 626/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1556727988224.0000 - val_loss: 1819523022848.0000\n",
      "Epoch 627/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1556205273088.0000 - val_loss: 1818916159488.0000\n",
      "Epoch 628/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1555652149248.0000 - val_loss: 1818333020160.0000\n",
      "Epoch 629/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1555127730176.0000 - val_loss: 1817733758976.0000\n",
      "Epoch 630/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1554590072832.0000 - val_loss: 1817122308096.0000\n",
      "Epoch 631/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1554047565824.0000 - val_loss: 1816500502528.0000\n",
      "Epoch 632/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1553494179840.0000 - val_loss: 1815910809600.0000\n",
      "Epoch 633/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1552977494016.0000 - val_loss: 1815284023296.0000\n",
      "Epoch 634/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1552447963136.0000 - val_loss: 1814655008768.0000\n",
      "Epoch 635/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1551888023552.0000 - val_loss: 1814059024384.0000\n",
      "Epoch 636/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1551355740160.0000 - val_loss: 1813471035392.0000\n",
      "Epoch 637/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1550842855424.0000 - val_loss: 1812857618432.0000\n",
      "Epoch 638/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1550291959808.0000 - val_loss: 1812269760512.0000\n",
      "Epoch 639/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1549762953216.0000 - val_loss: 1811654901760.0000\n",
      "Epoch 640/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1549202882560.0000 - val_loss: 1811009765376.0000\n",
      "Epoch 641/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1548637831168.0000 - val_loss: 1810386124800.0000\n",
      "Epoch 642/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1548081299456.0000 - val_loss: 1809802067968.0000\n",
      "Epoch 643/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1547561861120.0000 - val_loss: 1809170694144.0000\n",
      "Epoch 644/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1547009654784.0000 - val_loss: 1808524640256.0000\n",
      "Epoch 645/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1546446045184.0000 - val_loss: 1807906897920.0000\n",
      "Epoch 646/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1545883615232.0000 - val_loss: 1807294005248.0000\n",
      "Epoch 647/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1545344122880.0000 - val_loss: 1806660009984.0000\n",
      "Epoch 648/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1544796504064.0000 - val_loss: 1806042529792.0000\n",
      "Epoch 649/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1544251375616.0000 - val_loss: 1805420986368.0000\n",
      "Epoch 650/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1543689732096.0000 - val_loss: 1804835225600.0000\n",
      "Epoch 651/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1543168327680.0000 - val_loss: 1804206473216.0000\n",
      "Epoch 652/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1542616121344.0000 - val_loss: 1803570118656.0000\n",
      "Epoch 653/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1542057754624.0000 - val_loss: 1802932584448.0000\n",
      "Epoch 654/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1541494013952.0000 - val_loss: 1802313138176.0000\n",
      "Epoch 655/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1540931584000.0000 - val_loss: 1801691856896.0000\n",
      "Epoch 656/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1540382130176.0000 - val_loss: 1801045671936.0000\n",
      "Epoch 657/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1539804364800.0000 - val_loss: 1800398569472.0000\n",
      "Epoch 658/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1539224633344.0000 - val_loss: 1799755005952.0000\n",
      "Epoch 659/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1538662072320.0000 - val_loss: 1799107117056.0000\n",
      "Epoch 660/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1538084175872.0000 - val_loss: 1798450577408.0000\n",
      "Epoch 661/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1537509031936.0000 - val_loss: 1797813567488.0000\n",
      "Epoch 662/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1536953286656.0000 - val_loss: 1797176426496.0000\n",
      "Epoch 663/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1536391905280.0000 - val_loss: 1796535877632.0000\n",
      "Epoch 664/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1535823708160.0000 - val_loss: 1795906863104.0000\n",
      "Epoch 665/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1535261278208.0000 - val_loss: 1795258187776.0000\n",
      "Epoch 666/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1534686658560.0000 - val_loss: 1794614231040.0000\n",
      "Epoch 667/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1534116233216.0000 - val_loss: 1793980891136.0000\n",
      "Epoch 668/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1533562322944.0000 - val_loss: 1793322909696.0000\n",
      "Epoch 669/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1532970532864.0000 - val_loss: 1792703201280.0000\n",
      "Epoch 670/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1532433924096.0000 - val_loss: 1792056360960.0000\n",
      "Epoch 671/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1531864809472.0000 - val_loss: 1791421448192.0000\n",
      "Epoch 672/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1531309457408.0000 - val_loss: 1790808817664.0000\n",
      "Epoch 673/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1530773241856.0000 - val_loss: 1790192123904.0000\n",
      "Epoch 674/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1530225754112.0000 - val_loss: 1789575954432.0000\n",
      "Epoch 675/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1529668829184.0000 - val_loss: 1788956246016.0000\n",
      "Epoch 676/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1529102204928.0000 - val_loss: 1788341387264.0000\n",
      "Epoch 677/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1528552226816.0000 - val_loss: 1787681570816.0000\n",
      "Epoch 678/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1527981015040.0000 - val_loss: 1787044560896.0000\n",
      "Epoch 679/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1527418454016.0000 - val_loss: 1786398113792.0000\n",
      "Epoch 680/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1526855368704.0000 - val_loss: 1785735938048.0000\n",
      "Epoch 681/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1526266331136.0000 - val_loss: 1785099059200.0000\n",
      "Epoch 682/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1525705211904.0000 - val_loss: 1784433082368.0000\n",
      "Epoch 683/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1525108178944.0000 - val_loss: 1783803674624.0000\n",
      "Epoch 684/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1524536049664.0000 - val_loss: 1783168892928.0000\n",
      "Epoch 685/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1523974275072.0000 - val_loss: 1782508421120.0000\n",
      "Epoch 686/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1523396116480.0000 - val_loss: 1781845458944.0000\n",
      "Epoch 687/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1522811928576.0000 - val_loss: 1781179351040.0000\n",
      "Epoch 688/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1522211225600.0000 - val_loss: 1780534345728.0000\n",
      "Epoch 689/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1521651417088.0000 - val_loss: 1779872825344.0000\n",
      "Epoch 690/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1521075224576.0000 - val_loss: 1779237519360.0000\n",
      "Epoch 691/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1520521969664.0000 - val_loss: 1778606276608.0000\n",
      "Epoch 692/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1519955476480.0000 - val_loss: 1777967824896.0000\n",
      "Epoch 693/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1519392653312.0000 - val_loss: 1777347067904.0000\n",
      "Epoch 694/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1518834941952.0000 - val_loss: 1776703242240.0000\n",
      "Epoch 695/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1518265696256.0000 - val_loss: 1776064004096.0000\n",
      "Epoch 696/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1517698285568.0000 - val_loss: 1775427911680.0000\n",
      "Epoch 697/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1517119471616.0000 - val_loss: 1774784348160.0000\n",
      "Epoch 698/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1516558090240.0000 - val_loss: 1774107230208.0000\n",
      "Epoch 699/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1515966431232.0000 - val_loss: 1773432733696.0000\n",
      "Epoch 700/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1515367038976.0000 - val_loss: 1772783927296.0000\n",
      "Epoch 701/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1514799497216.0000 - val_loss: 1772132630528.0000\n",
      "Epoch 702/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1514213474304.0000 - val_loss: 1771503616000.0000\n",
      "Epoch 703/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1513651044352.0000 - val_loss: 1770856382464.0000\n",
      "Epoch 704/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1513085337600.0000 - val_loss: 1770200236032.0000\n",
      "Epoch 705/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1512517271552.0000 - val_loss: 1769540681728.0000\n",
      "Epoch 706/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1511921942528.0000 - val_loss: 1768903278592.0000\n",
      "Epoch 707/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1511374979072.0000 - val_loss: 1768235991040.0000\n",
      "Epoch 708/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1510769557504.0000 - val_loss: 1767599112192.0000\n",
      "Epoch 709/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1510215385088.0000 - val_loss: 1766948339712.0000\n",
      "Epoch 710/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1509617827840.0000 - val_loss: 1766282493952.0000\n",
      "Epoch 711/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1509022498816.0000 - val_loss: 1765614682112.0000\n",
      "Epoch 712/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1508432019456.0000 - val_loss: 1764936646656.0000\n",
      "Epoch 713/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1507861069824.0000 - val_loss: 1764271587328.0000\n",
      "Epoch 714/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1507273605120.0000 - val_loss: 1763620945920.0000\n",
      "Epoch 715/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1506687713280.0000 - val_loss: 1762991538176.0000\n",
      "Epoch 716/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1506121220096.0000 - val_loss: 1762312716288.0000\n",
      "Epoch 717/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1505532575744.0000 - val_loss: 1761669545984.0000\n",
      "Epoch 718/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1504959004672.0000 - val_loss: 1761006059520.0000\n",
      "Epoch 719/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1504362627072.0000 - val_loss: 1760364462080.0000\n",
      "Epoch 720/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1503800983552.0000 - val_loss: 1759697043456.0000\n",
      "Epoch 721/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1503211028480.0000 - val_loss: 1759051120640.0000\n",
      "Epoch 722/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1502639554560.0000 - val_loss: 1758377672704.0000\n",
      "Epoch 723/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1502062837760.0000 - val_loss: 1757704617984.0000\n",
      "Epoch 724/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1501472751616.0000 - val_loss: 1757042442240.0000\n",
      "Epoch 725/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1500879912960.0000 - val_loss: 1756395339776.0000\n",
      "Epoch 726/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1500307128320.0000 - val_loss: 1755718221824.0000\n",
      "Epoch 727/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1499694235648.0000 - val_loss: 1755054211072.0000\n",
      "Epoch 728/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1499117912064.0000 - val_loss: 1754364116992.0000\n",
      "Epoch 729/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1498520223744.0000 - val_loss: 1753698271232.0000\n",
      "Epoch 730/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1497926598656.0000 - val_loss: 1753035571200.0000\n",
      "Epoch 731/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1497324978176.0000 - val_loss: 1752367235072.0000\n",
      "Epoch 732/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1496721653760.0000 - val_loss: 1751713579008.0000\n",
      "Epoch 733/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1496161452032.0000 - val_loss: 1751036329984.0000\n",
      "Epoch 734/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1495547379712.0000 - val_loss: 1750341517312.0000\n",
      "Epoch 735/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1494913122304.0000 - val_loss: 1749668986880.0000\n",
      "Epoch 736/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1494331555840.0000 - val_loss: 1748969455616.0000\n",
      "Epoch 737/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1493721153536.0000 - val_loss: 1748299153408.0000\n",
      "Epoch 738/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1493130543104.0000 - val_loss: 1747625181184.0000\n",
      "Epoch 739/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1492523941888.0000 - val_loss: 1746957893632.0000\n",
      "Epoch 740/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1491922190336.0000 - val_loss: 1746267144192.0000\n",
      "Epoch 741/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1491328434176.0000 - val_loss: 1745553326080.0000\n",
      "Epoch 742/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1490703351808.0000 - val_loss: 1744883810304.0000\n",
      "Epoch 743/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1490098585600.0000 - val_loss: 1744189390848.0000\n",
      "Epoch 744/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1489496440832.0000 - val_loss: 1743499296768.0000\n",
      "Epoch 745/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1488892198912.0000 - val_loss: 1742831484928.0000\n",
      "Epoch 746/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1488297000960.0000 - val_loss: 1742164066304.0000\n",
      "Epoch 747/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1487696560128.0000 - val_loss: 1741489438720.0000\n",
      "Epoch 748/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1487099658240.0000 - val_loss: 1740820971520.0000\n",
      "Epoch 749/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1486498430976.0000 - val_loss: 1740109643776.0000\n",
      "Epoch 750/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1485865484288.0000 - val_loss: 1739407228928.0000\n",
      "Epoch 751/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1485261635584.0000 - val_loss: 1738710188032.0000\n",
      "Epoch 752/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1484633276416.0000 - val_loss: 1738004103168.0000\n",
      "Epoch 753/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1484025626624.0000 - val_loss: 1737307193344.0000\n",
      "Epoch 754/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1483409981440.0000 - val_loss: 1736616574976.0000\n",
      "Epoch 755/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1482790141952.0000 - val_loss: 1735947845632.0000\n",
      "Epoch 756/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1482208444416.0000 - val_loss: 1735271514112.0000\n",
      "Epoch 757/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1481574187008.0000 - val_loss: 1734547865600.0000\n",
      "Epoch 758/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1480946352128.0000 - val_loss: 1733838372864.0000\n",
      "Epoch 759/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1480344600576.0000 - val_loss: 1733112233984.0000\n",
      "Epoch 760/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1479692648448.0000 - val_loss: 1732416897024.0000\n",
      "Epoch 761/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1479078051840.0000 - val_loss: 1731742400512.0000\n",
      "Epoch 762/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1478476169216.0000 - val_loss: 1731054796800.0000\n",
      "Epoch 763/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1477879922688.0000 - val_loss: 1730369683456.0000\n",
      "Epoch 764/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1477275942912.0000 - val_loss: 1729684832256.0000\n",
      "Epoch 765/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1476659118080.0000 - val_loss: 1729004830720.0000\n",
      "Epoch 766/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1476046749696.0000 - val_loss: 1728269910016.0000\n",
      "Epoch 767/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1475400040448.0000 - val_loss: 1727571689472.0000\n",
      "Epoch 768/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1474782298112.0000 - val_loss: 1726861541376.0000\n",
      "Epoch 769/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1474166521856.0000 - val_loss: 1726167777280.0000\n",
      "Epoch 770/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1473562279936.0000 - val_loss: 1725475061760.0000\n",
      "Epoch 771/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1472937721856.0000 - val_loss: 1724796239872.0000\n",
      "Epoch 772/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1472350912512.0000 - val_loss: 1724094742528.0000\n",
      "Epoch 773/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1471727403008.0000 - val_loss: 1723437023232.0000\n",
      "Epoch 774/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1471150161920.0000 - val_loss: 1722762264576.0000\n",
      "Epoch 775/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1470553915392.0000 - val_loss: 1722066534400.0000\n",
      "Epoch 776/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1469937614848.0000 - val_loss: 1721389416448.0000\n",
      "Epoch 777/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1469328523264.0000 - val_loss: 1720715837440.0000\n",
      "Epoch 778/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1468729917440.0000 - val_loss: 1719995465728.0000\n",
      "Epoch 779/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1468104179712.0000 - val_loss: 1719297900544.0000\n",
      "Epoch 780/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1467469266944.0000 - val_loss: 1718584606720.0000\n",
      "Epoch 781/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1466842873856.0000 - val_loss: 1717853224960.0000\n",
      "Epoch 782/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1466196688896.0000 - val_loss: 1717159723008.0000\n",
      "Epoch 783/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1465581436928.0000 - val_loss: 1716469497856.0000\n",
      "Epoch 784/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1464985976832.0000 - val_loss: 1715761709056.0000\n",
      "Epoch 785/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1464355651584.0000 - val_loss: 1715074105344.0000\n",
      "Epoch 786/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1463732797440.0000 - val_loss: 1714365530112.0000\n",
      "Epoch 787/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1463124230144.0000 - val_loss: 1713637294080.0000\n",
      "Epoch 788/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1462485909504.0000 - val_loss: 1712951394304.0000\n",
      "Epoch 789/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1461864235008.0000 - val_loss: 1712248193024.0000\n",
      "Epoch 790/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1461246099456.0000 - val_loss: 1711510126592.0000\n",
      "Epoch 791/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1460596113408.0000 - val_loss: 1710806794240.0000\n",
      "Epoch 792/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1459981910016.0000 - val_loss: 1710099529728.0000\n",
      "Epoch 793/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1459360104448.0000 - val_loss: 1709393313792.0000\n",
      "Epoch 794/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1458732400640.0000 - val_loss: 1708688277504.0000\n",
      "Epoch 795/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1458112167936.0000 - val_loss: 1707996217344.0000\n",
      "Epoch 796/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1457501503488.0000 - val_loss: 1707258806272.0000\n",
      "Epoch 797/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1456863707136.0000 - val_loss: 1706545119232.0000\n",
      "Epoch 798/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1456227483648.0000 - val_loss: 1705862627328.0000\n",
      "Epoch 799/2000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1455624290304.0000 - val_loss: 1705156411392.0000\n",
      "Epoch 800/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1454997897216.0000 - val_loss: 1704470904832.0000\n",
      "Epoch 801/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1454394310656.0000 - val_loss: 1703758004224.0000\n",
      "Epoch 802/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1453750484992.0000 - val_loss: 1703055458304.0000\n",
      "Epoch 803/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1453120421888.0000 - val_loss: 1702358941696.0000\n",
      "Epoch 804/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1452503597056.0000 - val_loss: 1701644599296.0000\n",
      "Epoch 805/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1451869208576.0000 - val_loss: 1700923834368.0000\n",
      "Epoch 806/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1451225907200.0000 - val_loss: 1700194549760.0000\n",
      "Epoch 807/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1450611703808.0000 - val_loss: 1699468279808.0000\n",
      "Epoch 808/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1449967616000.0000 - val_loss: 1698742403072.0000\n",
      "Epoch 809/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1449313173504.0000 - val_loss: 1698037497856.0000\n",
      "Epoch 810/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1448690319360.0000 - val_loss: 1697331806208.0000\n",
      "Epoch 811/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1448082538496.0000 - val_loss: 1696598982656.0000\n",
      "Epoch 812/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1447433207808.0000 - val_loss: 1695899713536.0000\n",
      "Epoch 813/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1446819135488.0000 - val_loss: 1695173181440.0000\n",
      "Epoch 814/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1446168363008.0000 - val_loss: 1694467620864.0000\n",
      "Epoch 815/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1445560975360.0000 - val_loss: 1693757210624.0000\n",
      "Epoch 816/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1444920557568.0000 - val_loss: 1693074849792.0000\n",
      "Epoch 817/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1444321034240.0000 - val_loss: 1692342288384.0000\n",
      "Epoch 818/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1443660824576.0000 - val_loss: 1691618902016.0000\n",
      "Epoch 819/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1443022503936.0000 - val_loss: 1690879000576.0000\n",
      "Epoch 820/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1442381430784.0000 - val_loss: 1690165837824.0000\n",
      "Epoch 821/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1441745862656.0000 - val_loss: 1689424363520.0000\n",
      "Epoch 822/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1441100070912.0000 - val_loss: 1688697700352.0000\n",
      "Epoch 823/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1440434094080.0000 - val_loss: 1687996465152.0000\n",
      "Epoch 824/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1439818842112.0000 - val_loss: 1687244505088.0000\n",
      "Epoch 825/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1439149850624.0000 - val_loss: 1686522298368.0000\n",
      "Epoch 826/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1438515462144.0000 - val_loss: 1685787115520.0000\n",
      "Epoch 827/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1437882253312.0000 - val_loss: 1685059010560.0000\n",
      "Epoch 828/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1437229383680.0000 - val_loss: 1684355547136.0000\n",
      "Epoch 829/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1436592898048.0000 - val_loss: 1683615252480.0000\n",
      "Epoch 830/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1435958247424.0000 - val_loss: 1682869977088.0000\n",
      "Epoch 831/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1435317698560.0000 - val_loss: 1682140168192.0000\n",
      "Epoch 832/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1434672693248.0000 - val_loss: 1681434214400.0000\n",
      "Epoch 833/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1434023100416.0000 - val_loss: 1680722755584.0000\n",
      "Epoch 834/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1433397231616.0000 - val_loss: 1679964897280.0000\n",
      "Epoch 835/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1432745803776.0000 - val_loss: 1679239938048.0000\n",
      "Epoch 836/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1432107745280.0000 - val_loss: 1678530445312.0000\n",
      "Epoch 837/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1431488036864.0000 - val_loss: 1677815840768.0000\n",
      "Epoch 838/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1430850240512.0000 - val_loss: 1677115785216.0000\n",
      "Epoch 839/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1430238396416.0000 - val_loss: 1676407472128.0000\n",
      "Epoch 840/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1429610299392.0000 - val_loss: 1675682381824.0000\n",
      "Epoch 841/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1428959002624.0000 - val_loss: 1674965417984.0000\n",
      "Epoch 842/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1428317929472.0000 - val_loss: 1674242555904.0000\n",
      "Epoch 843/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1427670171648.0000 - val_loss: 1673495576576.0000\n",
      "Epoch 844/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1427030278144.0000 - val_loss: 1672736931840.0000\n",
      "Epoch 845/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1426366791680.0000 - val_loss: 1672022851584.0000\n",
      "Epoch 846/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1425718902784.0000 - val_loss: 1671312965632.0000\n",
      "Epoch 847/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1425105747968.0000 - val_loss: 1670566510592.0000\n",
      "Epoch 848/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1424456941568.0000 - val_loss: 1669852168192.0000\n",
      "Epoch 849/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1423819538432.0000 - val_loss: 1669108203520.0000\n",
      "Epoch 850/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1423150153728.0000 - val_loss: 1668391108608.0000\n",
      "Epoch 851/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1422504099840.0000 - val_loss: 1667636920320.0000\n",
      "Epoch 852/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1421838909440.0000 - val_loss: 1666876440576.0000\n",
      "Epoch 853/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1421181583360.0000 - val_loss: 1666130247680.0000\n",
      "Epoch 854/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1420522946560.0000 - val_loss: 1665398210560.0000\n",
      "Epoch 855/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1419874009088.0000 - val_loss: 1664637861888.0000\n",
      "Epoch 856/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1419205410816.0000 - val_loss: 1663900975104.0000\n",
      "Epoch 857/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1418545070080.0000 - val_loss: 1663161597952.0000\n",
      "Epoch 858/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1417903865856.0000 - val_loss: 1662388666368.0000\n",
      "Epoch 859/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1417234219008.0000 - val_loss: 1661651648512.0000\n",
      "Epoch 860/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1416588427264.0000 - val_loss: 1660931145728.0000\n",
      "Epoch 861/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1415942504448.0000 - val_loss: 1660217458688.0000\n",
      "Epoch 862/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1415309688832.0000 - val_loss: 1659485552640.0000\n",
      "Epoch 863/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1414655508480.0000 - val_loss: 1658767671296.0000\n",
      "Epoch 864/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1414017581056.0000 - val_loss: 1657998409728.0000\n",
      "Epoch 865/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1413331812352.0000 - val_loss: 1657226657792.0000\n",
      "Epoch 866/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1412657184768.0000 - val_loss: 1656473124864.0000\n",
      "Epoch 867/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1411978625024.0000 - val_loss: 1655701766144.0000\n",
      "Epoch 868/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1411316187136.0000 - val_loss: 1654961340416.0000\n",
      "Epoch 869/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1410657288192.0000 - val_loss: 1654199025664.0000\n",
      "Epoch 870/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1410000224256.0000 - val_loss: 1653459779584.0000\n",
      "Epoch 871/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1409350500352.0000 - val_loss: 1652732723200.0000\n",
      "Epoch 872/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1408690814976.0000 - val_loss: 1652029784064.0000\n",
      "Epoch 873/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1408075431936.0000 - val_loss: 1651245187072.0000\n",
      "Epoch 874/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1407381143552.0000 - val_loss: 1650490474496.0000\n",
      "Epoch 875/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1406734696448.0000 - val_loss: 1649733664768.0000\n",
      "Epoch 876/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1406059413504.0000 - val_loss: 1648997826560.0000\n",
      "Epoch 877/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1405402742784.0000 - val_loss: 1648266575872.0000\n",
      "Epoch 878/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1404742270976.0000 - val_loss: 1647479488512.0000\n",
      "Epoch 879/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1404049555456.0000 - val_loss: 1646711013376.0000\n",
      "Epoch 880/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1403393671168.0000 - val_loss: 1645965344768.0000\n",
      "Epoch 881/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1402743947264.0000 - val_loss: 1645217579008.0000\n",
      "Epoch 882/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1402076135424.0000 - val_loss: 1644481347584.0000\n",
      "Epoch 883/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1401420906496.0000 - val_loss: 1643719819264.0000\n",
      "Epoch 884/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1400748638208.0000 - val_loss: 1642988568576.0000\n",
      "Epoch 885/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1400098914304.0000 - val_loss: 1642243162112.0000\n",
      "Epoch 886/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1399441588224.0000 - val_loss: 1641475735552.0000\n",
      "Epoch 887/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1398769975296.0000 - val_loss: 1640713551872.0000\n",
      "Epoch 888/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1398077390848.0000 - val_loss: 1639951368192.0000\n",
      "Epoch 889/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1397413117952.0000 - val_loss: 1639184990208.0000\n",
      "Epoch 890/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1396753956864.0000 - val_loss: 1638430408704.0000\n",
      "Epoch 891/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1396069629952.0000 - val_loss: 1637684477952.0000\n",
      "Epoch 892/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1395409813504.0000 - val_loss: 1636894244864.0000\n",
      "Epoch 893/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1394732564480.0000 - val_loss: 1636128522240.0000\n",
      "Epoch 894/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1394038145024.0000 - val_loss: 1635388227584.0000\n",
      "Epoch 895/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1393381212160.0000 - val_loss: 1634638233600.0000\n",
      "Epoch 896/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1392736600064.0000 - val_loss: 1633851932672.0000\n",
      "Epoch 897/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1392038379520.0000 - val_loss: 1633065762816.0000\n",
      "Epoch 898/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1391335309312.0000 - val_loss: 1632301744128.0000\n",
      "Epoch 899/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1390667628544.0000 - val_loss: 1631519768576.0000\n",
      "Epoch 900/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1389984088064.0000 - val_loss: 1630736613376.0000\n",
      "Epoch 901/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1389290192896.0000 - val_loss: 1629932224512.0000\n",
      "Epoch 902/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1388593283072.0000 - val_loss: 1629154836480.0000\n",
      "Epoch 903/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1387919572992.0000 - val_loss: 1628404711424.0000\n",
      "Epoch 904/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1387251499008.0000 - val_loss: 1627668742144.0000\n",
      "Epoch 905/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1386586439680.0000 - val_loss: 1626931200000.0000\n",
      "Epoch 906/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1385938419712.0000 - val_loss: 1626151452672.0000\n",
      "Epoch 907/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1385245966336.0000 - val_loss: 1625358467072.0000\n",
      "Epoch 908/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1384554430464.0000 - val_loss: 1624590123008.0000\n",
      "Epoch 909/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1383883866112.0000 - val_loss: 1623830953984.0000\n",
      "Epoch 910/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1383224180736.0000 - val_loss: 1623077027840.0000\n",
      "Epoch 911/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1382564888576.0000 - val_loss: 1622334242816.0000\n",
      "Epoch 912/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1381913985024.0000 - val_loss: 1621551480832.0000\n",
      "Epoch 913/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1381199380480.0000 - val_loss: 1620808564736.0000\n",
      "Epoch 914/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1380533403648.0000 - val_loss: 1620012040192.0000\n",
      "Epoch 915/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1379854057472.0000 - val_loss: 1619243302912.0000\n",
      "Epoch 916/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1379147710464.0000 - val_loss: 1618487017472.0000\n",
      "Epoch 917/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1378486845440.0000 - val_loss: 1617674108928.0000\n",
      "Epoch 918/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1377780891648.0000 - val_loss: 1616892395520.0000\n",
      "Epoch 919/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1377092501504.0000 - val_loss: 1616143187968.0000\n",
      "Epoch 920/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1376436092928.0000 - val_loss: 1615419670528.0000\n",
      "Epoch 921/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1375793053696.0000 - val_loss: 1614652637184.0000\n",
      "Epoch 922/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1375116591104.0000 - val_loss: 1613915750400.0000\n",
      "Epoch 923/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1374477221888.0000 - val_loss: 1613137444864.0000\n",
      "Epoch 924/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1373770612736.0000 - val_loss: 1612393611264.0000\n",
      "Epoch 925/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1373129015296.0000 - val_loss: 1611613339648.0000\n",
      "Epoch 926/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1372458713088.0000 - val_loss: 1610846699520.0000\n",
      "Epoch 927/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1371782381568.0000 - val_loss: 1610104963072.0000\n",
      "Epoch 928/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1371136196608.0000 - val_loss: 1609324691456.0000\n",
      "Epoch 929/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1370428014592.0000 - val_loss: 1608598683648.0000\n",
      "Epoch 930/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1369763348480.0000 - val_loss: 1607853146112.0000\n",
      "Epoch 931/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1369104318464.0000 - val_loss: 1607007469568.0000\n",
      "Epoch 932/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1368373985280.0000 - val_loss: 1606227853312.0000\n",
      "Epoch 933/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1367710629888.0000 - val_loss: 1605442600960.0000\n",
      "Epoch 934/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1367013720064.0000 - val_loss: 1604697063424.0000\n",
      "Epoch 935/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1366346432512.0000 - val_loss: 1603945758720.0000\n",
      "Epoch 936/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1365685305344.0000 - val_loss: 1603182395392.0000\n",
      "Epoch 937/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1365006221312.0000 - val_loss: 1602420736000.0000\n",
      "Epoch 938/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1364341030912.0000 - val_loss: 1601663008768.0000\n",
      "Epoch 939/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1363665879040.0000 - val_loss: 1600893616128.0000\n",
      "Epoch 940/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1362975391744.0000 - val_loss: 1600141524992.0000\n",
      "Epoch 941/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1362323308544.0000 - val_loss: 1599333203968.0000\n",
      "Epoch 942/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1361607131136.0000 - val_loss: 1598550704128.0000\n",
      "Epoch 943/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1360911925248.0000 - val_loss: 1597748281344.0000\n",
      "Epoch 944/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1360219602944.0000 - val_loss: 1596973776896.0000\n",
      "Epoch 945/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1359552053248.0000 - val_loss: 1596204777472.0000\n",
      "Epoch 946/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1358877032448.0000 - val_loss: 1595447181312.0000\n",
      "Epoch 947/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1358195195904.0000 - val_loss: 1594646069248.0000\n",
      "Epoch 948/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1357489373184.0000 - val_loss: 1593900269568.0000\n",
      "Epoch 949/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1356851576832.0000 - val_loss: 1593121964032.0000\n",
      "Epoch 950/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1356152045568.0000 - val_loss: 1592345231360.0000\n",
      "Epoch 951/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1355461689344.0000 - val_loss: 1591576494080.0000\n",
      "Epoch 952/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1354776576000.0000 - val_loss: 1590762536960.0000\n",
      "Epoch 953/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1354068656128.0000 - val_loss: 1589987508224.0000\n",
      "Epoch 954/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1353396518912.0000 - val_loss: 1589230305280.0000\n",
      "Epoch 955/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1352727134208.0000 - val_loss: 1588462878720.0000\n",
      "Epoch 956/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1352045297664.0000 - val_loss: 1587678543872.0000\n",
      "Epoch 957/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1351352320000.0000 - val_loss: 1586923831296.0000\n",
      "Epoch 958/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1350681493504.0000 - val_loss: 1586112233472.0000\n",
      "Epoch 959/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1349980913664.0000 - val_loss: 1585320951808.0000\n",
      "Epoch 960/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1349288329216.0000 - val_loss: 1584570171392.0000\n",
      "Epoch 961/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1348611604480.0000 - val_loss: 1583805890560.0000\n",
      "Epoch 962/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1347935141888.0000 - val_loss: 1583005696000.0000\n",
      "Epoch 963/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1347240984576.0000 - val_loss: 1582205501440.0000\n",
      "Epoch 964/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1346533457920.0000 - val_loss: 1581438599168.0000\n",
      "Epoch 965/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1345855160320.0000 - val_loss: 1580672876544.0000\n",
      "Epoch 966/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1345185513472.0000 - val_loss: 1579909513216.0000\n",
      "Epoch 967/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1344509575168.0000 - val_loss: 1579115347968.0000\n",
      "Epoch 968/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1343823937536.0000 - val_loss: 1578353426432.0000\n",
      "Epoch 969/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1343157043200.0000 - val_loss: 1577598844928.0000\n",
      "Epoch 970/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1342459609088.0000 - val_loss: 1576833384448.0000\n",
      "Epoch 971/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1341819453440.0000 - val_loss: 1576033714176.0000\n",
      "Epoch 972/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1341128310784.0000 - val_loss: 1575279263744.0000\n",
      "Epoch 973/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1340463513600.0000 - val_loss: 1574511050752.0000\n",
      "Epoch 974/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1339778662400.0000 - val_loss: 1573717409792.0000\n",
      "Epoch 975/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1339077951488.0000 - val_loss: 1572941463552.0000\n",
      "Epoch 976/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1338397294592.0000 - val_loss: 1572163944448.0000\n",
      "Epoch 977/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1337696845824.0000 - val_loss: 1571386294272.0000\n",
      "Epoch 978/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1336997052416.0000 - val_loss: 1570584264704.0000\n",
      "Epoch 979/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1336283627520.0000 - val_loss: 1569797046272.0000\n",
      "Epoch 980/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1335619747840.0000 - val_loss: 1569016643584.0000\n",
      "Epoch 981/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1334937518080.0000 - val_loss: 1568245547008.0000\n",
      "Epoch 982/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1334230777856.0000 - val_loss: 1567457673216.0000\n",
      "Epoch 983/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1333557460992.0000 - val_loss: 1566663376896.0000\n",
      "Epoch 984/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1332844167168.0000 - val_loss: 1565860429824.0000\n",
      "Epoch 985/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1332151451648.0000 - val_loss: 1565067706368.0000\n",
      "Epoch 986/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1331442352128.0000 - val_loss: 1564284551168.0000\n",
      "Epoch 987/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1330752913408.0000 - val_loss: 1563500216320.0000\n",
      "Epoch 988/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1330066620416.0000 - val_loss: 1562702249984.0000\n",
      "Epoch 989/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1329358831616.0000 - val_loss: 1561900089344.0000\n",
      "Epoch 990/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1328652877824.0000 - val_loss: 1561116409856.0000\n",
      "Epoch 991/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1327981133824.0000 - val_loss: 1560321589248.0000\n",
      "Epoch 992/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1327281340416.0000 - val_loss: 1559525588992.0000\n",
      "Epoch 993/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1326581547008.0000 - val_loss: 1558737584128.0000\n",
      "Epoch 994/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1325897482240.0000 - val_loss: 1557966094336.0000\n",
      "Epoch 995/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1325199392768.0000 - val_loss: 1557193949184.0000\n",
      "Epoch 996/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1324507987968.0000 - val_loss: 1556362559488.0000\n",
      "Epoch 997/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1323796529152.0000 - val_loss: 1555564986368.0000\n",
      "Epoch 998/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1323081793536.0000 - val_loss: 1554781700096.0000\n",
      "Epoch 999/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1322406510592.0000 - val_loss: 1553990287360.0000\n",
      "Epoch 1000/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1321710911488.0000 - val_loss: 1553187209216.0000\n",
      "Epoch 1001/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1321010855936.0000 - val_loss: 1552407068672.0000\n",
      "Epoch 1002/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1320326004736.0000 - val_loss: 1551631646720.0000\n",
      "Epoch 1003/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1319633813504.0000 - val_loss: 1550856486912.0000\n",
      "Epoch 1004/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1318923403264.0000 - val_loss: 1550072020992.0000\n",
      "Epoch 1005/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1318243926016.0000 - val_loss: 1549258063872.0000\n",
      "Epoch 1006/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1317523423232.0000 - val_loss: 1548452102144.0000\n",
      "Epoch 1007/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1316838047744.0000 - val_loss: 1547651121152.0000\n",
      "Epoch 1008/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1316135763968.0000 - val_loss: 1546843455488.0000\n",
      "Epoch 1009/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1315424043008.0000 - val_loss: 1546049945600.0000\n",
      "Epoch 1010/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1314718875648.0000 - val_loss: 1545267052544.0000\n",
      "Epoch 1011/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1314009645056.0000 - val_loss: 1544457682944.0000\n",
      "Epoch 1012/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1313306968064.0000 - val_loss: 1543633108992.0000\n",
      "Epoch 1013/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1312572964864.0000 - val_loss: 1542800146432.0000\n",
      "Epoch 1014/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1311848005632.0000 - val_loss: 1541965086720.0000\n",
      "Epoch 1015/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1311120293888.0000 - val_loss: 1541163581440.0000\n",
      "Epoch 1016/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1310409359360.0000 - val_loss: 1540372692992.0000\n",
      "Epoch 1017/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1309716250624.0000 - val_loss: 1539555196928.0000\n",
      "Epoch 1018/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1309003612160.0000 - val_loss: 1538742812672.0000\n",
      "Epoch 1019/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1308288745472.0000 - val_loss: 1537943928832.0000\n",
      "Epoch 1020/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1307602976768.0000 - val_loss: 1537160118272.0000\n",
      "Epoch 1021/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1306910916608.0000 - val_loss: 1536378142720.0000\n",
      "Epoch 1022/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1306214531072.0000 - val_loss: 1535586074624.0000\n",
      "Epoch 1023/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1305511591936.0000 - val_loss: 1534783389696.0000\n",
      "Epoch 1024/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1304793317376.0000 - val_loss: 1534017929216.0000\n",
      "Epoch 1025/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1304122621952.0000 - val_loss: 1533216555008.0000\n",
      "Epoch 1026/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1303444324352.0000 - val_loss: 1532384903168.0000\n",
      "Epoch 1027/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1302712942592.0000 - val_loss: 1531582349312.0000\n",
      "Epoch 1028/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1301984051200.0000 - val_loss: 1530769309696.0000\n",
      "Epoch 1029/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1301287403520.0000 - val_loss: 1529941065728.0000\n",
      "Epoch 1030/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1300557987840.0000 - val_loss: 1529151619072.0000\n",
      "Epoch 1031/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1299874840576.0000 - val_loss: 1528349196288.0000\n",
      "Epoch 1032/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1299163512832.0000 - val_loss: 1527550312448.0000\n",
      "Epoch 1033/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1298434097152.0000 - val_loss: 1526761259008.0000\n",
      "Epoch 1034/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1297731682304.0000 - val_loss: 1525874688000.0000\n",
      "Epoch 1035/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1296975396864.0000 - val_loss: 1525041070080.0000\n",
      "Epoch 1036/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1296255287296.0000 - val_loss: 1524218855424.0000\n",
      "Epoch 1037/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1295533998080.0000 - val_loss: 1523410534400.0000\n",
      "Epoch 1038/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1294838923264.0000 - val_loss: 1522621480960.0000\n",
      "Epoch 1039/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1294132183040.0000 - val_loss: 1521822334976.0000\n",
      "Epoch 1040/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1293419282432.0000 - val_loss: 1521019256832.0000\n",
      "Epoch 1041/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1292712804352.0000 - val_loss: 1520191930368.0000\n",
      "Epoch 1042/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1291992825856.0000 - val_loss: 1519378235392.0000\n",
      "Epoch 1043/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1291261968384.0000 - val_loss: 1518599012352.0000\n",
      "Epoch 1044/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1290584064000.0000 - val_loss: 1517767753728.0000\n",
      "Epoch 1045/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1289852420096.0000 - val_loss: 1516979224576.0000\n",
      "Epoch 1046/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1289148301312.0000 - val_loss: 1516196724736.0000\n",
      "Epoch 1047/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1288478261248.0000 - val_loss: 1515344363520.0000\n",
      "Epoch 1048/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1287737573376.0000 - val_loss: 1514543906816.0000\n",
      "Epoch 1049/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1287033716736.0000 - val_loss: 1513751838720.0000\n",
      "Epoch 1050/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1286326583296.0000 - val_loss: 1512958328832.0000\n",
      "Epoch 1051/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1285631115264.0000 - val_loss: 1512168620032.0000\n",
      "Epoch 1052/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1284928438272.0000 - val_loss: 1511361871872.0000\n",
      "Epoch 1053/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1284244635648.0000 - val_loss: 1510546210816.0000\n",
      "Epoch 1054/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1283520200704.0000 - val_loss: 1509759909888.0000\n",
      "Epoch 1055/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1282798780416.0000 - val_loss: 1508971380736.0000\n",
      "Epoch 1056/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1282079064064.0000 - val_loss: 1508109713408.0000\n",
      "Epoch 1057/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1281323040768.0000 - val_loss: 1507219079168.0000\n",
      "Epoch 1058/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1280558759936.0000 - val_loss: 1506383364096.0000\n",
      "Epoch 1059/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1279847170048.0000 - val_loss: 1505536376832.0000\n",
      "Epoch 1060/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1279106875392.0000 - val_loss: 1504697909248.0000\n",
      "Epoch 1061/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1278360551424.0000 - val_loss: 1503882248192.0000\n",
      "Epoch 1062/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1277676355584.0000 - val_loss: 1503038275584.0000\n",
      "Epoch 1063/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1276907225088.0000 - val_loss: 1502231003136.0000\n",
      "Epoch 1064/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1276199043072.0000 - val_loss: 1501423730688.0000\n",
      "Epoch 1065/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1275503837184.0000 - val_loss: 1500599681024.0000\n",
      "Epoch 1066/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1274784120832.0000 - val_loss: 1499788214272.0000\n",
      "Epoch 1067/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1274072793088.0000 - val_loss: 1498975567872.0000\n",
      "Epoch 1068/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1273364217856.0000 - val_loss: 1498180091904.0000\n",
      "Epoch 1069/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1272649482240.0000 - val_loss: 1497375571968.0000\n",
      "Epoch 1070/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1271957946368.0000 - val_loss: 1496580227072.0000\n",
      "Epoch 1071/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1271255531520.0000 - val_loss: 1495802970112.0000\n",
      "Epoch 1072/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1270573039616.0000 - val_loss: 1495013130240.0000\n",
      "Epoch 1073/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1269869314048.0000 - val_loss: 1494231941120.0000\n",
      "Epoch 1074/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1269181579264.0000 - val_loss: 1493397929984.0000\n",
      "Epoch 1075/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1268448362496.0000 - val_loss: 1492576894976.0000\n",
      "Epoch 1076/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1267722878976.0000 - val_loss: 1491745112064.0000\n",
      "Epoch 1077/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1266994380800.0000 - val_loss: 1490946621440.0000\n",
      "Epoch 1078/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1266288033792.0000 - val_loss: 1490133581824.0000\n",
      "Epoch 1079/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1265580638208.0000 - val_loss: 1489280958464.0000\n",
      "Epoch 1080/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1264851746816.0000 - val_loss: 1488468049920.0000\n",
      "Epoch 1081/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1264141467648.0000 - val_loss: 1487673491456.0000\n",
      "Epoch 1082/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1263418081280.0000 - val_loss: 1486861107200.0000\n",
      "Epoch 1083/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1262701903872.0000 - val_loss: 1486025261056.0000\n",
      "Epoch 1084/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1261983629312.0000 - val_loss: 1485171326976.0000\n",
      "Epoch 1085/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1261240975360.0000 - val_loss: 1484361039872.0000\n",
      "Epoch 1086/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1260533841920.0000 - val_loss: 1483550490624.0000\n",
      "Epoch 1087/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1259818975232.0000 - val_loss: 1482739154944.0000\n",
      "Epoch 1088/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1259097292800.0000 - val_loss: 1481933324288.0000\n",
      "Epoch 1089/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1258364076032.0000 - val_loss: 1481101017088.0000\n",
      "Epoch 1090/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1257669263360.0000 - val_loss: 1480265039872.0000\n",
      "Epoch 1091/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1256926085120.0000 - val_loss: 1479472709632.0000\n",
      "Epoch 1092/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1256223145984.0000 - val_loss: 1478659932160.0000\n",
      "Epoch 1093/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1255512866816.0000 - val_loss: 1477835489280.0000\n",
      "Epoch 1094/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1254783320064.0000 - val_loss: 1477039489024.0000\n",
      "Epoch 1095/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1254066618368.0000 - val_loss: 1476208361472.0000\n",
      "Epoch 1096/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1253353979904.0000 - val_loss: 1475375661056.0000\n",
      "Epoch 1097/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1252610670592.0000 - val_loss: 1474560655360.0000\n",
      "Epoch 1098/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1251917955072.0000 - val_loss: 1473717862400.0000\n",
      "Epoch 1099/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1251177005056.0000 - val_loss: 1472903118848.0000\n",
      "Epoch 1100/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1250423734272.0000 - val_loss: 1472040402944.0000\n",
      "Epoch 1101/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1249713061888.0000 - val_loss: 1471198920704.0000\n",
      "Epoch 1102/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1248975126528.0000 - val_loss: 1470382997504.0000\n",
      "Epoch 1103/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1248257900544.0000 - val_loss: 1469570482176.0000\n",
      "Epoch 1104/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1247541198848.0000 - val_loss: 1468706717696.0000\n",
      "Epoch 1105/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1246769446912.0000 - val_loss: 1467870609408.0000\n",
      "Epoch 1106/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1246035705856.0000 - val_loss: 1467060715520.0000\n",
      "Epoch 1107/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1245321363456.0000 - val_loss: 1466212679680.0000\n",
      "Epoch 1108/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1244599943168.0000 - val_loss: 1465379979264.0000\n",
      "Epoch 1109/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1243859779584.0000 - val_loss: 1464580702208.0000\n",
      "Epoch 1110/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1243156578304.0000 - val_loss: 1463736074240.0000\n",
      "Epoch 1111/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1242386006016.0000 - val_loss: 1462893805568.0000\n",
      "Epoch 1112/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1241656197120.0000 - val_loss: 1462018375680.0000\n",
      "Epoch 1113/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1240911577088.0000 - val_loss: 1461173485568.0000\n",
      "Epoch 1114/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1240170627072.0000 - val_loss: 1460315750400.0000\n",
      "Epoch 1115/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1239398481920.0000 - val_loss: 1459503104000.0000\n",
      "Epoch 1116/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1238663692288.0000 - val_loss: 1458645106688.0000\n",
      "Epoch 1117/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1237903998976.0000 - val_loss: 1457757880320.0000\n",
      "Epoch 1118/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1237105246208.0000 - val_loss: 1456898572288.0000\n",
      "Epoch 1119/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1236383956992.0000 - val_loss: 1455983820800.0000\n",
      "Epoch 1120/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1235598311424.0000 - val_loss: 1455140241408.0000\n",
      "Epoch 1121/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1234890522624.0000 - val_loss: 1454270578688.0000\n",
      "Epoch 1122/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1234112872448.0000 - val_loss: 1453434077184.0000\n",
      "Epoch 1123/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1233399316480.0000 - val_loss: 1452596527104.0000\n",
      "Epoch 1124/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1232638967808.0000 - val_loss: 1451796463616.0000\n",
      "Epoch 1125/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1231925280768.0000 - val_loss: 1450918805504.0000\n",
      "Epoch 1126/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1231194554368.0000 - val_loss: 1450069983232.0000\n",
      "Epoch 1127/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1230455963648.0000 - val_loss: 1449269526528.0000\n",
      "Epoch 1128/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1229731659776.0000 - val_loss: 1448473919488.0000\n",
      "Epoch 1129/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1229023870976.0000 - val_loss: 1447625490432.0000\n",
      "Epoch 1130/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1228296290304.0000 - val_loss: 1446795542528.0000\n",
      "Epoch 1131/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1227558879232.0000 - val_loss: 1445986304000.0000\n",
      "Epoch 1132/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1226847551488.0000 - val_loss: 1445171822592.0000\n",
      "Epoch 1133/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1226144874496.0000 - val_loss: 1444343316480.0000\n",
      "Epoch 1134/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1225403006976.0000 - val_loss: 1443525296128.0000\n",
      "Epoch 1135/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1224694562816.0000 - val_loss: 1442672803840.0000\n",
      "Epoch 1136/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1223951777792.0000 - val_loss: 1441853341696.0000\n",
      "Epoch 1137/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1223209123840.0000 - val_loss: 1441020248064.0000\n",
      "Epoch 1138/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1222496878592.0000 - val_loss: 1440204324864.0000\n",
      "Epoch 1139/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1221787385856.0000 - val_loss: 1439387877376.0000\n",
      "Epoch 1140/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1221093359616.0000 - val_loss: 1438564220928.0000\n",
      "Epoch 1141/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1220352802816.0000 - val_loss: 1437729030144.0000\n",
      "Epoch 1142/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1219610148864.0000 - val_loss: 1436906422272.0000\n",
      "Epoch 1143/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1218895413248.0000 - val_loss: 1436064940032.0000\n",
      "Epoch 1144/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1218168487936.0000 - val_loss: 1435233419264.0000\n",
      "Epoch 1145/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1217433567232.0000 - val_loss: 1434416971776.0000\n",
      "Epoch 1146/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1216724336640.0000 - val_loss: 1433580732416.0000\n",
      "Epoch 1147/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1215986663424.0000 - val_loss: 1432766119936.0000\n",
      "Epoch 1148/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1215279661056.0000 - val_loss: 1431920967680.0000\n",
      "Epoch 1149/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1214525734912.0000 - val_loss: 1431123787776.0000\n",
      "Epoch 1150/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1213809688576.0000 - val_loss: 1430265528320.0000\n",
      "Epoch 1151/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1213065592832.0000 - val_loss: 1429408710656.0000\n",
      "Epoch 1152/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1212334342144.0000 - val_loss: 1428566835200.0000\n",
      "Epoch 1153/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1211579498496.0000 - val_loss: 1427738198016.0000\n",
      "Epoch 1154/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1210833567744.0000 - val_loss: 1426857525248.0000\n",
      "Epoch 1155/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1210046873600.0000 - val_loss: 1425982750720.0000\n",
      "Epoch 1156/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1209314312192.0000 - val_loss: 1425098670080.0000\n",
      "Epoch 1157/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1208518705152.0000 - val_loss: 1424231235584.0000\n",
      "Epoch 1158/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1207757176832.0000 - val_loss: 1423374548992.0000\n",
      "Epoch 1159/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1207014260736.0000 - val_loss: 1422479327232.0000\n",
      "Epoch 1160/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1206237921280.0000 - val_loss: 1421645053952.0000\n",
      "Epoch 1161/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1205511389184.0000 - val_loss: 1420784828416.0000\n",
      "Epoch 1162/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1204766638080.0000 - val_loss: 1419924865024.0000\n",
      "Epoch 1163/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1204021362688.0000 - val_loss: 1419100160000.0000\n",
      "Epoch 1164/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1203305316352.0000 - val_loss: 1418275717120.0000\n",
      "Epoch 1165/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1202567774208.0000 - val_loss: 1417441181696.0000\n",
      "Epoch 1166/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1201835474944.0000 - val_loss: 1416609398784.0000\n",
      "Epoch 1167/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1201100292096.0000 - val_loss: 1415757692928.0000\n",
      "Epoch 1168/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1200347938816.0000 - val_loss: 1414886850560.0000\n",
      "Epoch 1169/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1199596503040.0000 - val_loss: 1414046023680.0000\n",
      "Epoch 1170/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1198887403520.0000 - val_loss: 1413208866816.0000\n",
      "Epoch 1171/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1198141341696.0000 - val_loss: 1412388749312.0000\n",
      "Epoch 1172/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1197440499712.0000 - val_loss: 1411557621760.0000\n",
      "Epoch 1173/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1196703875072.0000 - val_loss: 1410768044032.0000\n",
      "Epoch 1174/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1196004081664.0000 - val_loss: 1409937571840.0000\n",
      "Epoch 1175/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1195284627456.0000 - val_loss: 1409103167488.0000\n",
      "Epoch 1176/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1194567139328.0000 - val_loss: 1408245432320.0000\n",
      "Epoch 1177/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1193814917120.0000 - val_loss: 1407435669504.0000\n",
      "Epoch 1178/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1193086156800.0000 - val_loss: 1406624333824.0000\n",
      "Epoch 1179/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1192361328640.0000 - val_loss: 1405776429056.0000\n",
      "Epoch 1180/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1191613038592.0000 - val_loss: 1404908077056.0000\n",
      "Epoch 1181/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1190852558848.0000 - val_loss: 1404037890048.0000\n",
      "Epoch 1182/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1190103875584.0000 - val_loss: 1403191427072.0000\n",
      "Epoch 1183/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1189366988800.0000 - val_loss: 1402339065856.0000\n",
      "Epoch 1184/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1188609261568.0000 - val_loss: 1401482641408.0000\n",
      "Epoch 1185/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1187866214400.0000 - val_loss: 1400616517632.0000\n",
      "Epoch 1186/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1187106652160.0000 - val_loss: 1399794171904.0000\n",
      "Epoch 1187/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1186391392256.0000 - val_loss: 1398936305664.0000\n",
      "Epoch 1188/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1185627635712.0000 - val_loss: 1398087876608.0000\n",
      "Epoch 1189/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1184870170624.0000 - val_loss: 1397234204672.0000\n",
      "Epoch 1190/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1184143245312.0000 - val_loss: 1396343701504.0000\n",
      "Epoch 1191/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1183363891200.0000 - val_loss: 1395473776640.0000\n",
      "Epoch 1192/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1182604984320.0000 - val_loss: 1394606211072.0000\n",
      "Epoch 1193/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1181852368896.0000 - val_loss: 1393737203712.0000\n",
      "Epoch 1194/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1181088088064.0000 - val_loss: 1392879861760.0000\n",
      "Epoch 1195/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1180347269120.0000 - val_loss: 1392016752640.0000\n",
      "Epoch 1196/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1179597406208.0000 - val_loss: 1391170289664.0000\n",
      "Epoch 1197/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1178874544128.0000 - val_loss: 1390324219904.0000\n",
      "Epoch 1198/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1178127171584.0000 - val_loss: 1389516161024.0000\n",
      "Epoch 1199/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1177414270976.0000 - val_loss: 1388698533888.0000\n",
      "Epoch 1200/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1176699928576.0000 - val_loss: 1387824152576.0000\n",
      "Epoch 1201/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1175920705536.0000 - val_loss: 1386988175360.0000\n",
      "Epoch 1202/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1175177789440.0000 - val_loss: 1386115629056.0000\n",
      "Epoch 1203/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1174418620416.0000 - val_loss: 1385211887616.0000\n",
      "Epoch 1204/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1173642149888.0000 - val_loss: 1384344059904.0000\n",
      "Epoch 1205/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1172878000128.0000 - val_loss: 1383521189888.0000\n",
      "Epoch 1206/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1172148977664.0000 - val_loss: 1382658342912.0000\n",
      "Epoch 1207/2000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1171397148672.0000 - val_loss: 1381788024832.0000\n",
      "Epoch 1208/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1170618318848.0000 - val_loss: 1380938416128.0000\n",
      "Epoch 1209/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1169895325696.0000 - val_loss: 1380070850560.0000\n",
      "Epoch 1210/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1169121476608.0000 - val_loss: 1379199483904.0000\n",
      "Epoch 1211/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1168379609088.0000 - val_loss: 1378314354688.0000\n",
      "Epoch 1212/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1167599730688.0000 - val_loss: 1377484931072.0000\n",
      "Epoch 1213/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1166868480000.0000 - val_loss: 1376601505792.0000\n",
      "Epoch 1214/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1166079295488.0000 - val_loss: 1375717031936.0000\n",
      "Epoch 1215/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1165337296896.0000 - val_loss: 1374853529600.0000\n",
      "Epoch 1216/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1164584812544.0000 - val_loss: 1374020304896.0000\n",
      "Epoch 1217/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1163841241088.0000 - val_loss: 1373141336064.0000\n",
      "Epoch 1218/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1163067785216.0000 - val_loss: 1372307718144.0000\n",
      "Epoch 1219/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1162357506048.0000 - val_loss: 1371468857344.0000\n",
      "Epoch 1220/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1161610526720.0000 - val_loss: 1370632486912.0000\n",
      "Epoch 1221/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1160891203584.0000 - val_loss: 1369770819584.0000\n",
      "Epoch 1222/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1160127709184.0000 - val_loss: 1368915574784.0000\n",
      "Epoch 1223/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1159397376000.0000 - val_loss: 1368062427136.0000\n",
      "Epoch 1224/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1158639517696.0000 - val_loss: 1367210852352.0000\n",
      "Epoch 1225/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1157888999424.0000 - val_loss: 1366331228160.0000\n",
      "Epoch 1226/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1157115412480.0000 - val_loss: 1365466152960.0000\n",
      "Epoch 1227/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1156379967488.0000 - val_loss: 1364603174912.0000\n",
      "Epoch 1228/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1155632726016.0000 - val_loss: 1363746881536.0000\n",
      "Epoch 1229/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1154880372736.0000 - val_loss: 1362912346112.0000\n",
      "Epoch 1230/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1154135359488.0000 - val_loss: 1362082922496.0000\n",
      "Epoch 1231/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1153398210560.0000 - val_loss: 1361230430208.0000\n",
      "Epoch 1232/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1152637206528.0000 - val_loss: 1360363126784.0000\n",
      "Epoch 1233/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1151905038336.0000 - val_loss: 1359472885760.0000\n",
      "Epoch 1234/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1151134728192.0000 - val_loss: 1358640709632.0000\n",
      "Epoch 1235/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1150424449024.0000 - val_loss: 1357797916672.0000\n",
      "Epoch 1236/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1149689790464.0000 - val_loss: 1356968361984.0000\n",
      "Epoch 1237/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1148943204352.0000 - val_loss: 1356125700096.0000\n",
      "Epoch 1238/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1148199763968.0000 - val_loss: 1355224580096.0000\n",
      "Epoch 1239/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1147423293440.0000 - val_loss: 1354374053888.0000\n",
      "Epoch 1240/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1146667794432.0000 - val_loss: 1353513959424.0000\n",
      "Epoch 1241/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1145932742656.0000 - val_loss: 1352662908928.0000\n",
      "Epoch 1242/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1145221283840.0000 - val_loss: 1351801110528.0000\n",
      "Epoch 1243/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1144448745472.0000 - val_loss: 1350963953664.0000\n",
      "Epoch 1244/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1143716839424.0000 - val_loss: 1350068207616.0000\n",
      "Epoch 1245/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1142940499968.0000 - val_loss: 1349221744640.0000\n",
      "Epoch 1246/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1142188277760.0000 - val_loss: 1348359290880.0000\n",
      "Epoch 1247/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1141435531264.0000 - val_loss: 1347531177984.0000\n",
      "Epoch 1248/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1140701528064.0000 - val_loss: 1346675015680.0000\n",
      "Epoch 1249/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1139956645888.0000 - val_loss: 1345828159488.0000\n",
      "Epoch 1250/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1139219890176.0000 - val_loss: 1344957448192.0000\n",
      "Epoch 1251/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1138454560768.0000 - val_loss: 1344117276672.0000\n",
      "Epoch 1252/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1137728028672.0000 - val_loss: 1343252070400.0000\n",
      "Epoch 1253/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1136963616768.0000 - val_loss: 1342406918144.0000\n",
      "Epoch 1254/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1136203792384.0000 - val_loss: 1341568843776.0000\n",
      "Epoch 1255/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1135479357440.0000 - val_loss: 1340689743872.0000\n",
      "Epoch 1256/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1134690041856.0000 - val_loss: 1339794653184.0000\n",
      "Epoch 1257/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1133919862784.0000 - val_loss: 1338896416768.0000\n",
      "Epoch 1258/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1133131071488.0000 - val_loss: 1337992544256.0000\n",
      "Epoch 1259/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1132351717376.0000 - val_loss: 1337119735808.0000\n",
      "Epoch 1260/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1131599101952.0000 - val_loss: 1336223858688.0000\n",
      "Epoch 1261/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1130822893568.0000 - val_loss: 1335347773440.0000\n",
      "Epoch 1262/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1130063462400.0000 - val_loss: 1334467231744.0000\n",
      "Epoch 1263/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1129279389696.0000 - val_loss: 1333616836608.0000\n",
      "Epoch 1264/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1128528478208.0000 - val_loss: 1332698677248.0000\n",
      "Epoch 1265/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1127713603584.0000 - val_loss: 1331845791744.0000\n",
      "Epoch 1266/2000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1126986547200.0000 - val_loss: 1330939559936.0000\n",
      "Epoch 1267/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1126199590912.0000 - val_loss: 1330048401408.0000\n",
      "Epoch 1268/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1125412372480.0000 - val_loss: 1329174282240.0000\n",
      "Epoch 1269/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1124651368448.0000 - val_loss: 1328317595648.0000\n",
      "Epoch 1270/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1123928113152.0000 - val_loss: 1327415296000.0000\n",
      "Epoch 1271/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1123126345728.0000 - val_loss: 1326570668032.0000\n",
      "Epoch 1272/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1122402304000.0000 - val_loss: 1325667844096.0000\n",
      "Epoch 1273/2000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1121614168064.0000 - val_loss: 1324814696448.0000\n",
      "Epoch 1274/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1120849887232.0000 - val_loss: 1323948703744.0000\n",
      "Epoch 1275/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1120115359744.0000 - val_loss: 1323074584576.0000\n",
      "Epoch 1276/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1119362744320.0000 - val_loss: 1322219077632.0000\n",
      "Epoch 1277/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1118602657792.0000 - val_loss: 1321363439616.0000\n",
      "Epoch 1278/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1117838114816.0000 - val_loss: 1320501248000.0000\n",
      "Epoch 1279/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1117109092352.0000 - val_loss: 1319628701696.0000\n",
      "Epoch 1280/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1116352675840.0000 - val_loss: 1318784466944.0000\n",
      "Epoch 1281/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1115627585536.0000 - val_loss: 1317925814272.0000\n",
      "Epoch 1282/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1114861993984.0000 - val_loss: 1317084332032.0000\n",
      "Epoch 1283/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1114109247488.0000 - val_loss: 1316196319232.0000\n",
      "Epoch 1284/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1113343393792.0000 - val_loss: 1315354312704.0000\n",
      "Epoch 1285/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1112614109184.0000 - val_loss: 1314468659200.0000\n",
      "Epoch 1286/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1111850745856.0000 - val_loss: 1313595588608.0000\n",
      "Epoch 1287/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1111094460416.0000 - val_loss: 1312751484928.0000\n",
      "Epoch 1288/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1110353641472.0000 - val_loss: 1311909871616.0000\n",
      "Epoch 1289/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1109621342208.0000 - val_loss: 1311044665344.0000\n",
      "Epoch 1290/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1108858372096.0000 - val_loss: 1310189027328.0000\n",
      "Epoch 1291/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1108103659520.0000 - val_loss: 1309304946688.0000\n",
      "Epoch 1292/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1107327713280.0000 - val_loss: 1308431745024.0000\n",
      "Epoch 1293/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1106581258240.0000 - val_loss: 1307565228032.0000\n",
      "Epoch 1294/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1105818943488.0000 - val_loss: 1306692419584.0000\n",
      "Epoch 1295/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1105075896320.0000 - val_loss: 1305829310464.0000\n",
      "Epoch 1296/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1104311222272.0000 - val_loss: 1304991105024.0000\n",
      "Epoch 1297/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1103588491264.0000 - val_loss: 1304105451520.0000\n",
      "Epoch 1298/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1102824210432.0000 - val_loss: 1303240114176.0000\n",
      "Epoch 1299/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1102044463104.0000 - val_loss: 1302404923392.0000\n",
      "Epoch 1300/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1101311639552.0000 - val_loss: 1301505638400.0000\n",
      "Epoch 1301/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1100536479744.0000 - val_loss: 1300606091264.0000\n",
      "Epoch 1302/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1099764203520.0000 - val_loss: 1299744817152.0000\n",
      "Epoch 1303/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1099024039936.0000 - val_loss: 1298861785088.0000\n",
      "Epoch 1304/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1098236035072.0000 - val_loss: 1298000642048.0000\n",
      "Epoch 1305/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1097484795904.0000 - val_loss: 1297124294656.0000\n",
      "Epoch 1306/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1096721629184.0000 - val_loss: 1296284123136.0000\n",
      "Epoch 1307/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1095968292864.0000 - val_loss: 1295405416448.0000\n",
      "Epoch 1308/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1095200145408.0000 - val_loss: 1294496301056.0000\n",
      "Epoch 1309/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1094441238528.0000 - val_loss: 1293596491776.0000\n",
      "Epoch 1310/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1093637177344.0000 - val_loss: 1292726697984.0000\n",
      "Epoch 1311/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1092884758528.0000 - val_loss: 1291857166336.0000\n",
      "Epoch 1312/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1092129980416.0000 - val_loss: 1290971906048.0000\n",
      "Epoch 1313/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1091356065792.0000 - val_loss: 1290106568704.0000\n",
      "Epoch 1314/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1090605088768.0000 - val_loss: 1289215279104.0000\n",
      "Epoch 1315/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1089842970624.0000 - val_loss: 1288337227776.0000\n",
      "Epoch 1316/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1089070891008.0000 - val_loss: 1287465205760.0000\n",
      "Epoch 1317/2000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1088312836096.0000 - val_loss: 1286581649408.0000\n",
      "Epoch 1318/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1087532892160.0000 - val_loss: 1285713428480.0000\n",
      "Epoch 1319/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1086759501824.0000 - val_loss: 1284831707136.0000\n",
      "Epoch 1320/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1085992665088.0000 - val_loss: 1283929538560.0000\n",
      "Epoch 1321/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1085224910848.0000 - val_loss: 1283029204992.0000\n",
      "Epoch 1322/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1084435595264.0000 - val_loss: 1282152333312.0000\n",
      "Epoch 1323/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1083683241984.0000 - val_loss: 1281269301248.0000\n",
      "Epoch 1324/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1082895761408.0000 - val_loss: 1280430309376.0000\n",
      "Epoch 1325/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1082159726592.0000 - val_loss: 1279545966592.0000\n",
      "Epoch 1326/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1081381945344.0000 - val_loss: 1278615224320.0000\n",
      "Epoch 1327/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1080598986752.0000 - val_loss: 1277694836736.0000\n",
      "Epoch 1328/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1079798333440.0000 - val_loss: 1276779560960.0000\n",
      "Epoch 1329/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1078997942272.0000 - val_loss: 1275910553600.0000\n",
      "Epoch 1330/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1078227697664.0000 - val_loss: 1275014021120.0000\n",
      "Epoch 1331/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1077468921856.0000 - val_loss: 1274083540992.0000\n",
      "Epoch 1332/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1076653129728.0000 - val_loss: 1273240092672.0000\n",
      "Epoch 1333/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1075906019328.0000 - val_loss: 1272360206336.0000\n",
      "Epoch 1334/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1075148488704.0000 - val_loss: 1271478747136.0000\n",
      "Epoch 1335/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1074386173952.0000 - val_loss: 1270562553856.0000\n",
      "Epoch 1336/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1073581785088.0000 - val_loss: 1269664710656.0000\n",
      "Epoch 1337/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1072788930560.0000 - val_loss: 1268790198272.0000\n",
      "Epoch 1338/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1072040771584.0000 - val_loss: 1267901005824.0000\n",
      "Epoch 1339/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1071269216256.0000 - val_loss: 1267031605248.0000\n",
      "Epoch 1340/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1070486323200.0000 - val_loss: 1266127208448.0000\n",
      "Epoch 1341/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1069705527296.0000 - val_loss: 1265245487104.0000\n",
      "Epoch 1342/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1068957433856.0000 - val_loss: 1264362192896.0000\n",
      "Epoch 1343/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1068200230912.0000 - val_loss: 1263502229504.0000\n",
      "Epoch 1344/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1067477630976.0000 - val_loss: 1262635319296.0000\n",
      "Epoch 1345/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1066704371712.0000 - val_loss: 1261818347520.0000\n",
      "Epoch 1346/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1065964732416.0000 - val_loss: 1260999147520.0000\n",
      "Epoch 1347/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1065272147968.0000 - val_loss: 1260100124672.0000\n",
      "Epoch 1348/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1064496594944.0000 - val_loss: 1259228364800.0000\n",
      "Epoch 1349/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1063722942464.0000 - val_loss: 1258367352832.0000\n",
      "Epoch 1350/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1062962069504.0000 - val_loss: 1257497296896.0000\n",
      "Epoch 1351/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1062207488000.0000 - val_loss: 1256569438208.0000\n",
      "Epoch 1352/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1061398970368.0000 - val_loss: 1255708426240.0000\n",
      "Epoch 1353/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1060632657920.0000 - val_loss: 1254800490496.0000\n",
      "Epoch 1354/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1059860381696.0000 - val_loss: 1253925847040.0000\n",
      "Epoch 1355/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1059094855680.0000 - val_loss: 1253060378624.0000\n",
      "Epoch 1356/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1058339422208.0000 - val_loss: 1252163321856.0000\n",
      "Epoch 1357/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1057557970944.0000 - val_loss: 1251289333760.0000\n",
      "Epoch 1358/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1056799391744.0000 - val_loss: 1250354921472.0000\n",
      "Epoch 1359/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1056002146304.0000 - val_loss: 1249444495360.0000\n",
      "Epoch 1360/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1055227117568.0000 - val_loss: 1248543244288.0000\n",
      "Epoch 1361/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1054430658560.0000 - val_loss: 1247683805184.0000\n",
      "Epoch 1362/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1053690363904.0000 - val_loss: 1246798020608.0000\n",
      "Epoch 1363/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1052916252672.0000 - val_loss: 1245923639296.0000\n",
      "Epoch 1364/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1052136964096.0000 - val_loss: 1245067870208.0000\n",
      "Epoch 1365/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1051366391808.0000 - val_loss: 1244157181952.0000\n",
      "Epoch 1366/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1050596737024.0000 - val_loss: 1243261435904.0000\n",
      "Epoch 1367/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1049823543296.0000 - val_loss: 1242374995968.0000\n",
      "Epoch 1368/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1049070665728.0000 - val_loss: 1241470992384.0000\n",
      "Epoch 1369/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1048275976192.0000 - val_loss: 1240616665088.0000\n",
      "Epoch 1370/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1047524868096.0000 - val_loss: 1239700602880.0000\n",
      "Epoch 1371/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1046739353600.0000 - val_loss: 1238807609344.0000\n",
      "Epoch 1372/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1045959081984.0000 - val_loss: 1237939257344.0000\n",
      "Epoch 1373/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1045203189760.0000 - val_loss: 1237047836672.0000\n",
      "Epoch 1374/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1044428619776.0000 - val_loss: 1236202422272.0000\n",
      "Epoch 1375/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1043702939648.0000 - val_loss: 1235322929152.0000\n",
      "Epoch 1376/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1042923847680.0000 - val_loss: 1234483937280.0000\n",
      "Epoch 1377/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1042193907712.0000 - val_loss: 1233599856640.0000\n",
      "Epoch 1378/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1041427988480.0000 - val_loss: 1232659546112.0000\n",
      "Epoch 1379/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1040611672064.0000 - val_loss: 1231783723008.0000\n",
      "Epoch 1380/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1039847981056.0000 - val_loss: 1230924414976.0000\n",
      "Epoch 1381/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1039096545280.0000 - val_loss: 1230035746816.0000\n",
      "Epoch 1382/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1038349369344.0000 - val_loss: 1229155860480.0000\n",
      "Epoch 1383/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1037578272768.0000 - val_loss: 1228263653376.0000\n",
      "Epoch 1384/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1036816220160.0000 - val_loss: 1227383504896.0000\n",
      "Epoch 1385/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1036037455872.0000 - val_loss: 1226530357248.0000\n",
      "Epoch 1386/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1035293229056.0000 - val_loss: 1225633038336.0000\n",
      "Epoch 1387/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1034526982144.0000 - val_loss: 1224751448064.0000\n",
      "Epoch 1388/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1033763684352.0000 - val_loss: 1223888470016.0000\n",
      "Epoch 1389/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1032995602432.0000 - val_loss: 1223030079488.0000\n",
      "Epoch 1390/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1032255373312.0000 - val_loss: 1222122143744.0000\n",
      "Epoch 1391/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1031454982144.0000 - val_loss: 1221266636800.0000\n",
      "Epoch 1392/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1030689128448.0000 - val_loss: 1220365123584.0000\n",
      "Epoch 1393/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1029878644736.0000 - val_loss: 1219419963392.0000\n",
      "Epoch 1394/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1029119541248.0000 - val_loss: 1218494070784.0000\n",
      "Epoch 1395/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1028310433792.0000 - val_loss: 1217620213760.0000\n",
      "Epoch 1396/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1027560505344.0000 - val_loss: 1216710967296.0000\n",
      "Epoch 1397/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1026765619200.0000 - val_loss: 1215840518144.0000\n",
      "Epoch 1398/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1026013069312.0000 - val_loss: 1214965612544.0000\n",
      "Epoch 1399/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1025250689024.0000 - val_loss: 1214100668416.0000\n",
      "Epoch 1400/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1024500629504.0000 - val_loss: 1213201645568.0000\n",
      "Epoch 1401/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1023714000896.0000 - val_loss: 1212346400768.0000\n",
      "Epoch 1402/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1022988976128.0000 - val_loss: 1211479621632.0000\n",
      "Epoch 1403/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1022228561920.0000 - val_loss: 1210600259584.0000\n",
      "Epoch 1404/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1021453402112.0000 - val_loss: 1209740296192.0000\n",
      "Epoch 1405/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1020703866880.0000 - val_loss: 1208873648128.0000\n",
      "Epoch 1406/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1019952103424.0000 - val_loss: 1207984193536.0000\n",
      "Epoch 1407/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1019187101696.0000 - val_loss: 1207118462976.0000\n",
      "Epoch 1408/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1018426753024.0000 - val_loss: 1206227959808.0000\n",
      "Epoch 1409/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1017661227008.0000 - val_loss: 1205332869120.0000\n",
      "Epoch 1410/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1016904876032.0000 - val_loss: 1204419297280.0000\n",
      "Epoch 1411/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1016101011456.0000 - val_loss: 1203543867392.0000\n",
      "Epoch 1412/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1015337123840.0000 - val_loss: 1202673025024.0000\n",
      "Epoch 1413/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1014585360384.0000 - val_loss: 1201812406272.0000\n",
      "Epoch 1414/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1013831630848.0000 - val_loss: 1200939728896.0000\n",
      "Epoch 1415/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1013082882048.0000 - val_loss: 1200057090048.0000\n",
      "Epoch 1416/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1012315717632.0000 - val_loss: 1199182839808.0000\n",
      "Epoch 1417/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1011522928640.0000 - val_loss: 1198292598784.0000\n",
      "Epoch 1418/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1010753208320.0000 - val_loss: 1197394362368.0000\n",
      "Epoch 1419/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1009979752448.0000 - val_loss: 1196492324864.0000\n",
      "Epoch 1420/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1009201053696.0000 - val_loss: 1195601952768.0000\n",
      "Epoch 1421/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1008438870016.0000 - val_loss: 1194683006976.0000\n",
      "Epoch 1422/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1007635726336.0000 - val_loss: 1193793814528.0000\n",
      "Epoch 1423/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1006873346048.0000 - val_loss: 1192913797120.0000\n",
      "Epoch 1424/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1006083768320.0000 - val_loss: 1192003371008.0000\n",
      "Epoch 1425/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1005293535232.0000 - val_loss: 1191114702848.0000\n",
      "Epoch 1426/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1004515885056.0000 - val_loss: 1190214369280.0000\n",
      "Epoch 1427/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1003770609664.0000 - val_loss: 1189281398784.0000\n",
      "Epoch 1428/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1002963599360.0000 - val_loss: 1188396138496.0000\n",
      "Epoch 1429/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1002180313088.0000 - val_loss: 1187498295296.0000\n",
      "Epoch 1430/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1001412362240.0000 - val_loss: 1186589442048.0000\n",
      "Epoch 1431/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1000607514624.0000 - val_loss: 1185689108480.0000\n",
      "Epoch 1432/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 999834648576.0000 - val_loss: 1184779730944.0000\n",
      "Epoch 1433/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 999047102464.0000 - val_loss: 1183857639424.0000\n",
      "Epoch 1434/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 998269452288.0000 - val_loss: 1182965956608.0000\n",
      "Epoch 1435/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 997476597760.0000 - val_loss: 1182075322368.0000\n",
      "Epoch 1436/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 996693114880.0000 - val_loss: 1181198057472.0000\n",
      "Epoch 1437/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 995949674496.0000 - val_loss: 1180299034624.0000\n",
      "Epoch 1438/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 995167567872.0000 - val_loss: 1179418755072.0000\n",
      "Epoch 1439/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 994399748096.0000 - val_loss: 1178505052160.0000\n",
      "Epoch 1440/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 993631272960.0000 - val_loss: 1177624117248.0000\n",
      "Epoch 1441/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 992868106240.0000 - val_loss: 1176773066752.0000\n",
      "Epoch 1442/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 992123289600.0000 - val_loss: 1175907205120.0000\n",
      "Epoch 1443/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 991359467520.0000 - val_loss: 1175018274816.0000\n",
      "Epoch 1444/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 990571593728.0000 - val_loss: 1174134718464.0000\n",
      "Epoch 1445/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 989820944384.0000 - val_loss: 1173211447296.0000\n",
      "Epoch 1446/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 989030121472.0000 - val_loss: 1172323172352.0000\n",
      "Epoch 1447/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 988260925440.0000 - val_loss: 1171408814080.0000\n",
      "Epoch 1448/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 987469840384.0000 - val_loss: 1170525126656.0000\n",
      "Epoch 1449/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 986718535680.0000 - val_loss: 1169626628096.0000\n",
      "Epoch 1450/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 985929744384.0000 - val_loss: 1168801529856.0000\n",
      "Epoch 1451/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 985231065088.0000 - val_loss: 1167943794688.0000\n",
      "Epoch 1452/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 984484478976.0000 - val_loss: 1167087763456.0000\n",
      "Epoch 1453/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 983749427200.0000 - val_loss: 1166203682816.0000\n",
      "Epoch 1454/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 982945759232.0000 - val_loss: 1165317636096.0000\n",
      "Epoch 1455/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 982193733632.0000 - val_loss: 1164421365760.0000\n",
      "Epoch 1456/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 981444788224.0000 - val_loss: 1163502157824.0000\n",
      "Epoch 1457/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 980631814144.0000 - val_loss: 1162653466624.0000\n",
      "Epoch 1458/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 979858685952.0000 - val_loss: 1161766764544.0000\n",
      "Epoch 1459/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 979120291840.0000 - val_loss: 1160869576704.0000\n",
      "Epoch 1460/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 978338316288.0000 - val_loss: 1159992442880.0000\n",
      "Epoch 1461/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 977574821888.0000 - val_loss: 1159128547328.0000\n",
      "Epoch 1462/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 976830791680.0000 - val_loss: 1158228606976.0000\n",
      "Epoch 1463/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 976081059840.0000 - val_loss: 1157284757504.0000\n",
      "Epoch 1464/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 975247441920.0000 - val_loss: 1156455858176.0000\n",
      "Epoch 1465/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 974537883648.0000 - val_loss: 1155578068992.0000\n",
      "Epoch 1466/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 973792018432.0000 - val_loss: 1154727411712.0000\n",
      "Epoch 1467/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 973042024448.0000 - val_loss: 1153905065984.0000\n",
      "Epoch 1468/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 972328009728.0000 - val_loss: 1152999227392.0000\n",
      "Epoch 1469/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 971524800512.0000 - val_loss: 1152148045824.0000\n",
      "Epoch 1470/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 970783588352.0000 - val_loss: 1151243911168.0000\n",
      "Epoch 1471/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 970006724608.0000 - val_loss: 1150364286976.0000\n",
      "Epoch 1472/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 969272786944.0000 - val_loss: 1149479813120.0000\n",
      "Epoch 1473/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 968486682624.0000 - val_loss: 1148578562048.0000\n",
      "Epoch 1474/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 967711064064.0000 - val_loss: 1147700248576.0000\n",
      "Epoch 1475/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 966955106304.0000 - val_loss: 1146827571200.0000\n",
      "Epoch 1476/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 966212124672.0000 - val_loss: 1145931431936.0000\n",
      "Epoch 1477/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 965434867712.0000 - val_loss: 1145096503296.0000\n",
      "Epoch 1478/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 964702371840.0000 - val_loss: 1144235491328.0000\n",
      "Epoch 1479/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 963941302272.0000 - val_loss: 1143371726848.0000\n",
      "Epoch 1480/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 963217588224.0000 - val_loss: 1142488039424.0000\n",
      "Epoch 1481/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 962463399936.0000 - val_loss: 1141619163136.0000\n",
      "Epoch 1482/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 961704296448.0000 - val_loss: 1140745175040.0000\n",
      "Epoch 1483/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 960962953216.0000 - val_loss: 1139858997248.0000\n",
      "Epoch 1484/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 960173441024.0000 - val_loss: 1139008471040.0000\n",
      "Epoch 1485/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 959443697664.0000 - val_loss: 1138126749696.0000\n",
      "Epoch 1486/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 958665850880.0000 - val_loss: 1137260101632.0000\n",
      "Epoch 1487/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 957894164480.0000 - val_loss: 1136352428032.0000\n",
      "Epoch 1488/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 957137420288.0000 - val_loss: 1135437152256.0000\n",
      "Epoch 1489/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 956341485568.0000 - val_loss: 1134540881920.0000\n",
      "Epoch 1490/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 955572813824.0000 - val_loss: 1133672136704.0000\n",
      "Epoch 1491/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 954824196096.0000 - val_loss: 1132802605056.0000\n",
      "Epoch 1492/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 954082000896.0000 - val_loss: 1131916558336.0000\n",
      "Epoch 1493/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 953320669184.0000 - val_loss: 1131030642688.0000\n",
      "Epoch 1494/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 952560844800.0000 - val_loss: 1130166616064.0000\n",
      "Epoch 1495/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 951798464512.0000 - val_loss: 1129315434496.0000\n",
      "Epoch 1496/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 951031824384.0000 - val_loss: 1128429125632.0000\n",
      "Epoch 1497/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 950271606784.0000 - val_loss: 1127526694912.0000\n",
      "Epoch 1498/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 949500575744.0000 - val_loss: 1126635798528.0000\n",
      "Epoch 1499/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 948747501568.0000 - val_loss: 1125764300800.0000\n",
      "Epoch 1500/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 947988267008.0000 - val_loss: 1124889264128.0000\n",
      "Epoch 1501/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 947245678592.0000 - val_loss: 1124018290688.0000\n",
      "Epoch 1502/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 946486378496.0000 - val_loss: 1123184410624.0000\n",
      "Epoch 1503/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 945744904192.0000 - val_loss: 1122271363072.0000\n",
      "Epoch 1504/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 944973479936.0000 - val_loss: 1121388855296.0000\n",
      "Epoch 1505/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 944191438848.0000 - val_loss: 1120503201792.0000\n",
      "Epoch 1506/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 943447736320.0000 - val_loss: 1119604834304.0000\n",
      "Epoch 1507/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 942651473920.0000 - val_loss: 1118753128448.0000\n",
      "Epoch 1508/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 941924286464.0000 - val_loss: 1117839818752.0000\n",
      "Epoch 1509/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 941128482816.0000 - val_loss: 1116965175296.0000\n",
      "Epoch 1510/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 940357976064.0000 - val_loss: 1116086730752.0000\n",
      "Epoch 1511/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 939634065408.0000 - val_loss: 1115161755648.0000\n",
      "Epoch 1512/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 938853007360.0000 - val_loss: 1114280820736.0000\n",
      "Epoch 1513/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 938073325568.0000 - val_loss: 1113445629952.0000\n",
      "Epoch 1514/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 937336045568.0000 - val_loss: 1112559976448.0000\n",
      "Epoch 1515/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 936583954432.0000 - val_loss: 1111637884928.0000\n",
      "Epoch 1516/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 935767638016.0000 - val_loss: 1110790897664.0000\n",
      "Epoch 1517/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 935035928576.0000 - val_loss: 1109881651200.0000\n",
      "Epoch 1518/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 934263062528.0000 - val_loss: 1109000060928.0000\n",
      "Epoch 1519/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 933516935168.0000 - val_loss: 1108106674176.0000\n",
      "Epoch 1520/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 932745314304.0000 - val_loss: 1107249856512.0000\n",
      "Epoch 1521/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 932010262528.0000 - val_loss: 1106365120512.0000\n",
      "Epoch 1522/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 931230777344.0000 - val_loss: 1105509482496.0000\n",
      "Epoch 1523/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 930492776448.0000 - val_loss: 1104617537536.0000\n",
      "Epoch 1524/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 929727643648.0000 - val_loss: 1103726116864.0000\n",
      "Epoch 1525/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 928974569472.0000 - val_loss: 1102854488064.0000\n",
      "Epoch 1526/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 928217694208.0000 - val_loss: 1101979582464.0000\n",
      "Epoch 1527/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 927433359360.0000 - val_loss: 1101109002240.0000\n",
      "Epoch 1528/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 926695882752.0000 - val_loss: 1100235931648.0000\n",
      "Epoch 1529/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 925925703680.0000 - val_loss: 1099364433920.0000\n",
      "Epoch 1530/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 925171974144.0000 - val_loss: 1098450599936.0000\n",
      "Epoch 1531/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 924395831296.0000 - val_loss: 1097541681152.0000\n",
      "Epoch 1532/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 923611955200.0000 - val_loss: 1096665923584.0000\n",
      "Epoch 1533/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 922876510208.0000 - val_loss: 1095714603008.0000\n",
      "Epoch 1534/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 922064781312.0000 - val_loss: 1094828621824.0000\n",
      "Epoch 1535/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 921294012416.0000 - val_loss: 1093986353152.0000\n",
      "Epoch 1536/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 920566169600.0000 - val_loss: 1093126258688.0000\n",
      "Epoch 1537/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 919816044544.0000 - val_loss: 1092272193536.0000\n",
      "Epoch 1538/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 919053860864.0000 - val_loss: 1091397615616.0000\n",
      "Epoch 1539/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 918339190784.0000 - val_loss: 1090452193280.0000\n",
      "Epoch 1540/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 917508521984.0000 - val_loss: 1089605795840.0000\n",
      "Epoch 1541/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 916759379968.0000 - val_loss: 1088771850240.0000\n",
      "Epoch 1542/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 916049559552.0000 - val_loss: 1087859654656.0000\n",
      "Epoch 1543/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 915274334208.0000 - val_loss: 1086982520832.0000\n",
      "Epoch 1544/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 914527092736.0000 - val_loss: 1086128259072.0000\n",
      "Epoch 1545/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 913783980032.0000 - val_loss: 1085250863104.0000\n",
      "Epoch 1546/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 913021075456.0000 - val_loss: 1084384280576.0000\n",
      "Epoch 1547/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 912273178624.0000 - val_loss: 1083483422720.0000\n",
      "Epoch 1548/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 911501754368.0000 - val_loss: 1082627588096.0000\n",
      "Epoch 1549/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 910784856064.0000 - val_loss: 1081758711808.0000\n",
      "Epoch 1550/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 910014218240.0000 - val_loss: 1080950456320.0000\n",
      "Epoch 1551/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 909312983040.0000 - val_loss: 1080068603904.0000\n",
      "Epoch 1552/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 908557549568.0000 - val_loss: 1079196057600.0000\n",
      "Epoch 1553/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 907796611072.0000 - val_loss: 1078340419584.0000\n",
      "Epoch 1554/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 907060051968.0000 - val_loss: 1077457190912.0000\n",
      "Epoch 1555/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 906303569920.0000 - val_loss: 1076561117184.0000\n",
      "Epoch 1556/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 905527361536.0000 - val_loss: 1075639549952.0000\n",
      "Epoch 1557/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 904733851648.0000 - val_loss: 1074749636608.0000\n",
      "Epoch 1558/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 903978811392.0000 - val_loss: 1073860575232.0000\n",
      "Epoch 1559/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 903197491200.0000 - val_loss: 1073030430720.0000\n",
      "Epoch 1560/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 902471876608.0000 - val_loss: 1072125837312.0000\n",
      "Epoch 1561/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 901697568768.0000 - val_loss: 1071206105088.0000\n",
      "Epoch 1562/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 900933615616.0000 - val_loss: 1070321631232.0000\n",
      "Epoch 1563/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 900177723392.0000 - val_loss: 1069449019392.0000\n",
      "Epoch 1564/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 899402760192.0000 - val_loss: 1068580864000.0000\n",
      "Epoch 1565/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 898654470144.0000 - val_loss: 1067677974528.0000\n",
      "Epoch 1566/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 897877540864.0000 - val_loss: 1066803920896.0000\n",
      "Epoch 1567/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 897134231552.0000 - val_loss: 1065900703744.0000\n",
      "Epoch 1568/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 896369295360.0000 - val_loss: 1065030254592.0000\n",
      "Epoch 1569/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 895594594304.0000 - val_loss: 1064182743040.0000\n",
      "Epoch 1570/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 894875205632.0000 - val_loss: 1063257702400.0000\n",
      "Epoch 1571/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 894084186112.0000 - val_loss: 1062359728128.0000\n",
      "Epoch 1572/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 893299654656.0000 - val_loss: 1061465292800.0000\n",
      "Epoch 1573/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 892534652928.0000 - val_loss: 1060586913792.0000\n",
      "Epoch 1574/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 891771420672.0000 - val_loss: 1059703947264.0000\n",
      "Epoch 1575/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 891035582464.0000 - val_loss: 1058830548992.0000\n",
      "Epoch 1576/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 890274840576.0000 - val_loss: 1057948762112.0000\n",
      "Epoch 1577/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 889503940608.0000 - val_loss: 1057103937536.0000\n",
      "Epoch 1578/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 888781537280.0000 - val_loss: 1056227721216.0000\n",
      "Epoch 1579/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 888026693632.0000 - val_loss: 1055279742976.0000\n",
      "Epoch 1580/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 887208345600.0000 - val_loss: 1054428495872.0000\n",
      "Epoch 1581/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 886472114176.0000 - val_loss: 1053563092992.0000\n",
      "Epoch 1582/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 885712814080.0000 - val_loss: 1052641656832.0000\n",
      "Epoch 1583/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 884945518592.0000 - val_loss: 1051745255424.0000\n",
      "Epoch 1584/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 884175208448.0000 - val_loss: 1050859274240.0000\n",
      "Epoch 1585/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 883425869824.0000 - val_loss: 1049983647744.0000\n",
      "Epoch 1586/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 882646777856.0000 - val_loss: 1049102516224.0000\n",
      "Epoch 1587/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 881886953472.0000 - val_loss: 1048217387008.0000\n",
      "Epoch 1588/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 881120837632.0000 - val_loss: 1047323869184.0000\n",
      "Epoch 1589/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 880358850560.0000 - val_loss: 1046455779328.0000\n",
      "Epoch 1590/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 879625437184.0000 - val_loss: 1045609775104.0000\n",
      "Epoch 1591/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 878896939008.0000 - val_loss: 1044769472512.0000\n",
      "Epoch 1592/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 878158348288.0000 - val_loss: 1043893125120.0000\n",
      "Epoch 1593/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 877431357440.0000 - val_loss: 1043012124672.0000\n",
      "Epoch 1594/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 876672188416.0000 - val_loss: 1042139250688.0000\n",
      "Epoch 1595/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 875894210560.0000 - val_loss: 1041234591744.0000\n",
      "Epoch 1596/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 875091329024.0000 - val_loss: 1040309944320.0000\n",
      "Epoch 1597/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 874317545472.0000 - val_loss: 1039418261504.0000\n",
      "Epoch 1598/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 873564733440.0000 - val_loss: 1038548074496.0000\n",
      "Epoch 1599/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 872821030912.0000 - val_loss: 1037655474176.0000\n",
      "Epoch 1600/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 872067956736.0000 - val_loss: 1036805406720.0000\n",
      "Epoch 1601/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 871337230336.0000 - val_loss: 1035962613760.0000\n",
      "Epoch 1602/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 870606962688.0000 - val_loss: 1035090657280.0000\n",
      "Epoch 1603/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 869883772928.0000 - val_loss: 1034220863488.0000\n",
      "Epoch 1604/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 869136465920.0000 - val_loss: 1033395372032.0000\n",
      "Epoch 1605/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 868412489728.0000 - val_loss: 1032539734016.0000\n",
      "Epoch 1606/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 867667214336.0000 - val_loss: 1031681474560.0000\n",
      "Epoch 1607/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 866933342208.0000 - val_loss: 1030769999872.0000\n",
      "Epoch 1608/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 866138128384.0000 - val_loss: 1029910822912.0000\n",
      "Epoch 1609/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 865421819904.0000 - val_loss: 1028998430720.0000\n",
      "Epoch 1610/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 864628637696.0000 - val_loss: 1028117889024.0000\n",
      "Epoch 1611/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 863872548864.0000 - val_loss: 1027226599424.0000\n",
      "Epoch 1612/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 863101386752.0000 - val_loss: 1026394619904.0000\n",
      "Epoch 1613/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 862414503936.0000 - val_loss: 1025471283200.0000\n",
      "Epoch 1614/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 861609197568.0000 - val_loss: 1024608632832.0000\n",
      "Epoch 1615/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 860851208192.0000 - val_loss: 1023721078784.0000\n",
      "Epoch 1616/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 860096364544.0000 - val_loss: 1022861770752.0000\n",
      "Epoch 1617/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 859332870144.0000 - val_loss: 1021959274496.0000\n",
      "Epoch 1618/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 858562887680.0000 - val_loss: 1021080895488.0000\n",
      "Epoch 1619/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 857812959232.0000 - val_loss: 1020182528000.0000\n",
      "Epoch 1620/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 857041403904.0000 - val_loss: 1019348058112.0000\n",
      "Epoch 1621/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 856313298944.0000 - val_loss: 1018454212608.0000\n",
      "Epoch 1622/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 855566123008.0000 - val_loss: 1017557155840.0000\n",
      "Epoch 1623/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 854801842176.0000 - val_loss: 1016682840064.0000\n",
      "Epoch 1624/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 854063710208.0000 - val_loss: 1015818158080.0000\n",
      "Epoch 1625/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 853333049344.0000 - val_loss: 1014979690496.0000\n",
      "Epoch 1626/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 852597604352.0000 - val_loss: 1014104653824.0000\n",
      "Epoch 1627/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 851841187840.0000 - val_loss: 1013211856896.0000\n",
      "Epoch 1628/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 851069829120.0000 - val_loss: 1012293566464.0000\n",
      "Epoch 1629/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 850286346240.0000 - val_loss: 1011437207552.0000\n",
      "Epoch 1630/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 849555554304.0000 - val_loss: 1010566430720.0000\n",
      "Epoch 1631/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 848816701440.0000 - val_loss: 1009665703936.0000\n",
      "Epoch 1632/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 848049209344.0000 - val_loss: 1008817078272.0000\n",
      "Epoch 1633/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 847299805184.0000 - val_loss: 1007945842688.0000\n",
      "Epoch 1634/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 846559641600.0000 - val_loss: 1007073951744.0000\n",
      "Epoch 1635/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 845809254400.0000 - val_loss: 1006213070848.0000\n",
      "Epoch 1636/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 845037895680.0000 - val_loss: 1005317914624.0000\n",
      "Epoch 1637/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 844294520832.0000 - val_loss: 1004373606400.0000\n",
      "Epoch 1638/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 843500093440.0000 - val_loss: 1003488149504.0000\n",
      "Epoch 1639/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 842754097152.0000 - val_loss: 1002646274048.0000\n",
      "Epoch 1640/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 842022780928.0000 - val_loss: 1001819078656.0000\n",
      "Epoch 1641/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 841316302848.0000 - val_loss: 1000976678912.0000\n",
      "Epoch 1642/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 840586035200.0000 - val_loss: 1000092008448.0000\n",
      "Epoch 1643/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 839840890880.0000 - val_loss: 999199670272.0000\n",
      "Epoch 1644/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 839083622400.0000 - val_loss: 998341345280.0000\n",
      "Epoch 1645/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 838347718656.0000 - val_loss: 997497307136.0000\n",
      "Epoch 1646/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 837604474880.0000 - val_loss: 996614078464.0000\n",
      "Epoch 1647/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 836862607360.0000 - val_loss: 995738255360.0000\n",
      "Epoch 1648/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 836101931008.0000 - val_loss: 994869903360.0000\n",
      "Epoch 1649/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 835343876096.0000 - val_loss: 993987395584.0000\n",
      "Epoch 1650/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 834603188224.0000 - val_loss: 993118912512.0000\n",
      "Epoch 1651/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 833874558976.0000 - val_loss: 992255868928.0000\n",
      "Epoch 1652/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 833139769344.0000 - val_loss: 991403900928.0000\n",
      "Epoch 1653/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 832422871040.0000 - val_loss: 990536597504.0000\n",
      "Epoch 1654/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 831664619520.0000 - val_loss: 989726048256.0000\n",
      "Epoch 1655/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 830952636416.0000 - val_loss: 988874604544.0000\n",
      "Epoch 1656/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 830223220736.0000 - val_loss: 988006973440.0000\n",
      "Epoch 1657/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 829487513600.0000 - val_loss: 987139473408.0000\n",
      "Epoch 1658/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 828750888960.0000 - val_loss: 986264240128.0000\n",
      "Epoch 1659/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 827983069184.0000 - val_loss: 985394184192.0000\n",
      "Epoch 1660/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 827258699776.0000 - val_loss: 984529764352.0000\n",
      "Epoch 1661/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 826511917056.0000 - val_loss: 983691886592.0000\n",
      "Epoch 1662/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 825797443584.0000 - val_loss: 982795681792.0000\n",
      "Epoch 1663/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 825017761792.0000 - val_loss: 981985656832.0000\n",
      "Epoch 1664/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 824321638400.0000 - val_loss: 981137620992.0000\n",
      "Epoch 1665/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 823601135616.0000 - val_loss: 980292796416.0000\n",
      "Epoch 1666/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 822884106240.0000 - val_loss: 979446071296.0000\n",
      "Epoch 1667/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 822150430720.0000 - val_loss: 978562711552.0000\n",
      "Epoch 1668/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 821401550848.0000 - val_loss: 977661263872.0000\n",
      "Epoch 1669/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 820630716416.0000 - val_loss: 976825745408.0000\n",
      "Epoch 1670/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 819934986240.0000 - val_loss: 975966371840.0000\n",
      "Epoch 1671/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 819187613696.0000 - val_loss: 975134523392.0000\n",
      "Epoch 1672/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 818462588928.0000 - val_loss: 974305427456.0000\n",
      "Epoch 1673/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 817766006784.0000 - val_loss: 973449658368.0000\n",
      "Epoch 1674/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 817042489344.0000 - val_loss: 972608569344.0000\n",
      "Epoch 1675/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 816326443008.0000 - val_loss: 971761451008.0000\n",
      "Epoch 1676/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 815606071296.0000 - val_loss: 970911907840.0000\n",
      "Epoch 1677/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 814880522240.0000 - val_loss: 970064461824.0000\n",
      "Epoch 1678/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 814146912256.0000 - val_loss: 969241853952.0000\n",
      "Epoch 1679/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 813432045568.0000 - val_loss: 968403648512.0000\n",
      "Epoch 1680/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 812723404800.0000 - val_loss: 967504363520.0000\n",
      "Epoch 1681/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 811956436992.0000 - val_loss: 966661046272.0000\n",
      "Epoch 1682/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 811231739904.0000 - val_loss: 965821988864.0000\n",
      "Epoch 1683/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 810506715136.0000 - val_loss: 964972052480.0000\n",
      "Epoch 1684/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 809766682624.0000 - val_loss: 964088233984.0000\n",
      "Epoch 1685/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 809019506688.0000 - val_loss: 963202908160.0000\n",
      "Epoch 1686/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 808266956800.0000 - val_loss: 962357755904.0000\n",
      "Epoch 1687/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 807528693760.0000 - val_loss: 961486061568.0000\n",
      "Epoch 1688/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 806759366656.0000 - val_loss: 960621051904.0000\n",
      "Epoch 1689/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 805997576192.0000 - val_loss: 959688081408.0000\n",
      "Epoch 1690/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 805234081792.0000 - val_loss: 958791090176.0000\n",
      "Epoch 1691/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 804502634496.0000 - val_loss: 957921361920.0000\n",
      "Epoch 1692/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 803762208768.0000 - val_loss: 957100326912.0000\n",
      "Epoch 1693/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 803057238016.0000 - val_loss: 956263038976.0000\n",
      "Epoch 1694/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 802355085312.0000 - val_loss: 955396128768.0000\n",
      "Epoch 1695/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 801596637184.0000 - val_loss: 954578698240.0000\n",
      "Epoch 1696/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 800880263168.0000 - val_loss: 953702875136.0000\n",
      "Epoch 1697/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 800115916800.0000 - val_loss: 952843567104.0000\n",
      "Epoch 1698/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 799385649152.0000 - val_loss: 951938908160.0000\n",
      "Epoch 1699/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 798638997504.0000 - val_loss: 951073767424.0000\n",
      "Epoch 1700/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 797909057536.0000 - val_loss: 950182477824.0000\n",
      "Epoch 1701/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 797144973312.0000 - val_loss: 949335621632.0000\n",
      "Epoch 1702/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 796425060352.0000 - val_loss: 948478476288.0000\n",
      "Epoch 1703/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 795682603008.0000 - val_loss: 947579387904.0000\n",
      "Epoch 1704/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 794918125568.0000 - val_loss: 946685476864.0000\n",
      "Epoch 1705/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 794183860224.0000 - val_loss: 945846222848.0000\n",
      "Epoch 1706/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 793449332736.0000 - val_loss: 944981213184.0000\n",
      "Epoch 1707/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 792716443648.0000 - val_loss: 944100081664.0000\n",
      "Epoch 1708/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 791956160512.0000 - val_loss: 943218425856.0000\n",
      "Epoch 1709/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 791200595968.0000 - val_loss: 942399750144.0000\n",
      "Epoch 1710/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 790518956032.0000 - val_loss: 941547257856.0000\n",
      "Epoch 1711/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 789779644416.0000 - val_loss: 940686835712.0000\n",
      "Epoch 1712/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 789052129280.0000 - val_loss: 939828051968.0000\n",
      "Epoch 1713/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 788327563264.0000 - val_loss: 938997121024.0000\n",
      "Epoch 1714/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 787626393600.0000 - val_loss: 938162585600.0000\n",
      "Epoch 1715/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 786900451328.0000 - val_loss: 937335717888.0000\n",
      "Epoch 1716/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 786184929280.0000 - val_loss: 936505245696.0000\n",
      "Epoch 1717/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 785471832064.0000 - val_loss: 935631454208.0000\n",
      "Epoch 1718/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 784755261440.0000 - val_loss: 934787743744.0000\n",
      "Epoch 1719/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 784028467200.0000 - val_loss: 933953732608.0000\n",
      "Epoch 1720/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 783328542720.0000 - val_loss: 933111595008.0000\n",
      "Epoch 1721/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 782597357568.0000 - val_loss: 932317298688.0000\n",
      "Epoch 1722/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 781901561856.0000 - val_loss: 931489054720.0000\n",
      "Epoch 1723/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 781195739136.0000 - val_loss: 930598420480.0000\n",
      "Epoch 1724/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 780460163072.0000 - val_loss: 929749925888.0000\n",
      "Epoch 1725/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 779734482944.0000 - val_loss: 928914800640.0000\n",
      "Epoch 1726/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 779025383424.0000 - val_loss: 928081707008.0000\n",
      "Epoch 1727/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 778321592320.0000 - val_loss: 927221415936.0000\n",
      "Epoch 1728/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 777582608384.0000 - val_loss: 926397628416.0000\n",
      "Epoch 1729/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 776893169664.0000 - val_loss: 925555425280.0000\n",
      "Epoch 1730/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 776153202688.0000 - val_loss: 924692709376.0000\n",
      "Epoch 1731/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 775403995136.0000 - val_loss: 923812102144.0000\n",
      "Epoch 1732/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 774659244032.0000 - val_loss: 922989428736.0000\n",
      "Epoch 1733/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 773954207744.0000 - val_loss: 922112884736.0000\n",
      "Epoch 1734/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 773202968576.0000 - val_loss: 921243811840.0000\n",
      "Epoch 1735/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 772470931456.0000 - val_loss: 920400232448.0000\n",
      "Epoch 1736/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 771772055552.0000 - val_loss: 919526572032.0000\n",
      "Epoch 1737/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 771044474880.0000 - val_loss: 918697672704.0000\n",
      "Epoch 1738/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 770336227328.0000 - val_loss: 917890793472.0000\n",
      "Epoch 1739/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 769640759296.0000 - val_loss: 917064450048.0000\n",
      "Epoch 1740/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 768919863296.0000 - val_loss: 916240859136.0000\n",
      "Epoch 1741/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 768234160128.0000 - val_loss: 915363201024.0000\n",
      "Epoch 1742/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 767500156928.0000 - val_loss: 914529517568.0000\n",
      "Epoch 1743/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 766799511552.0000 - val_loss: 913673224192.0000\n",
      "Epoch 1744/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 766059544576.0000 - val_loss: 912855859200.0000\n",
      "Epoch 1745/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 765343367168.0000 - val_loss: 911994322944.0000\n",
      "Epoch 1746/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 764644622336.0000 - val_loss: 911150678016.0000\n",
      "Epoch 1747/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 763900198912.0000 - val_loss: 910370406400.0000\n",
      "Epoch 1748/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 763208073216.0000 - val_loss: 909515030528.0000\n",
      "Epoch 1749/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 762505854976.0000 - val_loss: 908667518976.0000\n",
      "Epoch 1750/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 761779519488.0000 - val_loss: 907813388288.0000\n",
      "Epoch 1751/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 761061441536.0000 - val_loss: 906989010944.0000\n",
      "Epoch 1752/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 760360206336.0000 - val_loss: 906155786240.0000\n",
      "Epoch 1753/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 759669194752.0000 - val_loss: 905317122048.0000\n",
      "Epoch 1754/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 758947381248.0000 - val_loss: 904489730048.0000\n",
      "Epoch 1755/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 758225371136.0000 - val_loss: 903653752832.0000\n",
      "Epoch 1756/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 757518565376.0000 - val_loss: 902769672192.0000\n",
      "Epoch 1757/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 756779122688.0000 - val_loss: 901929828352.0000\n",
      "Epoch 1758/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 756063731712.0000 - val_loss: 901134548992.0000\n",
      "Epoch 1759/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 755374948352.0000 - val_loss: 900259905536.0000\n",
      "Epoch 1760/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 754637471744.0000 - val_loss: 899386507264.0000\n",
      "Epoch 1761/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 753932894208.0000 - val_loss: 898541355008.0000\n",
      "Epoch 1762/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 753186963456.0000 - val_loss: 897756037120.0000\n",
      "Epoch 1763/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 752523083776.0000 - val_loss: 896920059904.0000\n",
      "Epoch 1764/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 751795896320.0000 - val_loss: 896097320960.0000\n",
      "Epoch 1765/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 751072509952.0000 - val_loss: 895254331392.0000\n",
      "Epoch 1766/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 750367408128.0000 - val_loss: 894378639360.0000\n",
      "Epoch 1767/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 749648281600.0000 - val_loss: 893508124672.0000\n",
      "Epoch 1768/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 748928106496.0000 - val_loss: 892679880704.0000\n",
      "Epoch 1769/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 748240044032.0000 - val_loss: 891853537280.0000\n",
      "Epoch 1770/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 747504861184.0000 - val_loss: 891061075968.0000\n",
      "Epoch 1771/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 746824794112.0000 - val_loss: 890209370112.0000\n",
      "Epoch 1772/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 746121723904.0000 - val_loss: 889346326528.0000\n",
      "Epoch 1773/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 745370943488.0000 - val_loss: 888537350144.0000\n",
      "Epoch 1774/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 744686026752.0000 - val_loss: 887703339008.0000\n",
      "Epoch 1775/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 743985971200.0000 - val_loss: 886861398016.0000\n",
      "Epoch 1776/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 743277199360.0000 - val_loss: 886008381440.0000\n",
      "Epoch 1777/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 742550470656.0000 - val_loss: 885177712640.0000\n",
      "Epoch 1778/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 741846417408.0000 - val_loss: 884370833408.0000\n",
      "Epoch 1779/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 741160255488.0000 - val_loss: 883545931776.0000\n",
      "Epoch 1780/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 740464852992.0000 - val_loss: 882696060928.0000\n",
      "Epoch 1781/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 739734847488.0000 - val_loss: 881906548736.0000\n",
      "Epoch 1782/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 739078963200.0000 - val_loss: 881086758912.0000\n",
      "Epoch 1783/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 738372747264.0000 - val_loss: 880280469504.0000\n",
      "Epoch 1784/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 737700347904.0000 - val_loss: 879413821440.0000\n",
      "Epoch 1785/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 736953499648.0000 - val_loss: 878604910592.0000\n",
      "Epoch 1786/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 736284573696.0000 - val_loss: 877790363648.0000\n",
      "Epoch 1787/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 735574556672.0000 - val_loss: 877002227712.0000\n",
      "Epoch 1788/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 734914805760.0000 - val_loss: 876189581312.0000\n",
      "Epoch 1789/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 734230872064.0000 - val_loss: 875370119168.0000\n",
      "Epoch 1790/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 733515284480.0000 - val_loss: 874553999360.0000\n",
      "Epoch 1791/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 732819226624.0000 - val_loss: 873722216448.0000\n",
      "Epoch 1792/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 732108881920.0000 - val_loss: 872876539904.0000\n",
      "Epoch 1793/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 731393163264.0000 - val_loss: 872039579648.0000\n",
      "Epoch 1794/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 730691796992.0000 - val_loss: 871181778944.0000\n",
      "Epoch 1795/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 729949601792.0000 - val_loss: 870352551936.0000\n",
      "Epoch 1796/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 729257869312.0000 - val_loss: 869504188416.0000\n",
      "Epoch 1797/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 728539987968.0000 - val_loss: 868627120128.0000\n",
      "Epoch 1798/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 727799234560.0000 - val_loss: 867809886208.0000\n",
      "Epoch 1799/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 727105601536.0000 - val_loss: 866992848896.0000\n",
      "Epoch 1800/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 726444802048.0000 - val_loss: 866150318080.0000\n",
      "Epoch 1801/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 725727707136.0000 - val_loss: 865338720256.0000\n",
      "Epoch 1802/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 725029814272.0000 - val_loss: 864544423936.0000\n",
      "Epoch 1803/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 724360757248.0000 - val_loss: 863728041984.0000\n",
      "Epoch 1804/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 723682459648.0000 - val_loss: 862915526656.0000\n",
      "Epoch 1805/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 723011895296.0000 - val_loss: 862084530176.0000\n",
      "Epoch 1806/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 722287329280.0000 - val_loss: 861312188416.0000\n",
      "Epoch 1807/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 721624629248.0000 - val_loss: 860455174144.0000\n",
      "Epoch 1808/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 720902422528.0000 - val_loss: 859617558528.0000\n",
      "Epoch 1809/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 720184606720.0000 - val_loss: 858801504256.0000\n",
      "Epoch 1810/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 719474786304.0000 - val_loss: 857948422144.0000\n",
      "Epoch 1811/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 718764048384.0000 - val_loss: 857113427968.0000\n",
      "Epoch 1812/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 718068842496.0000 - val_loss: 856316968960.0000\n",
      "Epoch 1813/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 717398212608.0000 - val_loss: 855499800576.0000\n",
      "Epoch 1814/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 716699533312.0000 - val_loss: 854634528768.0000\n",
      "Epoch 1815/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 715976278016.0000 - val_loss: 853828567040.0000\n",
      "Epoch 1816/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 715287429120.0000 - val_loss: 853037088768.0000\n",
      "Epoch 1817/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 714625056768.0000 - val_loss: 852172931072.0000\n",
      "Epoch 1818/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 713870540800.0000 - val_loss: 851376668672.0000\n",
      "Epoch 1819/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 713189228544.0000 - val_loss: 850523193344.0000\n",
      "Epoch 1820/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 712481767424.0000 - val_loss: 849696980992.0000\n",
      "Epoch 1821/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 711802880000.0000 - val_loss: 848864542720.0000\n",
      "Epoch 1822/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 711080804352.0000 - val_loss: 848028958720.0000\n",
      "Epoch 1823/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 710367313920.0000 - val_loss: 847177515008.0000\n",
      "Epoch 1824/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 709655658496.0000 - val_loss: 846268596224.0000\n",
      "Epoch 1825/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 708898586624.0000 - val_loss: 845423902720.0000\n",
      "Epoch 1826/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 708176248832.0000 - val_loss: 844637405184.0000\n",
      "Epoch 1827/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 707498999808.0000 - val_loss: 843818074112.0000\n",
      "Epoch 1828/2000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 706820046848.0000 - val_loss: 842968268800.0000\n",
      "Epoch 1829/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 706112454656.0000 - val_loss: 842139631616.0000\n",
      "Epoch 1830/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 705428717568.0000 - val_loss: 841328361472.0000\n",
      "Epoch 1831/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 704729186304.0000 - val_loss: 840527446016.0000\n",
      "Epoch 1832/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 704013598720.0000 - val_loss: 839672856576.0000\n",
      "Epoch 1833/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 703306268672.0000 - val_loss: 838774358016.0000\n",
      "Epoch 1834/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 702551556096.0000 - val_loss: 837928026112.0000\n",
      "Epoch 1835/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 701852352512.0000 - val_loss: 837114658816.0000\n",
      "Epoch 1836/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 701175103488.0000 - val_loss: 836280647680.0000\n",
      "Epoch 1837/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 700457091072.0000 - val_loss: 835427565568.0000\n",
      "Epoch 1838/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 699758346240.0000 - val_loss: 834616557568.0000\n",
      "Epoch 1839/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 699061895168.0000 - val_loss: 833822785536.0000\n",
      "Epoch 1840/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 698382876672.0000 - val_loss: 833002930176.0000\n",
      "Epoch 1841/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 697705562112.0000 - val_loss: 832183074816.0000\n",
      "Epoch 1842/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 697005637632.0000 - val_loss: 831336218624.0000\n",
      "Epoch 1843/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 696294572032.0000 - val_loss: 830507450368.0000\n",
      "Epoch 1844/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 695573676032.0000 - val_loss: 829671669760.0000\n",
      "Epoch 1845/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 694895640576.0000 - val_loss: 828825468928.0000\n",
      "Epoch 1846/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 694188441600.0000 - val_loss: 828015378432.0000\n",
      "Epoch 1847/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 693512044544.0000 - val_loss: 827218526208.0000\n",
      "Epoch 1848/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 692815462400.0000 - val_loss: 826466828288.0000\n",
      "Epoch 1849/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 692196343808.0000 - val_loss: 825655230464.0000\n",
      "Epoch 1850/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 691492093952.0000 - val_loss: 824845074432.0000\n",
      "Epoch 1851/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 690819694592.0000 - val_loss: 824026398720.0000\n",
      "Epoch 1852/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 690130059264.0000 - val_loss: 823224631296.0000\n",
      "Epoch 1853/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 689444618240.0000 - val_loss: 822405890048.0000\n",
      "Epoch 1854/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 688763240448.0000 - val_loss: 821604974592.0000\n",
      "Epoch 1855/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 688088809472.0000 - val_loss: 820795867136.0000\n",
      "Epoch 1856/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 687389868032.0000 - val_loss: 819944423424.0000\n",
      "Epoch 1857/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 686690533376.0000 - val_loss: 819139575808.0000\n",
      "Epoch 1858/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 686005026816.0000 - val_loss: 818357600256.0000\n",
      "Epoch 1859/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 685313228800.0000 - val_loss: 817528897536.0000\n",
      "Epoch 1860/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 684659245056.0000 - val_loss: 816653598720.0000\n",
      "Epoch 1861/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 683936055296.0000 - val_loss: 815842590720.0000\n",
      "Epoch 1862/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 683254218752.0000 - val_loss: 815046524928.0000\n",
      "Epoch 1863/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 682579132416.0000 - val_loss: 814251835392.0000\n",
      "Epoch 1864/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 681907322880.0000 - val_loss: 813467893760.0000\n",
      "Epoch 1865/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 681238986752.0000 - val_loss: 812698501120.0000\n",
      "Epoch 1866/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 680591097856.0000 - val_loss: 811889721344.0000\n",
      "Epoch 1867/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 679911227392.0000 - val_loss: 811090968576.0000\n",
      "Epoch 1868/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 679239548928.0000 - val_loss: 810267901952.0000\n",
      "Epoch 1869/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 678541000704.0000 - val_loss: 809444179968.0000\n",
      "Epoch 1870/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 677852741632.0000 - val_loss: 808639397888.0000\n",
      "Epoch 1871/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 677175689216.0000 - val_loss: 807854407680.0000\n",
      "Epoch 1872/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 676506959872.0000 - val_loss: 807074725888.0000\n",
      "Epoch 1873/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 675857956864.0000 - val_loss: 806270533632.0000\n",
      "Epoch 1874/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 675183591424.0000 - val_loss: 805437112320.0000\n",
      "Epoch 1875/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 674507390976.0000 - val_loss: 804634099712.0000\n",
      "Epoch 1876/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 673842397184.0000 - val_loss: 803834626048.0000\n",
      "Epoch 1877/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 673142472704.0000 - val_loss: 803086598144.0000\n",
      "Epoch 1878/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 672523485184.0000 - val_loss: 802270806016.0000\n",
      "Epoch 1879/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 671833587712.0000 - val_loss: 801481687040.0000\n",
      "Epoch 1880/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 671176130560.0000 - val_loss: 800691650560.0000\n",
      "Epoch 1881/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 670504517632.0000 - val_loss: 799934251008.0000\n",
      "Epoch 1882/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 669859577856.0000 - val_loss: 799105548288.0000\n",
      "Epoch 1883/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 669167321088.0000 - val_loss: 798275600384.0000\n",
      "Epoch 1884/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 668460908544.0000 - val_loss: 797478289408.0000\n",
      "Epoch 1885/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 667782283264.0000 - val_loss: 796717350912.0000\n",
      "Epoch 1886/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 667165917184.0000 - val_loss: 795888254976.0000\n",
      "Epoch 1887/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 666463436800.0000 - val_loss: 795127840768.0000\n",
      "Epoch 1888/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 665841369088.0000 - val_loss: 794337607680.0000\n",
      "Epoch 1889/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 665173950464.0000 - val_loss: 793532235776.0000\n",
      "Epoch 1890/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 664474812416.0000 - val_loss: 792716640256.0000\n",
      "Epoch 1891/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 663769841664.0000 - val_loss: 791900913664.0000\n",
      "Epoch 1892/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 663072866304.0000 - val_loss: 791068606464.0000\n",
      "Epoch 1893/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 662399221760.0000 - val_loss: 790211133440.0000\n",
      "Epoch 1894/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 661667250176.0000 - val_loss: 789391671296.0000\n",
      "Epoch 1895/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 660975190016.0000 - val_loss: 788531052544.0000\n",
      "Epoch 1896/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 660263337984.0000 - val_loss: 787681247232.0000\n",
      "Epoch 1897/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 659566886912.0000 - val_loss: 786886033408.0000\n",
      "Epoch 1898/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 658909888512.0000 - val_loss: 786113101824.0000\n",
      "Epoch 1899/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 658267176960.0000 - val_loss: 785322082304.0000\n",
      "Epoch 1900/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 657589731328.0000 - val_loss: 784537878528.0000\n",
      "Epoch 1901/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 656931422208.0000 - val_loss: 783733358592.0000\n",
      "Epoch 1902/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 656249192448.0000 - val_loss: 782923857920.0000\n",
      "Epoch 1903/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 655594094592.0000 - val_loss: 782141292544.0000\n",
      "Epoch 1904/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 654948761600.0000 - val_loss: 781373014016.0000\n",
      "Epoch 1905/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 654282653696.0000 - val_loss: 780586188800.0000\n",
      "Epoch 1906/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 653634502656.0000 - val_loss: 779787173888.0000\n",
      "Epoch 1907/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 652976652288.0000 - val_loss: 779011031040.0000\n",
      "Epoch 1908/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 652324372480.0000 - val_loss: 778242228224.0000\n",
      "Epoch 1909/2000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 651684478976.0000 - val_loss: 777461301248.0000\n",
      "Epoch 1910/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 650993664000.0000 - val_loss: 776661696512.0000\n",
      "Epoch 1911/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 650349838336.0000 - val_loss: 775867138048.0000\n",
      "Epoch 1912/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 649677963264.0000 - val_loss: 775089684480.0000\n",
      "Epoch 1913/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 649026207744.0000 - val_loss: 774320029696.0000\n",
      "Epoch 1914/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 648377466880.0000 - val_loss: 773553848320.0000\n",
      "Epoch 1915/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 647743799296.0000 - val_loss: 772764925952.0000\n",
      "Epoch 1916/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 647083655168.0000 - val_loss: 771966500864.0000\n",
      "Epoch 1917/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 646423052288.0000 - val_loss: 771190358016.0000\n",
      "Epoch 1918/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 645761925120.0000 - val_loss: 770440560640.0000\n",
      "Epoch 1919/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 645132386304.0000 - val_loss: 769696530432.0000\n",
      "Epoch 1920/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 644490592256.0000 - val_loss: 768934608896.0000\n",
      "Epoch 1921/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 643876454400.0000 - val_loss: 768134217728.0000\n",
      "Epoch 1922/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 643207987200.0000 - val_loss: 767351259136.0000\n",
      "Epoch 1923/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 642553872384.0000 - val_loss: 766587633664.0000\n",
      "Epoch 1924/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 641919680512.0000 - val_loss: 765815685120.0000\n",
      "Epoch 1925/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 641269694464.0000 - val_loss: 765061365760.0000\n",
      "Epoch 1926/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 640642318336.0000 - val_loss: 764284502016.0000\n",
      "Epoch 1927/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 639993053184.0000 - val_loss: 763513405440.0000\n",
      "Epoch 1928/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 639343067136.0000 - val_loss: 762769178624.0000\n",
      "Epoch 1929/2000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 638694850560.0000 - val_loss: 761986023424.0000\n",
      "Epoch 1930/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 638087659520.0000 - val_loss: 761148604416.0000\n",
      "Epoch 1931/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 637369778176.0000 - val_loss: 760429805568.0000\n",
      "Epoch 1932/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 636754984960.0000 - val_loss: 759681908736.0000\n",
      "Epoch 1933/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 636127936512.0000 - val_loss: 758919593984.0000\n",
      "Epoch 1934/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635529789440.0000 - val_loss: 758107078656.0000\n",
      "Epoch 1935/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 634832420864.0000 - val_loss: 757374189568.0000\n",
      "Epoch 1936/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 634220183552.0000 - val_loss: 756629962752.0000\n",
      "Epoch 1937/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 633579044864.0000 - val_loss: 755856572416.0000\n",
      "Epoch 1938/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 632916672512.0000 - val_loss: 755069026304.0000\n",
      "Epoch 1939/2000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 632295260160.0000 - val_loss: 754255462400.0000\n",
      "Epoch 1940/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 631603462144.0000 - val_loss: 753520082944.0000\n",
      "Epoch 1941/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 630990700544.0000 - val_loss: 752708812800.0000\n",
      "Epoch 1942/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 630335995904.0000 - val_loss: 751931162624.0000\n",
      "Epoch 1943/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 629676113920.0000 - val_loss: 751174156288.0000\n",
      "Epoch 1944/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 629035630592.0000 - val_loss: 750438842368.0000\n",
      "Epoch 1945/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 628410744832.0000 - val_loss: 749690880000.0000\n",
      "Epoch 1946/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 627795230720.0000 - val_loss: 748895272960.0000\n",
      "Epoch 1947/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 627145572352.0000 - val_loss: 748132827136.0000\n",
      "Epoch 1948/2000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 626519048192.0000 - val_loss: 747387158528.0000\n",
      "Epoch 1949/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 625894293504.0000 - val_loss: 746656628736.0000\n",
      "Epoch 1950/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 625298374656.0000 - val_loss: 745913712640.0000\n",
      "Epoch 1951/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 624667262976.0000 - val_loss: 745198059520.0000\n",
      "Epoch 1952/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 624042901504.0000 - val_loss: 744445247488.0000\n",
      "Epoch 1953/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 623431122944.0000 - val_loss: 743664910336.0000\n",
      "Epoch 1954/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 622786707456.0000 - val_loss: 742926516224.0000\n",
      "Epoch 1955/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 622177157120.0000 - val_loss: 742165250048.0000\n",
      "Epoch 1956/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 621538312192.0000 - val_loss: 741418926080.0000\n",
      "Epoch 1957/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 620920963072.0000 - val_loss: 740643176448.0000\n",
      "Epoch 1958/2000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 620254003200.0000 - val_loss: 739908452352.0000\n",
      "Epoch 1959/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 619640782848.0000 - val_loss: 739145220096.0000\n",
      "Epoch 1960/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 618987716608.0000 - val_loss: 738338603008.0000\n",
      "Epoch 1961/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 618335240192.0000 - val_loss: 737546207232.0000\n",
      "Epoch 1962/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 617674506240.0000 - val_loss: 736807682048.0000\n",
      "Epoch 1963/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 617079963648.0000 - val_loss: 736058408960.0000\n",
      "Epoch 1964/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 616454029312.0000 - val_loss: 735313133568.0000\n",
      "Epoch 1965/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 615835369472.0000 - val_loss: 734553767936.0000\n",
      "Epoch 1966/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 615208648704.0000 - val_loss: 733787062272.0000\n",
      "Epoch 1967/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 614557548544.0000 - val_loss: 733060923392.0000\n",
      "Epoch 1968/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 613952061440.0000 - val_loss: 732300967936.0000\n",
      "Epoch 1969/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 613328945152.0000 - val_loss: 731560869888.0000\n",
      "Epoch 1970/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 612701634560.0000 - val_loss: 730784333824.0000\n",
      "Epoch 1971/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 612060168192.0000 - val_loss: 730033356800.0000\n",
      "Epoch 1972/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 611431743488.0000 - val_loss: 729252757504.0000\n",
      "Epoch 1973/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 610804957184.0000 - val_loss: 728512266240.0000\n",
      "Epoch 1974/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 610185641984.0000 - val_loss: 727787634688.0000\n",
      "Epoch 1975/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 609579040768.0000 - val_loss: 727068835840.0000\n",
      "Epoch 1976/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 608976175104.0000 - val_loss: 726321463296.0000\n",
      "Epoch 1977/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 608335101952.0000 - val_loss: 725598994432.0000\n",
      "Epoch 1978/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 607709691904.0000 - val_loss: 724830257152.0000\n",
      "Epoch 1979/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 607101583360.0000 - val_loss: 724035502080.0000\n",
      "Epoch 1980/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 606444650496.0000 - val_loss: 723289440256.0000\n",
      "Epoch 1981/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 605827235840.0000 - val_loss: 722563760128.0000\n",
      "Epoch 1982/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 605212508160.0000 - val_loss: 721777852416.0000\n",
      "Epoch 1983/2000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 604567764992.0000 - val_loss: 721060954112.0000\n",
      "Epoch 1984/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 603972108288.0000 - val_loss: 720307159040.0000\n",
      "Epoch 1985/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 603343224832.0000 - val_loss: 719492546560.0000\n",
      "Epoch 1986/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 602673184768.0000 - val_loss: 718765293568.0000\n",
      "Epoch 1987/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 602057998336.0000 - val_loss: 718009991168.0000\n",
      "Epoch 1988/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 601448382464.0000 - val_loss: 717227163648.0000\n",
      "Epoch 1989/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 600810717184.0000 - val_loss: 716483854336.0000\n",
      "Epoch 1990/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 600182292480.0000 - val_loss: 715748474880.0000\n",
      "Epoch 1991/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 599552425984.0000 - val_loss: 714985963520.0000\n",
      "Epoch 1992/2000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 598914301952.0000 - val_loss: 714225614848.0000\n",
      "Epoch 1993/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 598264512512.0000 - val_loss: 713443704832.0000\n",
      "Epoch 1994/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 597618786304.0000 - val_loss: 712647704576.0000\n",
      "Epoch 1995/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 596965588992.0000 - val_loss: 711860289536.0000\n",
      "Epoch 1996/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 596333297664.0000 - val_loss: 711091093504.0000\n",
      "Epoch 1997/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 595709853696.0000 - val_loss: 710336184320.0000\n",
      "Epoch 1998/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 595073695744.0000 - val_loss: 709640192000.0000\n",
      "Epoch 1999/2000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 594493636608.0000 - val_loss: 708913397760.0000\n",
      "Epoch 2000/2000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 593871175680.0000 - val_loss: 708147871744.0000\n"
     ]
    }
   ],
   "source": [
    "from tabnanny import verbose\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, verbose=1, epochs=2000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55      120000\n",
       " 73      160000\n",
       " 33      145000\n",
       " 446    3600000\n",
       " 425    1500000\n",
       "         ...   \n",
       " 60      139900\n",
       " 110     275000\n",
       " 299    1900000\n",
       " 316    1990000\n",
       " 29      115000\n",
       " Name: preco, Length: 141, dtype: int64,\n",
       " array([[ 161936.11 ],\n",
       "        [ 143339.55 ],\n",
       "        [ 159312.45 ],\n",
       "        [1156859.1  ],\n",
       "        [1008548.5  ],\n",
       "        [ 146783.81 ],\n",
       "        [ 121908.5  ],\n",
       "        [ 107328.38 ],\n",
       "        [ 845657.56 ],\n",
       "        [ 132724.4  ],\n",
       "        [ 186320.81 ],\n",
       "        [ 783246.56 ],\n",
       "        [1129731.6  ],\n",
       "        [ 929976.4  ],\n",
       "        [1605417.8  ],\n",
       "        [1137071.9  ],\n",
       "        [ 170818.45 ],\n",
       "        [ 160303.69 ],\n",
       "        [ 999525.6  ],\n",
       "        [ 156598.42 ],\n",
       "        [ 176947.88 ],\n",
       "        [1694943.9  ],\n",
       "        [ 139173.8  ],\n",
       "        [ 741030.75 ],\n",
       "        [ 175184.95 ],\n",
       "        [ 159071.53 ],\n",
       "        [ 914894.3  ],\n",
       "        [ 185800.1  ],\n",
       "        [ 140735.95 ],\n",
       "        [ 161765.45 ],\n",
       "        [ 124712.87 ],\n",
       "        [ 628630.75 ],\n",
       "        [ 187362.27 ],\n",
       "        [ 927002.6  ],\n",
       "        [ 129079.375],\n",
       "        [ 176827.42 ],\n",
       "        [1176608.9  ],\n",
       "        [1189783.6  ],\n",
       "        [ 670288.2  ],\n",
       "        [ 135277.81 ],\n",
       "        [ 986138.75 ],\n",
       "        [ 687955.06 ],\n",
       "        [ 131011.69 ],\n",
       "        [ 193090.17 ],\n",
       "        [ 625023.3  ],\n",
       "        [ 167173.4  ],\n",
       "        [ 947363.4  ],\n",
       "        [ 138031.97 ],\n",
       "        [ 149688.55 ],\n",
       "        [ 188924.42 ],\n",
       "        [ 897189.9  ],\n",
       "        [ 656548.75 ],\n",
       "        [ 168635.19 ],\n",
       "        [ 921644.8  ],\n",
       "        [ 170718.06 ],\n",
       "        [ 179871.42 ],\n",
       "        [ 186320.81 ],\n",
       "        [1093369.1  ],\n",
       "        [ 185800.1  ],\n",
       "        [ 175084.58 ],\n",
       "        [ 947363.4  ],\n",
       "        [ 670288.2  ],\n",
       "        [ 888394.06 ],\n",
       "        [  96482.375],\n",
       "        [ 117843.15 ],\n",
       "        [ 671329.7  ],\n",
       "        [ 195072.66 ],\n",
       "        [1499266.4  ],\n",
       "        [ 170718.06 ],\n",
       "        [1059522.4  ],\n",
       "        [1371244.8  ],\n",
       "        [ 181634.36 ],\n",
       "        [ 409138.25 ],\n",
       "        [1060043.1  ],\n",
       "        [ 129079.375],\n",
       "        [1334273.8  ],\n",
       "        [ 674974.7  ],\n",
       "        [ 102491.34 ],\n",
       "        [ 179250.31 ],\n",
       "        [ 913313.4  ],\n",
       "        [ 674454.   ],\n",
       "        [ 654986.6  ],\n",
       "        [ 882591.   ],\n",
       "        [ 704134.94 ],\n",
       "        [  87139.555],\n",
       "        [ 757210.7  ],\n",
       "        [ 827971.94 ],\n",
       "        [ 131011.69 ],\n",
       "        [ 160894.67 ],\n",
       "        [ 985985.56 ],\n",
       "        [ 190486.58 ],\n",
       "        [ 136890.17 ],\n",
       "        [ 703093.5  ],\n",
       "        [ 729091.8  ],\n",
       "        [1080871.9  ],\n",
       "        [ 799232.   ],\n",
       "        [ 182155.06 ],\n",
       "        [ 938270.3  ],\n",
       "        [ 152392.53 ],\n",
       "        [ 819696.9  ],\n",
       "        [ 162907.28 ],\n",
       "        [ 615650.44 ],\n",
       "        [ 637520.56 ],\n",
       "        [ 184758.66 ],\n",
       "        [ 135227.62 ],\n",
       "        [1520797.9  ],\n",
       "        [ 648455.6  ],\n",
       "        [ 140215.23 ],\n",
       "        [ 106787.59 ],\n",
       "        [  90263.87 ],\n",
       "        [ 113997.35 ],\n",
       "        [ 181533.95 ],\n",
       "        [ 164620.02 ],\n",
       "        [ 160303.69 ],\n",
       "        [1260890.   ],\n",
       "        [ 928897.3  ],\n",
       "        [ 158020.05 ],\n",
       "        [1215662.8  ],\n",
       "        [ 142247.92 ],\n",
       "        [ 800373.8  ],\n",
       "        [ 795706.2  ],\n",
       "        [ 666963.2  ],\n",
       "        [ 621899.06 ],\n",
       "        [ 579720.8  ],\n",
       "        [ 173422.03 ],\n",
       "        [ 144901.7  ],\n",
       "        [ 575555.06 ],\n",
       "        [ 433523.03 ],\n",
       "        [ 180072.2  ],\n",
       "        [ 167173.4  ],\n",
       "        [ 162486.94 ],\n",
       "        [ 106787.59 ],\n",
       "        [1667904.   ],\n",
       "        [ 894046.8  ],\n",
       "        [ 178510.05 ],\n",
       "        [1002281.   ],\n",
       "        [ 158741.53 ],\n",
       "        [ 185229.19 ],\n",
       "        [ 898513.75 ],\n",
       "        [1142561.4  ],\n",
       "        [ 155597.16 ]], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = model.predict(X_test)\n",
    "y_test, prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(prediction_test - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cProfile import label\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validao loss')\n",
    "plt.title('treinando e validando perda')\n",
    "plt.xlabel('Epocas')\n",
    "plt.ylabel('perda')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________ Layer 0____________\n",
      "Bias to Layes 1 Neuron 0: 0.0\n",
      "Bias to Layes 1 Neuron 1: 22.73893928527832\n",
      "Layer 0, Neuron 0 to Layer 1, Neuron0 = 0.36219334602355957\n",
      "Layer 0, Neuron 0 to Layer 1, Neuron1 = 22.931974411010742\n",
      "Layer 0, Neuron 1 to Layer 1, Neuron0 = -1.063982367515564\n",
      "Layer 0, Neuron 1 to Layer 1, Neuron1 = 23.374052047729492\n",
      "______________ Layer 1____________\n",
      "Bias to Layes 2 Neuron 0: 20.783994674682617\n",
      "Layer 1, Neuron 0 to Layer 2, Neuron0 = -1.0872366428375244\n",
      "Layer 1, Neuron 1 to Layer 2, Neuron0 = 22.707096099853516\n"
     ]
    }
   ],
   "source": [
    "for layer_depth, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print(f'______________ Layer {layer_depth}____________')\n",
    "    for toNeuronNum, bias in enumerate(biases):\n",
    "        print(f'Bias to Layes {layer_depth+1} Neuron {toNeuronNum}: {bias}')\n",
    "    for fromNeuronNum, wgt in enumerate(weights):\n",
    "        for toNeuronNum, wgt2 in enumerate(wgt):\n",
    "            print(f'Layer {layer_depth}, Neuron {fromNeuronNum} to Layer {layer_depth+1}, Neuron{toNeuronNum} = {wgt2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 165\n",
    "x1 = 1530\n",
    "# 1700000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1552279.377133201"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden0 = max(0, ((x0*20.663421630859375)+(x1*21.274261474609375)+(20.698856353759766)))\n",
    "hidden1 = max(0, ((x0*20.630306243896484)+(x1*21.345911026000977)+(20.425968170166016)))\n",
    "\n",
    "output = max(0,((hidden0*21.40823745727539)+(hidden1*21.671785354614258)+(18.069671630859375)))\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa4685aff39827e2a5629e0c724fb241485259b314fe538401b57d336b9a4f7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
